[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Apuntes de Juegos en Red",
    "section": "",
    "text": "Preface\nApuntes de la asignatura Juegos en Red. Se organizan en 4 partes:\n\nIntroducci√≥n a las redes de computadores. Ofrece una visi√≥n general de c√≥mo funcionan las redes de computadores, tanto la parte hardware como software, utilizando la categorizaci√≥n de la pila de protocolos TCP/IP. Esta parte adem√°s tendr√° una serie de visualizaciones y ‚ÄúJuegos‚Äù que podr√©is encontrar en jergames.dslabapps.es\nBreve introducci√≥n a HTML, CSS, JS y Phaser con el que crearemos un juego web que al que se le a√±adir√°n funcionalidades de red en los pr√≥ximas partes.\nComunicaci√≥n entre clientes y servidores a trav√©s de APIs REST.\nComunicaci√≥n as√≠ncrona entre clientes y servidores.\n\n\n\n\n\n\n\nImportante\n\n\n\nNota: En la parte de redes de computadores, muchos conceptos debido a la naturaleza introductoria de este curso. Esta simplificaci√≥n se ve realizada por omisi√≥n, por ejemplo, se cuentan las variantes antiguas pero no las m√°s nuevas que son m√°s complejas, o por incompletitud, ignorando alguna parte de tecnolog√≠as o protocolos que dificultar√≠an su explicaci√≥n.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "ch/part_networks/network_intro/network_intro.html",
    "href": "ch/part_networks/network_intro/network_intro.html",
    "title": "1¬† Introducci√≥n a las Redes de Ordenadores",
    "section": "",
    "text": "1.1 Introducci√≥n\nLa etimolog√≠a de Internet es ‚ÄúInterconnected Networks‚Äù (Redes interconectadas), lo cual nos da una pista sobre qu√© es: una red global interconectada de redes m√°s peque√±as que permite la comunicaci√≥n entre los diferentes dispositivos conectados. Internet opera como un sistema descentralizado compuesto por varias capas de redes, desde las LAN (Local Area Networks), que son los nodos donde nos conectamos, hasta las WAN (Wide Area Networks) que abarcan continentes.\nEn la Figura¬†1.1 podemos ver una organizaci√≥n jer√°rquica de Internet, donde m√∫ltiples redes del mismo nivel se agregan para formar el siguiente nivel superior. A medida que ascendemos en la jerarqu√≠a, el n√∫mero de dispositivos que se pueden conectar se incrementa exponencialmente. Las PAN son redes que conectan dispositivos personales como smartphones y sirven para conectar con smartwatches y electrodom√©sticos, entre otros. Desde las PAN podemos tomar dos rutas principales hasta el Internet, a trav√©s de las LAN o directamente con las MAN (5G o 4G). Las LAN son redes que cubren hogares, oficinas u otras unidades donde el n√∫mero de dispositivos es reducido. La conexi√≥n a las LAN puede ser cableada o inal√°mbrica, por ejemplo con WLAN (Wi-Fi). Una CAN es una agrupaci√≥n de redes LAN, generalmente en campus universitarios o grandes empresas donde el n√∫mero de dispositivos es elevado. Las redes CAN, LANs individuales y las redes de telefon√≠a m√≥vil (e.g., 4G/5G) se juntan para dar lugar a las MAN. Las MAN generalmente abarcan ciudades o grupos de ciudades, que interconectadas dan lugar a las WANs. Finalmente, m√∫ltiples WANs dan lugar al Internet global. Las VPN (Virtual Private Network) operan como t√∫neles seguros sobre toda esta infraestructura, permitiendo que los dispositivos cambien din√°micamente entre rutas seg√∫n la tecnolog√≠a disponible en cada momento.\nPara ilustrar el funcionamiento de Internet vamos a utilizar un ejemplo simplificado. Supongamos que Mar√≠a quiere enviar un mensaje desde un Smartphone conectado a Internet a trav√©s del WiFi de su casa en Madrid a Takeshi, conectado a una LAN en la universidad de Tokio (dentro de una CAN). Puede que algunos t√©rminos no os suenen, no os preocup√©is, los iremos viendo a lo largo de la asignatura. El proceso de env√≠o ser√≠a el siguiente:\nEn este ejemplo simplificado de env√≠o de un mensaje por Internet ya estamos dispuestos para comprender algunos de sus componentes y identificadores. Si os fij√°is, hay dos componentes que est√°n presentes a lo largo del ejemplo, los switches y routers. El router es un dispositivo que conecta diferentes redes entre s√≠ usando direcciones IP. Es como un ‚Äúdirector de tr√°fico‚Äù que conoce las rutas entre redes distantes. Su funcionamiento a grandes rasgos es el siguiente: Llega un paquete, se identifica a trav√©s de la IP destino el camino de salida obteniendo la MAC del siguiente salto (hop), y se env√≠a el paquete. Este proceso, denominado enrutamiento 1, se repite hasta llegar a la red destino, por eso estos algoritmos, y por ello se determinan hop by hop. El switch por otra parte es un dispositivo que conecta equipos dentro de una misma red local usando direcciones MAC. Funciona como un ‚Äúrepartidor inteligente‚Äù que conoce exactamente d√≥nde est√° cada dispositivo en su red. Completando la analog√≠a, Los switches manejan el tr√°fico local, mientras que cuando necesitan enviar datos fuera de su red, los entregan a los routers. Los routers, a su vez, se conectan a otros routers o switches seg√∫n el destino.\nEl procedimiento de env√≠o se realiza con dos identificadores que hemos mencionado durante el ejemplo, la MAC y la direcci√≥n IP. La direcci√≥n IP funciona como la direcci√≥n postal de una casa y permite localizar el dispositivo en las redes (como 192.168.1.100), y la direcci√≥n MAC, que es como el DNI del dispositivo: √∫nico, asignado por el fabricante y que no cambia nunca. Los routers usan direcciones IP para decidir hacia d√≥nde enviar los paquetes, mientras que los switches usan direcciones MAC para entregar los datos al dispositivo correcto dentro de la red local. Por √∫ltimo, tenemos ARP, un protocolo que nos permite relacionarlas. El protocolo ARP es como un servicio de directorio telef√≥nico: cuando un dispositivo conoce la ‚Äúdirecci√≥n postal‚Äù (IP) pero necesita el ‚ÄúDNI‚Äù (MAC) para hacer la entrega final, env√≠a una consulta ARP preguntando ‚Äú¬øqui√©n vive en esta direcci√≥n?‚Äù. El dispositivo correspondiente responde con su MAC, permitiendo que la comunicaci√≥n se complete. ARP traduce entre el mundo de las direcciones (IP) y el mundo de las identidades f√≠sicas (MAC).\nUna vez vistos los componentes principales de Internet, vamos a realizar unas observaciones. Primero, Internet es un sistema distribuido. Esto quiere decir que es una uni√≥n de dispositivos que operan juntos con el fin de ofrecer una funcionalidad. Segundo, Internet tiene una arquitectura descentralizada2. Por lo tanto, la ca√≠da de alguna parte de Internet no tiene porque implicar la ca√≠da de Internet globalmente. Tercero, la ejecuci√≥n de los procesos de enrutamiento es local. Cada nodo de la red s√≥lo necesita saber cual va a ser el siguiente destino (‚Äúhop‚Äù). Es decir, no hay una planificaci√≥n global para el env√≠o de los paquetes. Debido a esto los algoritmos de enrutamiento normalmente se denominan ‚Äúhop by hop‚Äù e incorporan informaci√≥n de tiempo real 3, por lo que dos mensajes enviados al mismo destino no tienen por qu√© seguir la misma ruta. Todo esto facilita la escalabilidad del sistema, disminuye la congesti√≥n de la red y adem√°s proporciona resiliencia a fallos.\nHasta ahora hemos visto un ejemplo simplificado de env√≠o de mensaje, los principales componentes de Internet y algunos conceptos t√©cnicos. Pero a√∫n falta algo. Hemos dicho que Internet es un sistema distribuido formado por redes interconectadas. Pero, ¬øC√≥mo se entienden entre s√≠?. La respuesta son los protocolos. Un protocolo es una serie de pasos bien definidos que se realizan con un objetivo. En redes de computadores, es como un manual de instrucciones que especifica c√≥mo dos dispositivos deben intercambiar informaci√≥n. Es un conjunto de reglas que define exactamente c√≥mo deben estructurarse los mensajes, en qu√© orden enviarlos, qu√© estructura y formato tienen los mensajes que recibimos, y c√≥mo se debe actuar. Internet funciona gracias a una familia de protocolos organizados en capas, que veremos en el (intro-network-stacks?).\nPor ejemplificar los protocolos de red con una analog√≠a, son como las reglas de tr√°fico en una ciudad: as√≠ como los autos necesitan sem√°foros, se√±ales y carriles para circular ordenadamente sin chocar, los datos en una red necesitan protocolos que definan c√≥mo moverse, comunicarse y llegar a su destino correctamente. Sin estas reglas, tanto el tr√°fico vehicular como el flujo de datos ser√≠an un caos total, con ‚Äúaccidentes‚Äù y p√©rdida de informaci√≥n constante. Desde un punto de vista m√°s formal, podr√≠amos definir un protocolo como:\nEn los siguientes apartados vamos a profundizar en los conceptos introducidos hasta ahora, obteniendo un mejor entendimiento de c√≥mo funciona Internet, cuales son los principales actores involucrados, y c√≥mo podemos realizar nuestras propias aplicaciones que funcionen sobre la red. Los puntos se abordar√°n de la siguiente manera. Primero, se ver√°n desde un enfoque ‚Äúinform√°tico‚Äù, y despu√©s contextualizaremos como encaja cada uno de los puntos desde el punto de vista de desarrollo de videojuegos.",
    "crumbs": [
      "Introducci√≥n a redes",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n a las Redes de Ordenadores</span>"
    ]
  },
  {
    "objectID": "ch/part_networks/network_intro/network_intro.html#introducci√≥n",
    "href": "ch/part_networks/network_intro/network_intro.html#introducci√≥n",
    "title": "1¬† Introducci√≥n a las Redes de Ordenadores",
    "section": "",
    "text": "graph TD\n    PAN[\"üì± PAN (Personal Area Network)&lt;br&gt;Smartphone ‚Üî Smartwatch\"]\n    LAN[\"üè† LAN (Local Area Network)&lt;br&gt;Home/Office/Building Network\"]\n    WLAN[\"üì° WLAN (Wireless LAN)&lt;br&gt;Wi-Fi Implementation of LAN\"]\n    CAN[\"üè´ CAN (Campus Area Network)&lt;br&gt;Multiple LANs in Campus\"]\n    MAN_ISP[\"üèôÔ∏è MAN (Metropolitan Area Network)&lt;br&gt;ISP Network\"]\n    MAN_MOBILE[\"üì∂ MAN (Metropolitan Area Network)&lt;br&gt;5G/4G Mobile Network\"]\n    WAN[\"üåç WAN (Wide Area Network)&lt;br&gt;Between Cities or Countries\"]\n    INTERNET[\"üåê Internet&lt;br&gt;Global Interconnected WANs\"]\n    VPN[\"üîê VPN (Virtual Private Network)&lt;br&gt;Secure Tunnel over Internet\"]\n    \n    %% Traditional wired path\n    PAN --&gt; LAN\n    WLAN -.-&gt; LAN\n    LAN --&gt;|Multiple LANs| CAN\n    CAN --&gt; MAN_ISP\n    LAN --&gt;|Multiple LANs| MAN_ISP\n    \n    %% Mobile path\n    PAN --&gt; MAN_MOBILE\n    \n    %% Both MANs connect to WAN\n    MAN_ISP --&gt;|Multiple MANs| WAN\n    MAN_MOBILE --&gt;|Multiple MANs| WAN\n    WAN --&gt;|Multiple WANs| INTERNET\n    VPN --&gt; INTERNET\n    \n    style WLAN fill:#e1f5fe\n    style VPN fill:#f3e5f5\n    style MAN_MOBILE fill:#fff3e0\n\n\n\n\n\n\n\n\nFigura¬†1.1: Topolog√≠a jer√°rquica de Internet.\n\n\n\n\n\n\n1. Origen - LAN Madrid: El smartphone de Mar√≠a crea el paquete (pod√©is pensar en el como un mensaje) con la direcci√≥n IP de destino de Tokio y la direcci√≥n MAC del router WiFi como destino inmediato. El router WiFi recibe el frame Ethernet, examina la direcci√≥n IP de destino y se da cuenta de que no pertenece a su red local. Reemplaza la direcci√≥n MAC de destino por la de su gateway (ISP) y reenv√≠a el paquete.\n2. Router local a MAN: El router del ISP local recibe el frame con su propia direcci√≥n MAC como destino. Extrae el paquete IP, examina la direcci√≥n IP de destino y determina que debe enviarlo hacia la MAN de Madrid. Encapsula el paquete en un nuevo frame con la direcci√≥n MAC del siguiente router como destino.\n3. MAN a WAN nacional: El router de la MAN de Madrid recibe el frame dirigido a su direcci√≥n MAC, extrae el paquete IP y analiza el destino. Al comprender que Tokio est√° fuera de Espa√±a, encapsula el paquete en un nuevo frame con la direcci√≥n MAC del router de la WAN espa√±ola como destino.\n4. WAN a Internet global: El router de la WAN espa√±ola recibe el frame con su direcci√≥n MAC, consulta sus tablas de rutas internacionales para Jap√≥n y encapsula el paquete con la direcci√≥n MAC del siguiente router en la ruta internacional. En cada salto a trav√©s del backbone de Internet, los routers intercambian las direcciones MAC (origen y destino) mientras preservan las direcciones IP originales.\n5. Llegada a Jap√≥n - WAN a MAN: Un router de la WAN japonesa recibe el frame dirigido a su direcci√≥n MAC, reconoce que el destino IP est√° dentro de Jap√≥n y encapsula el paquete con la direcci√≥n MAC del router de la MAN de Tokio como nuevo destino.\n6. MAN a CAN: El router de la MAN de Tokio recibe el frame con su direcci√≥n MAC como destino, examina la IP y determina que pertenece a la universidad de Tokio. Encapsula el paquete en un nuevo frame dirigido a la direcci√≥n MAC del router gateway de la CAN universitaria.\n7. CAN a LAN destino: El router de la CAN universitaria recibe el frame dirigido a su direcci√≥n MAC, analiza la IP de destino para identificar qu√© LAN espec√≠fica del campus corresponde, y encapsula el paquete con la direcci√≥n MAC del router de esa LAN como destino.\n8. Destino final - LAN universitaria: El router de la LAN recibe el frame con su direcci√≥n MAC como destino, extrae el paquete IP y lo entrega al switch. El switch examina sus tablas ARP para encontrar la direcci√≥n MAC correspondiente a la IP de Takeshi, y finalmente env√≠a el frame con la direcci√≥n MAC real de Takeshi como destino, completando el viaje desde Madrid.\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipProtocolo\n\n\n\nUn protocolo define una serie de tipos de mensaje, su sint√°xis y su sem√°ntica, as√≠ como las reglas de cu√°ndo y c√≥mo enviar/responder los mensajes.",
    "crumbs": [
      "Introducci√≥n a redes",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n a las Redes de Ordenadores</span>"
    ]
  },
  {
    "objectID": "ch/part_networks/network_intro/network_intro.html#la-historia-de-internet",
    "href": "ch/part_networks/network_intro/network_intro.html#la-historia-de-internet",
    "title": "1¬† Introducci√≥n a las Redes de Ordenadores",
    "section": "1.2 La Historia de Internet",
    "text": "1.2 La Historia de Internet\nInternet, como otros muchos avances de la sociedad, naci√≥ como una necesidad de guerra. En concreto, en la Guerra Fr√≠a. En una guerra la informaci√≥n y poder comunicarla es poder. El objetivo inicial del germen de Internet, llamado ARPANET, era precisamente la comunicaci√≥n de informaci√≥n y que estos medios fuesen capaces de sobrevivir a un ataque nuclear. En 1969 la red experimental contaba con 4 host: UCLA, Stanford, UC Santa B√°rbara y la Universidad de Utah. Esta red utilizaba un mecanismo para la comunicaci√≥n de informaci√≥n llamada conmutaci√≥n de paquetes, donde los mensajes se divid√≠an en paquetes m√°s peque√±os que pod√≠an tomar diferentes rutas hasta llegar a su destino. As√≠ cumplieron los requisitos de tolerancia a fallos en el env√≠o de informaci√≥n a trav√©s de la descentralizaci√≥n y duplicidad, y adem√°s sentaron la semilla que permitir√≠a una escalabilidad natural. En 1971 ya contaba con 23 host (ver Figura¬†1.2), y en 1973 se realiz√≥ la primera conexi√≥n internacional con Noruega y Londres a trav√©s de tecnolog√≠a satelital. En esa √©poca la red se incrementaba a raz√≥n de 1 host cada aproximadamente 20 d√≠as.\n\n\n\n\n\n\nFigura¬†1.2: Distribuci√≥n geogr√°fica de los nodos de ARPANET en 1971¬†(BBC Brasil 2019).\n\n\n\nEn la d√©cada de los 80 ocurrir√≠an 4 eventos que dar√≠an forma al Internet que conocemos hoy en d√≠a. En primer lugar, en 1983 se adopt√≥ oficialmente la pila de protocolos TCP/IP como est√°ndar para ARPANET, que estableci√≥ las reglas de comunicaci√≥n que a√∫n seguimos hoy en d√≠a. Una de las grandes ventajas de TCP/IP fue que permiti√≥ que diferentes tipos de redes se pudiesen comunicar entre s√≠ de manera est√°ndar. Es decir, empezamos a tener redes formadas por redes interconectadas. En este momento fue cuando se empez√≥ a hablar del t√©rmino ‚ÄúInternet‚Äù para describir esta red de redes interconectadas. En segundo lugar, ARPANET se dividi√≥ en 1983, cre√°ndose MILNET como una red independiente para fines militares, mientras ARPANET continu√≥ creciendo en su uso acad√©mico. En tercer lugar, el CERN empez√≥ a interconectar sus ordenadores utilizando TCP/IP, sentando la base para el √∫ltimo evento. En cuarto y √∫ltimo lugar, Tim Berners-Lee, trabajando en el CERN, invent√≥ la World Wide Web en 1989-1990. Propuso un sistema de intercambio de informaci√≥n basado en hipertexto as√≠ como las direcciones URL, el protocolo HTTP y el lenguaje HTML, que son omnipresentes hoy en d√≠a.\nLos a√±os 90 fueron testigos de la transformaci√≥n de Internet de un proyecto acad√©mico a una infraestructura comercial global. El tr√°fico de ARPANET fue absorbido por Internet y se desmantel√≥ en 1990. En 1991, la World Wide Web fue anunciada p√∫blicamente cuando Tim Berners-Lee public√≥ el primer sitio web. Ese mismo a√±o se cre√≥ el primer navegador web gr√°fico, Mosaic, desarrollado en la Universidad de Illinois en 1993, que revolucion√≥ la experiencia de usuario al permitir la visualizaci√≥n de im√°genes junto con texto. La eliminaci√≥n de las restricciones comerciales sobre el uso de Internet por parte de la National Science Foundation en 1995 marc√≥ un punto de inflexi√≥n crucial. Comenzaron a aparecer los primeros proveedores comerciales de servicios de Internet (ISP) como America Online (AOL), que llev√≥ Internet a millones de hogares. Las empresas empezaron a ver el potencial no solo como un medio de comunicaci√≥n, sino como una plataforma de negocio, surgiendo los primeros sitios de comercio electr√≥nico como Amazon (1995) y eBay (1995). Yahoo! se estableci√≥ como uno de los primeros directorios web populares, mientras que motores de b√∫squeda como AltaVista comenzaron a indexar la creciente web. A finales de la d√©cada, Google fue fundado en 1998, revolucionando la b√∫squeda en Internet. Finalmente, se complet√≥ la transici√≥n de Internet de un proyecto gubernamental y acad√©mico a una infraestructura comercial global.\nEl cambio de milenio trajo la adopci√≥n masiva de Internet, inicialmente centrada en la conectividad de banda ancha en hogares y oficinas. La llamada ‚Äúburbuja de las punto-com‚Äù explot√≥ en 2000-2001, pero esto no fren√≥ la innovaci√≥n. Surgi√≥ la Web 2.0 a mediados de la d√©cada, caracterizada por sitios interactivos y generados por usuarios. Plataformas como MySpace (2003), Facebook (2004), YouTube (2005) y Twitter (2006) transformaron Internet en un medio social y participativo. La revoluci√≥n m√≥vil comenz√≥ realmente con el lanzamiento del iPhone en 2007, que democratiz√≥ el acceso a Internet desde dispositivos m√≥viles. Esto fue seguido por el desarrollo del sistema operativo Android y la proliferaci√≥n de smartphones. El concepto de ‚ÄúInternet de las Cosas‚Äù (IoT) comenz√≥ a materializarse con dispositivos dom√©sticos inteligentes, wearables y sensores conectados. La d√©cada de 2010 vio el surgimiento de la computaci√≥n en la nube con servicios como Amazon Web Services, la popularizaci√≥n de las redes sociales m√≥viles, el auge del comercio electr√≥nico m√≥vil, y el desarrollo de tecnolog√≠as como la realidad virtual y aumentada. M√°s recientemente, la inteligencia artificial, el machine learning, la tecnolog√≠a blockchain y las criptomonedas han redefinido las posibilidades de Internet.\nEl n√∫mero de dispositivos conectados se ha incrementado exponencialmente, pasando de millones en los 90 a miles de millones en la actualidad, marcando el desarrollo de nuevas tecnolog√≠as como 5G para soportar el creciente n√∫mero de dispositivos. En la Figura¬†1.3 pod√©is apreciar c√≥mo se han ido incrementando exponencialmente, y esta tendencia est√° lejos de revertirse. Las redes sociales, herramientas de teletrabajo, VoIP y videollamadas, inteligencia artificial, streaming de video, realidad virtual y aumentada, y otras muchas aplicaciones hacen que no solo se incremente el n√∫mero de dispositivos conectados, sino tambi√©n las necesidades de ancho de banda y tiempos de respuesta cada vez m√°s exigentes.\n\n\n\n\n\n\n\n\nxychart-beta\n    title \"Dispositivos Conectados a Internet por D√©cada (Log‚ÇÅ‚ÇÄ)\"\n    x-axis [\"1970s\", \"1980s\", \"1990s\", \"2000s\", \"2010s\", \"2020s\"]\n    y-axis \"Log‚ÇÅ‚ÇÄ (N√∫mero de dispositivos)\" 0 --&gt; 12\n    bar [0.6, 2.3, 4.5, 9.0, 10.1, 11.7]\n\n\n\n\n\n\n\n\nFigura¬†1.3: N√∫mero de dispositivos conectados por d√©cada desde ARPANET hasta Internet en 2025 (Ritchie et¬†al. 2023; Analytics 2020).\n\n\n\nEn conclusi√≥n, la evoluci√≥n de Internet (ver resumen en la Figura¬†1.4) desde sus or√≠genes militares como ARPANET hasta convertirse en la infraestructura global actual ilustra una transformaci√≥n extraordinaria que ha redefinido la sociedad moderna. Lo que comenz√≥ en 1969 como una red experimental de 4 hosts dise√±ada para resistir ataques nucleares, se ha convertido en un ecosistema interconectado de miles de millones de dispositivos. En los siguientes apartados veremos en detalle la tecnolog√≠a que sustenta Internet y obtendremos el conocimiento necesario para poder realizar aplicaciones y juegos en red.\n\n\n\n\n\n\n\n\ntimeline\n    title Evoluci√≥n de Internet: De ARPANET a la Era Digital\n    \n    section Era ARPANET (1969-1983)\n        1969 : Nace ARPANET\n             : 4 nodos iniciales (UCLA, Stanford, UC Santa B√°rbara, Utah)\n             : Implementaci√≥n de conmutaci√≥n de paquetes\n        \n        1973 : Primera conexi√≥n internacional\n        \n        1983 : Adopci√≥n oficial de TCP/IP\n             : Divisi√≥n de ARPANET (creaci√≥n de MILNET)\n             : Nace el t√©rmino \"Internet\"\n\n    section Nacimiento de la Web (1989-1995)\n        1989-1990 : Tim Berners-Lee inventa la World Wide Web\n                  : Desarrollo de HTTP, HTML y URLs\n        \n        1991 : Primer sitio web p√∫blico\n\n    section Era Comercial (1995-2000)\n        1995 : Eliminaci√≥n de restricciones comerciales\n             : Primeros ISPs comerciales (AOL)\n             : Aparecen Amazon y eBay\n        \n        1998 : Fundaci√≥n de Google\n        \n        2000-2001 : Explosi√≥n de la burbuja punto-com\n\n    section Web 2.0 y Redes Sociales (2003-2010)\n        2003-2006 : Redes sociales\n        2007 : Lanzamiento del iPhone\n\n    section Era Moderna (2010-2025)\n        2010s : Computaci√≥n en la nube, Internet de las cosas\n        \n        2020s : Inteligencia Artificial\n              : Tecnolog√≠a 5G\n\n\n\n\n\n\n\n\n\nFigura¬†1.4: Esquema de tiempo de los eventos m√°s significativos desde la creaci√≥n de ARPANET hasta 2025.",
    "crumbs": [
      "Introducci√≥n a redes",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n a las Redes de Ordenadores</span>"
    ]
  },
  {
    "objectID": "ch/part_networks/network_intro/network_intro.html#infraestructura-de-la-red-y-tecnolog√≠as-de-transmisi√≥n",
    "href": "ch/part_networks/network_intro/network_intro.html#infraestructura-de-la-red-y-tecnolog√≠as-de-transmisi√≥n",
    "title": "1¬† Introducci√≥n a las Redes de Ordenadores",
    "section": "1.3 Infraestructura de la red y tecnolog√≠as de transmisi√≥n",
    "text": "1.3 Infraestructura de la red y tecnolog√≠as de transmisi√≥n\nEn los cap√≠tulos anteriores hemos visto una peque√±a introducci√≥n a Internet y sus componentes. Ahora pasaremos a ver brevemente la parte f√≠sica (Hardware) de Internet antes de ver la parte Software en los siguientes cap√≠tulos. En la Figura¬†1.5 tenemos un ejemplo de diagrama donde se muestran los componentes de la red y parte de la taxonom√≠a que veremos en este cap√≠tulo.\n\n\n\n\n\n\nFigura¬†1.5: Red simplificada¬†(Kurose y Ross 2017).\n\n\n\nEmpezando por la parte m√°s externa, vamos a hablar de los sistemas terminales (‚Äúend systems‚Äù). De forma simplificada, podr√≠amos decir que estos son los sistemas que utilizan la Internet, y que el resto de componentes son los que sustentan la red. En esta categor√≠a tendr√≠amos los ordenadores, smartphones, dispositivos inteligentes.. es decir, los componentes conectados. En la jerga de Internet estos componentes se conocen como ‚Äúhost‚Äù, por que son los que tienen aplicaciones que funcionan sobre internet. Estos dispositivos se pueden conectar a la red a trav√©s de diferentes tecnolog√≠as que veremos posteriormente en este cap√≠tulo como WiFi o 5g. Los hosts, dependiendo de su uso, tambi√©n se pueden clasificar como clientes y servidores. Los servidores generalmente ofrecen un servicio que los clientes utilizan. Por ejemplo, cuando hablamos por Whatsapp, nuestro tel√©fono y el tel√©fono destino son clientes, y los ‚Äúordenadores‚Äù de Whatsapp que ofrecen el servidor son servidores. Esto no es clasificaci√≥n est√°tica y fija, y un cliente puede actuar de servidor tambi√©n. Este tipo de clasificaci√≥n la veremos en m√°s detalle en el Cap√≠tulo 5.\nMovi√©ndonos a la capa m√°s interna tenemos las redes de acceso (‚Äúaccess network‚Äù). Las redes de acceso es la red en la cual se conecta un host con el router (tambi√©n conocido router de borde, o ingl√©s ‚Äúedge router‚Äù) en el camino hacia el n√∫cleo de la red (core network). El router de borde junto a los hosts tambi√©n forman parte de lo que se denomina el borde de la red (‚Äúedge of the network‚Äù). Siguiendo con los ejemplos anteriores, cuando nos conectamos a Internet por WiFi/Ethernet en nuestra casa, universidad, etc, nos conectamos al ‚Äúrouter‚Äù, que ser√≠a el router de borde.\nAqu√≠ merece la pena hacer una aclaraci√≥n t√©cnica sobre el ‚Äúrouter‚Äù dom√©stico del ejemplo anterior. En realidad, estos dispositivos son equipos multifunci√≥n que integran varias tecnolog√≠as: un switch para la red local, un router para el enrutamiento entre redes, y t√≠picamente un punto de acceso WiFi. Cuando nos conectamos por cable o WiFi, t√©cnicamente nos conectamos primero al switch integrado, y cuando la comunicaci√≥n debe salir hacia Internet, el componente router se encarga del enrutamiento hacia otras redes. Aunque en el uso cotidiano llamamos ‚Äúrouter‚Äù a todo el dispositivo, es importante entender que internamente realiza m√∫ltiples funciones de red.\nEn el router dom√©stico, o router de borde, tenemos dos tipos de conexiones principales: la conexi√≥n con los hosts y la conexi√≥n con el siguiente router. Vamos a ver brevemente los tipos de tecnolog√≠a para cada caso. Empezando por la conexi√≥n host-router, tenemos dos tipos principalmente: conexi√≥n cableada tipo Ethernet y conexi√≥n inal√°mbrica WiFi. En la (tab-ni-infra-host-edge?) pod√©is ver una comparativa de sus principales caracter√≠sticas.\n\n\n\n\n\n\n\n\n\n\n\n\n\nTecnolog√≠a\nMedio F√≠sico\nTipo Conexi√≥n\nSimetr√≠a\nVelocidad T√≠pica\nAlcance\nEstado 2025\n\n\n\n\nWiFi 6\nRadio 2.4/5/6 GHz\nCompartida\nSim√©trica*\n200-400 Mb/s\n30-50 m\nEst√°ndar\n\n\nEthernet\nPar trenzado\nDedicada\nSim√©trica\n1000/1000 Mb/s\n&lt;100 m\nEst√°ndar\n\n\n4G LTE\nRadio m√≥vil\nCompartida\nAsim√©trica\n50/15 Mb/s\nVarios km\nEstable\n\n\n5G\nRadio m√≥vil\nCompartida\nAsim√©trica\n300/50 Mb/s\n1-5 km\nEn despliegue\n\n\n\nTabla comparativa de tecnolog√≠as de acceso host-router. *Sim√©trica en teor√≠a, asim√©trica en la pr√°ctica.\n\nWiFi 6 es una tecnolog√≠a de acceso inal√°mbrico, es decir, no requiere una conexi√≥n f√≠sica entre los dispositivos. Como contrapartida a la flexibilidad de no tener el v√≠nculo f√≠sico, el alcance se ve reducido. La m√°xima distancia entre el router y el dispositivo es t√≠picamente de 30-50 metros, pero puede verse reducida por obst√°culos entre ambos. Los est√°ndares WiFi van desde el original 802.11 hasta el m√°s moderno 802.11ax (WiFi 6E), que es capaz de alcanzar velocidades te√≥ricas de hasta 9.6 Gb/s mediante m√∫ltiples antenas y t√©cnicas avanzadas. Adem√°s, en las √∫ltimas versiones se ha incrementado el ancho de banda disponible, incluyendo la banda de 6 GHz, proporcionando espectro adicional para reducir la congesti√≥n. La conexi√≥n mediante WiFi es sim√©trica en teor√≠a, aunque en la pr√°ctica las velocidades pueden variar seg√∫n las condiciones del entorno, y del hardware del router y del host. Una de las principales desventajas de los medios inal√°mbricos es que el medio de transmisi√≥n es compartido entre todos los dispositivos, lo que puede causar problemas de congesti√≥n cuando hay muchos dispositivos conectados simult√°neamente.\nPor otra parte, tenemos el acceso tipo Ethernet, que se realiza mediante un cable f√≠sico de par trenzado (que explicaremos m√°s adelante). En este caso, el alcance se extiende hasta algo menos de 100 metros. Al ser una conexi√≥n f√≠sica, generalmente no importa qu√© obst√°culos haya entre ambos puntos4. Algunas personas han intentado empalmar cables para lograr longitudes superiores a 100 metros, pero esto no funciona adecuadamente. Las causas principales son la degradaci√≥n de la se√±al y que los protocolos Ethernet est√°n dise√±ados asumiendo tiempos espec√≠ficos de propagaci√≥n en el cable5. Al ser un tipo de conexi√≥n dedicada, cuando nos conectamos por cable no tenemos problemas de congesti√≥n del medio de transmisi√≥n. Las velocidades est√°ndar actuales suelen ser de 1000 Mb/s (Gigabit Ethernet), aunque existen est√°ndares m√°s r√°pidos como 10 Gigabit Ethernet.\nFinalmente, tenemos las tecnolog√≠as de acceso m√≥vil como alternativa de conectividad. Tanto 4G LTE como 5G utilizan ondas de radio en el espectro m√≥vil licenciado para conectar dispositivos con las torres de telefon√≠a, que act√∫an como puntos de acceso a la red del operador. Su principal ventaja es el amplio alcance (varios kil√≥metros para 4G, 1-5 km para 5G seg√∫n la banda), lo que las hace ideales para ubicaciones sin infraestructura fija o como backup de conectividad. Ambas tecnolog√≠as son asim√©tricas y utilizan un medio compartido, con 4G LTE ofreciendo velocidades t√≠picas de 50/15 Mb/s y 5G alcanzando hasta 300/50 Mb/s en condiciones reales. El 5G representa una evoluci√≥n significativa al usar un espectro m√°s amplio, incluyendo frecuencias milim√©tricas, aunque presenta un compromiso entre velocidad y alcance: las frecuencias m√°s altas proporcionan mayor velocidad pero menor penetraci√≥n. Mientras 4G LTE est√° completamente desplegado, 5G se encuentra en fase de despliegue activo con cobertura variable seg√∫n ubicaci√≥n y operador6.\nAhora pasaremos a la conexi√≥n del router de borde con el siguiente router. Las tecnolog√≠as disponibles\n\n\n\n\n\n\n\n\n\n\n\n\n\nTecnolog√≠a\nMedio F√≠sico\nTipo Conexi√≥n\nSimetr√≠a\nVelocidad T√≠pica\nAlcance\nEstado 2025\n\n\n\n\nDial-up\nPar trenzado\nDedicada\nSim√©trica\n56 kb/s\nIlimitado*\nObsoleta\n\n\nDSL/VDSL\nPar trenzado\nDedicada\nAsim√©trica\n50/15 Mb/s\n&lt;3 km de central\nEn declive\n\n\nCable HFC\nCoaxial/Fibra\nCompartida\nAsim√©trica\n300/30 Mb/s\nRed local\nEstable\n\n\nFTTH PON\nFibra √≥ptica\nCompartida\nSim√©trica\n1000/1000 Mb/s\n&lt;20 km\nEn expansi√≥n\n\n\nFTTH P2P\nFibra √≥ptica\nDedicada\nSim√©trica\n10000/10000 Mb/s\n&lt;40 km\nPremium\n\n\nSatelital\nMicroondas\nCompartida\nAsim√©trica\n100/20 Mb/s\nGlobal\nNicho\n\n\n\n\nPara la conexi√≥n entre el router de borde y el siguiente router en la jerarqu√≠a de red, disponemos de diversas tecnolog√≠as WAN (Wide Area Network) que han evolucionado significativamente. Las tecnolog√≠as m√°s tradicionales como Dial-up (56 kb/s) est√°n obsoletas, mientras que DSL/VDSL (50/15 Mb/s t√≠picas) se encuentran en declive debido a sus limitaciones de distancia (&lt;3 km de la central telef√≥nica) y asimetr√≠a inherente del par trenzado. El Cable HFC (Hybrid Fiber-Coaxial) ofrece velocidades superiores (300/30 Mb/s) mediante una combinaci√≥n de fibra √≥ptica hasta el vecindario y cable coaxial hasta el hogar, aunque mantiene asimetr√≠a y medio compartido. Las tecnolog√≠as de fibra √≥ptica representan el estado del arte: FTTH PON (Fiber-to-the-Home Passive Optical Network) proporciona 1000/1000 Mb/s sim√©tricos con medio compartido y est√° en expansi√≥n activa, mientras que FTTH P2P (Point-to-Point) ofrece conexiones dedicadas de hasta 10000/10000 Mb/s para aplicaciones premium. Como alternativa para ubicaciones remotas, la conectividad satelital proporciona cobertura global con velocidades de 100/20 Mb/s, aunque con mayor latencia y asimetr√≠a, ocupando un nicho espec√≠fico donde otras tecnolog√≠as no son viables.\nFinalmente, llegamos a la √∫ltima capa, denominada el n√∫cleo de la red. El n√∫cleo de la red es una compleja jerarqu√≠a de redes interconectadas que trabajan conjuntamente para proporcionar conectividad global. Por contextualizar las tres partes de la red mencionadas hasta ahora vamos a ver un ejemplo. Sup√≥n que una persona A (host) env√≠a un mensaje (carta) a otra persona B (otro host). La persona A deposita la carta en correos, que ser√≠a el router de frontera. Todo el proceso del env√≠o de la carta desde correos (router de frontera de A) hasta llegar al buz√≥n de B (router de frontera de B) ser√≠a el n√∫cleo de la red.\nDespu√©s de haber ejemplificado su estructura, vamos a indagar en c√≥mo est√° estructurado el n√∫cleo de la red. Primeramente hablaremos de su estructura, que comentamos en la introducci√≥n tiene una estructura descentralizada, lo que permite que el sistema sea mas robusto y escalable. Los componentes de esta red que nos proporcionan interconexi√≥n con otras redes se denominan ISP (proveedores de servicio de Internet, del ingl√©s ‚ÄúInternet Service Providers‚Äù). Los ISPs se organizan en tres niveles, cada uno con caracter√≠sticas y roles espec√≠ficos en el ecosistema global de conectividad.\nLos proveedores de Nivel 1 (Tier 1 en ingl√©s) forman la √©lite de Internet, operando las redes troncales globales de m√°s alta capacidad. Estas organizaciones incluyen empresas como Cogent, AT&T, Verizon, TeliaSonera y Telef√≥nica. Los proveedores Tier 1 mantienen infraestructuras que abarcan continentes enteros con enlaces de 10-100 Gb/s y routers de rendimiento extremo capaces de procesar millones de paquetes por segundo. Entre los proveedores ISP Tier 1 se pueden mandar mensajes sin costo alguno mediante acuerdos de ‚Äúpeering‚Äù gratuito. Esto mantiene la exclusividad del estatus Tier 1, ya que se deben alcanzar acuerdos con todos los Tier 1 existentes antes de ser considerado Tier 1.\nLos ISP de Nivel 2 (Tier 2 en ingl√©s) operan redes regionales o nacionales m√°s peque√±as que se conectan a Internet a trav√©s de uno o m√°s proveedores Tier 1. Pagan a los Tier 1 por ‚Äútr√°nsito‚Äù - el servicio de llevar su tr√°fico a destinos que no pueden alcanzar directamente. Sin embargo, los Tier 2 tambi√©n establecen conexiones directas entre s√≠ cuando es mutuamente beneficioso, reduciendo los costos de tr√°nsito y mejorando el rendimiento para rutas comunes. Estos proveedores sirven como el tejido conectivo esencial de Internet, agregando tr√°fico de numerosos proveedores m√°s peque√±os y proporcionando redundancia y rutas alternativas. Su posici√≥n intermedia les permite ofrecer servicios especializados y soporte m√°s personalizado que los grandes Tier 1, mientras mantienen conexiones globales a trav√©s de sus relaciones de tr√°nsito.\nLos ISP de Nivel 3 son los proveedores de acceso que conectan directamente a usuarios finales - hogares, peque√±as empresas, y organizaciones locales. Estos proveedores compran conectividad a Internet de ISP de niveles superiores y generalmente no mantienen conexiones directas entre s√≠. Su valor radica en el conocimiento local, servicio personalizado, y la infraestructura de ‚Äú√∫ltima milla‚Äù que lleva Internet directamente a los usuarios finales.\n\n\n\n\n\ngraph TD\n    subgraph \"Tier 1 ISPs\"\n        T1A[\"Tier 1 ISP A&lt;br/&gt;Global Backbone\"]\n        T1B[\"Tier 1 ISP B&lt;br/&gt;Global Backbone\"]\n        T1C[\"Tier 1 ISP C&lt;br/&gt;Global Backbone\"]\n    end\n    \n    subgraph \"Tier 2 ISPs\"\n        T2A[\"Tier 2 ISP A&lt;br/&gt;Regional Provider\"]\n        T2B[\"Tier 2 ISP B&lt;br/&gt;Regional Provider\"]\n        T2C[\"Tier 2 ISP C&lt;br/&gt;Regional Provider\"]\n        T2D[\"Tier 2 ISP D&lt;br/&gt;Regional Provider\"]\n    end\n    \n    subgraph \"Tier 3 ISPs\"\n        T3A[\"Tier 3 ISP A&lt;br/&gt;Local Provider\"]\n        T3B[\"Tier 3 ISP B&lt;br/&gt;Local Provider\"]\n        T3C[\"Tier 3 ISP C&lt;br/&gt;Local Provider\"]\n        T3D[\"Tier 3 ISP D&lt;br/&gt;Local Provider\"]\n        T3E[\"Tier 3 ISP E&lt;br/&gt;Local Provider\"]\n        T3F[\"Tier 3 ISP F&lt;br/&gt;Local Provider\"]\n    end\n    \n    %% Tier 1 peering relationships (free exchange)\n    T1A -.-&gt;|\"Free Peering\"| T1B\n    T1B -.-&gt;|\"Free Peering\"| T1C\n    T1A -.-&gt;|\"Free Peering\"| T1C\n    \n    %% Tier 2 purchasing transit from Tier 1\n    T1A --&gt;|\"Transit (Paid)\"| T2A\n    T1A --&gt;|\"Transit (Paid)\"| T2B\n    T1B --&gt;|\"Transit (Paid)\"| T2C\n    T1C --&gt;|\"Transit (Paid)\"| T2D\n    \n    %% Tier 2 peering with other Tier 2\n    T2A -.-&gt;|\"Peering\"| T2C\n    T2B -.-&gt;|\"Peering\"| T2D\n    \n    %% Tier 3 purchasing transit from Tier 2\n    T2A --&gt;|\"Transit (Paid)\"| T3A\n    T2A --&gt;|\"Transit (Paid)\"| T3B\n    T2B --&gt;|\"Transit (Paid)\"| T3C\n    T2C --&gt;|\"Transit (Paid)\"| T3D\n    T2D --&gt;|\"Transit (Paid)\"| T3E\n    T2D --&gt;|\"Transit (Paid)\"| T3F\n    \n    %% Styling\n    classDef tier1 fill:#ff6b6b,stroke:#d63031,stroke-width:3px,color:#fff\n    classDef tier2 fill:#4ecdc4,stroke:#00b894,stroke-width:2px,color:#fff\n    classDef tier3 fill:#fdcb6e,stroke:#e17055,stroke-width:2px,color:#2d3436\n    \n    class T1A,T1B,T1C tier1\n    class T2A,T2B,T2C,T2D tier2\n    class T3A,T3B,T3C,T3D,T3E,T3F tier3",
    "crumbs": [
      "Introducci√≥n a redes",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n a las Redes de Ordenadores</span>"
    ]
  },
  {
    "objectID": "ch/part_networks/network_intro/network_intro.html#intro-network-stacks",
    "href": "ch/part_networks/network_intro/network_intro.html#intro-network-stacks",
    "title": "1¬† Introducci√≥n a las Redes de Ordenadores",
    "section": "1.4 Modelos de Referencia de Redes",
    "text": "1.4 Modelos de Referencia de Redes\nUna vez visto la parte m√°s hardware de Internet, vamos a pasar a introducir la parte software. En concreto, vamos a hablar de c√≥mo se estructura la parte software de la comunicaci√≥n en red. Primero, vamos a introducir dos conceptos software muy importantes: Las arquitecturas por capas (‚ÄúLayered architectures‚Äù) y la encapsulaci√≥n.\nLas arquitecturas por capas es una forma de estructurar una aplicaci√≥n software en capas (componentes) donde cada capa tiene una responsabilidad espec√≠fica y bien definida. Cada capa proporciona servicios a la capa superior y utiliza los servicios de la capa inferior, creando una jerarqu√≠a organizada. Esta organizaci√≥n permite que cada capa se pueda desarrollar, modificar y mantener de forma independiente, siempre que mantenga la misma interfaz con las capas adyacentes.\nEn el contexto de las redes de comunicaci√≥n, esta aproximaci√≥n arquitect√≥nica es fundamental porque permite dividir la complejidad de la comunicaci√≥n en red en problemas m√°s peque√±os y manejables. Por ejemplo, una capa puede encargarse √∫nicamente del enrutamiento de datos, mientras que otra se ocupa exclusivamente de la detecci√≥n y correcci√≥n de errores. Esta separaci√≥n de responsabilidades hace que el sistema sea m√°s modular, escalable y f√°cil de debuggear.\n\n\n\n\n\n\nTipEncapsulaci√≥n\n\n\n\nLa encapsulaci√≥n, por su parte, es el proceso mediante el cual cada capa a√±ade su propia informaci√≥n de control (headers) a los datos que recibe de la capa superior, creando una nueva unidad de datos que pasa a la capa inferior. De esta manera, cada capa trata los datos de las capas superiores como una carga √∫til (payload) a la que simplemente a√±ade su propia informaci√≥n de control, sin necesidad de entender o modificar el contenido interno de esos datos.\n\n\nBajo estos dos conceptos se definen los dos modelos m√°s importantes: el modelo OSI y el modelo TCP/IP. En la Figura¬†1.6 podemos ver los modelos OSI y TCP/IP divididos en sus diferentes capas y cu√°l es la equivalencia entre ambos.\n\n\n\n\n\n\nFigura¬†1.6: Modelos OSI y TCP/IP.\n\n\n\nEl modelo OSI, desarrollado por la Organizaci√≥n Internacional de Normalizaci√≥n (ISO) en 1984, es un modelo conceptual de siete capas que describe c√≥mo diferentes sistemas de red pueden comunicarse entre s√≠. El modelo TCP/IP, tambi√©n conocido como modelo de Internet, es el modelo pr√°ctico utilizado en Internet, desarrollado por DARPA con cuatro capas que corresponden aproximadamente a las capas OSI, pero con una estructura m√°s simple y pr√°ctica. Aunque en la pr√°ctica se usa m√°s el modelo TCP/IP, OSI sigue siendo fundamental para entender los principios de las comunicaciones de red. A continuaci√≥n, explicamos cada nivel de funcionalidad, mostrando c√≥mo se mapean entre ambos modelos:\nNivel de Aplicaci√≥n OSI: Capas 7, 6 y 5 (Aplicaci√≥n, Presentaci√≥n y Sesi√≥n) TCP/IP: Capa de Aplicaci√≥n\nEn el modelo OSI, este nivel se divide en tres capas separadas, mientras que TCP/IP las agrupa en una sola capa m√°s pr√°ctica:\n\nFuncionalidad de Aplicaci√≥n (OSI Capa 7): Es la capa m√°s cercana al usuario final. Aqu√≠ residen las aplicaciones de red como navegadores web (HTTP/HTTPS), clientes de correo electr√≥nico (SMTP, POP3, IMAP), transferencia de archivos (FTP) y servicios de nombres de dominio (DNS). Esta capa proporciona servicios directamente a las aplicaciones del usuario.\nFuncionalidad de Presentaci√≥n (OSI Capa 6): Se encarga de la traducci√≥n, cifrado y compresi√≥n de datos. Convierte los datos del formato de aplicaci√≥n al formato de red y viceversa. Maneja diferentes representaciones de datos (ASCII, EBCDIC), cifrado/descifrado y compresi√≥n/descompresi√≥n.\nFuncionalidad de Sesi√≥n (OSI Capa 5): Establece, mantiene y termina las sesiones de comunicaci√≥n entre aplicaciones. Controla los di√°logos/conexiones entre ordenadores, implementa checkpoints para recuperaci√≥n en caso de fallo y gestiona el control de acceso.\n\nEn TCP/IP, todas estas funcionalidades est√°n integradas en la Capa de Aplicaci√≥n, que incluye protocolos como HTTP/HTTPS para web, SMTP para correo electr√≥nico, FTP para transferencia de archivos, DNS para resoluci√≥n de nombres, y muchos otros que proporcionan servicios directos a los usuarios. Esta aproximaci√≥n m√°s pr√°ctica evita la complejidad de separar artificialmente funciones que a menudo est√°n estrechamente relacionadas.\nNivel de Transporte OSI: Capa 4 (Transporte) TCP/IP: Capa de Transporte Este nivel es pr√°cticamente id√©ntico en ambos modelos. Proporciona transferencia de datos confiable entre sistemas finales, maneja el control de flujo, la correcci√≥n de errores y la segmentaci√≥n/reensamblado de datos.\nLos protocolos principales son:\n\nTCP (Transmission Control Protocol): Ofrece comunicaci√≥n confiable con control de flujo, correcci√≥n de errores y garant√≠a de entrega ordenada.\nUDP (User Datagram Protocol): Ofrece comunicaci√≥n r√°pida pero sin garant√≠as de entrega, ideal para aplicaciones en tiempo real.\n\nNivel de Red/Internet OSI: Capa 3 (Red) TCP/IP: Capa de Internet\nAmbos modelos manejan esta funcionalidad de manera muy similar. Se encarga del enrutamiento de paquetes a trav√©s de m√∫ltiples redes, determinando la mejor ruta para enviar datos desde el origen hasta el destino. El protocolo principal es IP (Internet Protocol), junto con protocolos auxiliares como:\n\nICMP: Para mensajes de control y error.\nARP: Para resoluci√≥n de direcciones (en TCP/IP).\nProtocolos de enrutamiento: Como OSPF y BGP.\n\nNivel de Acceso F√≠sico OSI: Capas 2 y 1 (Enlace de Datos y F√≠sica) TCP/IP: Capa de Acceso a la Red\nEl modelo OSI separa estas funciones en dos capas distintas, mientras que TCP/IP las combina por practicidad:\n\nFuncionalidad de Enlace de Datos (OSI Capa 2): Proporciona transferencia de datos libre de errores entre nodos adyacentes. Se divide en dos subcapas: LLC (Logical Link Control) y MAC (Media Access Control). Maneja la detecci√≥n y correcci√≥n de errores a nivel de enlace y controla el acceso al medio f√≠sico.\nFuncionalidad F√≠sica (OSI Capa 1): Define las caracter√≠sticas el√©ctricas, mec√°nicas y funcionales para activar, mantener y desactivar el enlace f√≠sico. Especifica voltajes, velocidades de datos, conectores y otros aspectos del medio de transmisi√≥n (cable, fibra √≥ptica, radio).\n\nEn TCP/IP, la Capa de Acceso a la Red combina ambas funcionalidades, encarg√°ndose de la transmisi√≥n de datos en la red local espec√≠fica, incluyendo tecnologias como Ethernet, WiFi, y otros protocolos de acceso al medio.\nDiferencias Clave Entre los Modelos\n\nComplejidad: OSI tiene 7 capas vs 4 en TCP/IP, siendo OSI m√°s detallado te√≥ricamente pero TCP/IP m√°s pr√°ctico.\nUso real: TCP/IP es el modelo usado en Internet, mientras que OSI es principalmente un modelo de referencia educativo.\nFlexibilidad: TCP/IP agrupa funcionalidades relacionadas, evitando separaciones artificiales que raramente se implementan por separado en la pr√°ctica.\nEvoluci√≥n: TCP/IP evolucion√≥ con Internet, mientras que OSI fue dise√±ado como est√°ndar te√≥rico antes de su implementaci√≥n masiva.",
    "crumbs": [
      "Introducci√≥n a redes",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n a las Redes de Ordenadores</span>"
    ]
  },
  {
    "objectID": "ch/part_networks/network_intro/network_intro.html#rendimiento",
    "href": "ch/part_networks/network_intro/network_intro.html#rendimiento",
    "title": "1¬† Introducci√≥n a las Redes de Ordenadores",
    "section": "1.5 Rendimiento",
    "text": "1.5 Rendimiento\nPor √∫ltimo, vamos a cerrar esta introducci√≥n a las redes de telecomunicaciones describiendo brevemente los factores presentes en su rendimiento. Primero, vamos a conceptualizarlo con un ejemplo simplificado. Supongamos que la red de telecomunicaci√≥n es una carretera entre dos puntos y los paquetes son los veh√≠culos. ¬øC√≥mo podr√≠amos medir el rendimiento de este sistema? Las dos m√©tricas m√°s sencillas ser√≠an el tiempo en recorrer la carretera y la cantidad de veh√≠culos que pueden circular a la vez. La primera m√©trica se conoce como latencia, y est√° influenciada en nuestro ejemplo por la velocidad del medio, y la segunda se conoce como la tasa de transferencia efectiva (throughput), que ser√≠a el n√∫mero de carriles de las carreteras. El objetivo, bajo estas dos m√©tricas, ser√≠a que los veh√≠culos fueran lo m√°s r√°pido posible aprovechando todos los carriles, consiguiendo que el n√∫mero de veh√≠culos que llega sea lo m√°s alto posible.\nEl ejemplo es muy simple, pero nos ha ayudado a introducir dos conceptos clave, la latencia y el throughput. En este cap√≠tulo veremos cu√°les son los principales factores que influyen en estos dos conceptos cuando en lugar de tener una carretera, tenemos varias carreteras con conexiones entre ellas y no todos los veh√≠culos van al mismo sitio. Las conexiones entre las carreteras, es decir, las redes, se realiza a trav√©s de routers como hemos comentado en los cap√≠tulos anteriores.\nPrimero, nos vamos a centrar en el throughput, que es la cantidad de datos real que podemos transmitir por unidad de tiempo. Generalmente se mide en Mb/s o Gb/s. El throughput a veces se mide de manera instant√°nea pero tambi√©n se puede considerar como media de un periodo de tiempo. El throughput est√° limitado por el componente m√°s ‚Äúlento‚Äù en el camino entre dos puntos. Por ejemplo, si estamos descargando informaci√≥n y el medio tiene un throughput de 1Gb/s pero el servidor solo es capaz de proporcionar 100Mb/s, el throughput resultante ser√° 100Mb/s.\nUn t√©rmino asociado al throughput es el ancho de banda (bandwidth). El bandwidth es la capacidad m√°xima te√≥rica del canal de comunicaci√≥n, es decir, la cantidad m√°xima de datos que puede transmitir por unidad de tiempo en condiciones ideales. Es decir, es el l√≠mite f√≠sico. Por otra parte, el throughput como dijimos es la cantidad real que obtenemos condiciones reales.\n\n\n\n\n\n\nNota\n\n\n\nEs importante no confundir MB/s con Mb/s (u otros pares como GB/s con Gb/s). En inform√°tica se suele hablar en MB/s, es decir, MegaBytes por segundo, mientras que en telecomunicaciones se suele hablar en Mb/s. Es una diferencia importante ya que un MB/s es 8 veces m√°s velocidad que un Mb/s.\n\n\nAhora pasaremos a la latencia de red, y los factores que la definen. La latencia es el tiempo total que tarda un paquete en viajar desde el origen hasta el destino. Esta latencia no se mide √∫nicamente con el tiempo te√≥rico de propagaci√≥n por el medio, sino que es la suma de varios factores. Primero nos enfocaremos en los factores que afectan a un √∫nico paquete:\n\nRetardo de procesamiento (\\(d_{proc}\\)): El retardo de procesamiento es el tiempo que tarda un router en procesar el paquete. Esto incluye, comprobar la integridad del paquete (checksum), determinar cu√°l es el siguiente salto y otros procesos adicionales del protocolo. En los routers modernos este proceso normalmente es de microsegundos en condiciones normales, pero puede incrementarse en caso de congesti√≥n o pol√≠ticas adicionales. Este procesamiento se lleva a cabo en hardware especializado (ASICs), pero en determinadas circunstancias es posible que sea necesario inspeccionar el paquete mediante software, como por ejemplo en Deep Packet Inspection, que se suele utilizar para monitorizar la red por seguridad o para forzar pol√≠ticas Kurose y Ross (2017).\nRetardo de cola (\\(d_{queue}\\)): El retardo de cola ocurre una vez se ha procesado el paquete con su correspondiente retardo de procesamiento. En este momento, el paquete es colocado en un buffer con la informaci√≥n necesaria para determinar el siguiente salto. El retardo de cola es el tiempo que tarda el paquete en ser enviado al siguiente salto. Si hay poco tr√°fico, el retardo de cola ser√° casi nulo, en cambio, si hay mucho tr√°fico este retardo crecer√° considerablemente.\nRetardo de propagaci√≥n (\\(d_{prop}\\)): El retardo de propagaci√≥n es el tiempo que tarda en viajar un paquete por el medio, como puede ser la fibra √≥ptica o 5G, o generalmente, una combinaci√≥n de varias, ya que de un punto a otro puede haber diferentes medios. El retardo, por lo tanto, es la suma de los retardos de cada uno de los medios. El retardo de un medio, se calcula como \\(d/s\\), donde d es la longitud del medio y s es la velocidad del medio. Por contextualizar con datos las velocidades de los medios, la fibra √≥ptica y el cable coaxial tienen una velocidad (en promedio) de aproximadamente el 67% de la velocidad de la luz y en el 5G la velocidad de la luz Kurose y Ross (2017). Este retardo est√° limitado por las leyes de la f√≠sica.\n\nEstos factores afectan a un √∫nico paquete, pero generalmente cuando enviamos algo es demasiado grande como para entrar en un paquete y se divide en varios paquetes, que posteriormente se recomponen en el destino. Por lo tanto, tenemos otro tipo de retardo, que tiene en cuenta la cantidad de informaci√≥n que queremos enviar:\n\nRetardo de transmisi√≥n (\\(d_{trans}\\)): Este retardo est√° determinado por el tama√±o de la informaci√≥n que queremos enviar (L) y la velocidad del enlace (R), es decir, \\(L/R\\). Generalmente este retardo es predecible y constante, pero puede variar significativamente entre tecnolog√≠as de red. La velocidad del enlace es el throughput.\n\nUna vez definidos todos los factores, podemos expresar el retardo total como:\n\\(d_{total} = d_{proc} + d_{queue} + d_{prop} + d_{trans}\\)\nVamos a ver un ejemplo ‚Äúreal‚Äù de retardo comparando dos enlaces, uno con fibra y otro con 5G. Haremos la comparaci√≥n hasta el primer router (router de borde) incluido:\n\nRetardo de propagaci√≥n: Como comentamos previamente, el 5G se propaga a la velocidad de la luz y la fibra aproximadamente al 67% de la velocidad de la luz. Por lo tanto, el 5G es m√°s r√°pido.\nRetardo de procesamiento: En 5G tenemos retardo debido a la estaci√≥n de radio, la decodificaci√≥n y la gesti√≥n de los recursos de radio (aproximadamente unos 4ms). En cambio, en la fibra este proceso es mucho m√°s r√°pido, necesitando aproximadamente unos 0.1ms por salto. La fibra suele ser mucho m√°s r√°pida.\nRetardo de cola: A una estaci√≥n suele haber conectados cientos de dispositivos, puede haber interferencias y adem√°s tambi√©n suelen ser dependientes del clima. Un ejemplo de esto lo podr√©is haber vivido cuando est√°is en un concierto con miles de personas y no funciona bien la conexi√≥n debido a la congesti√≥n. En el caso de la fibra √≥ptica suele haber menos congesti√≥n, el n√∫mero de usuarios es predecible y los sistemas cuentan con buffers m√°s grandes y eficientes.\nRetardo de transmisi√≥n: El throughput en 5G es inferior a 1Gb/s, mientras que en fibra pueden llegar actualmente a 10 Gb/s.\n\n\n\n\n\n\n\nNotaLatencia vs Throughput\n\n\n\nLa latencia mide cu√°nto tiempo tarda en llegar la informaci√≥n y el throughput mide cu√°nta informaci√≥n puede viajar simult√°neamente por el canal de comunicaci√≥n. Volviendo al ejemplo de la carretera: la latencia ser√≠a el tiempo que tarda un veh√≠culo en recorrer toda la carretera de extremo a extremo, mientras que el throughput ser√≠a la cantidad total de veh√≠culos que pueden pasar por la carretera en un periodo determinado (relacionado con el n√∫mero de carriles y la densidad de tr√°fico).\n\n\nUn concepto asociado a la latencia de suma importancia en las aplicaciones en red, especialmente los juegos interactivos es el jitter. Cuando enviamos varios paquetes podemos calcular una latencia promedio, ya que no todos los paquetes tardar√°n lo mismo debido a las condiciones de red y diferentes rutas. En aplicaciones altamente interactivas tener una latencia promedio baja es indispensable. Sin embargo, considera este peque√±o ejemplo donde se env√≠an 4 paquetes.\n\nEscenario 1: Los paquetes tardan 50ms, 52ms, 48ms, 51ms\nEscenario 2: Los paquetes tardan 28ms, 68ms, 43ms, 62ms.\n\nEn ambos escenarios los paquetes tienen una latencia promedio de 50.25ms. Sin embargo, la variaci√≥n entre los paquetes es elevada. En el primer caso, la variaci√≥n es de 1.48ms mientras que en el segundo es de 15.82ms. Esta variabilidad se conoce como jitter. Un jitter alto puede ocasionar voz entrecortada o saltos en videoconferencias o degradaci√≥n de la calidad en videojuegos. En el caso de los videojuegos, se suelen utilizar buffers para realizar interpolaciones de los elementos de red y as√≠ tener un juego m√°s fluido.\nFinalmente, vamos a ver un √∫ltimo factor que no se ajusta a los anteriores. Hasta ahora hemos asumido que todos los paquetes que enviamos llegan correctamente a su destinatario. Pero esto no es siempre cierto. Por ejemplo, si un router est√° congestionado y tiene su buffer lleno, descartar√° los paquetes. Si un paquete se corrompe debido a alteraciones (e.g., campos electromagn√©ticos, radiaci√≥n solar7) un router de tr√°nsito lo podr√° descartar. Esto forma parte del protocolo de Internet. Otros protocolos, en capas superiores como por ejemplo TCP, tienen en cuenta estas situaciones y reenv√≠an el paquete cuando determinan que no ha llegado a su destino.\nAplicaciones Pr√°cticas: Videojuegos Cuando estamos dise√±ando aplicaciones en red tenemos que tener en cuenta estos retardos, pues pueden hacer nuestra aplicaci√≥n inutilizable. En el caso de los videojuegos, los requisitos de retardo m√°ximo vendr√°n dados dependiendo del tipo de juego, por ejemplo Claypool y Claypool (2006):\n\nReal-Time Strategy (RTS): Tolerancia media (100-200ms) debido a su naturaleza estrat√©gica.\nTurn-Based Games: Tolerancia alta (500ms+) debido a que los turnos son discretos.\nFirst-Person Shooters (FPS): Baja tolerancia (20-50ms) para juegos competitivos.\nFighting Games: Tolerancia muy baja (1-3 frames, ~16-50ms).\nRacing Games: Tolerancia baja o moderada (50-100ms) dependiendo del realismo.\nMMORPGs: Tolerancia variable dependiendo de la actividad, por ejemplo combates vs social.\n\nEstos tiempos se miden en RTT (Round Trip Time), que involucra el tiempo entre que se manda el mensaje, se procesa en el servidor, y obtenemos la respuesta de vuelta en el cliente.\n\n\n\n\nAnalytics, IoT. 2020. ¬´Internet of Things (IoT) and non-IoT active device connections worldwide from 2010 to 2025 (in billions)¬ª. Statista. https://www.statista.com/statistics/1101442/iot-number-of-connected-devices-worldwide/.\n\n\nBBC Brasil. 2019. ¬´[Image from: Article Title]¬ª. https://www.bbc.com/portuguese/geral-50162526.\n\n\nClaypool, Mark, y Kajal Claypool. 2006. ¬´Latency and player actions in online games¬ª. Commun. ACM 49 (11): 40-45. https://doi.org/10.1145/1167838.1167860.\n\n\nKurose, James F., y Keith W. Ross. 2017. Computer Networks: A Top-Down Approach. 7.¬™ ed. Boston, MA: Pearson.\n\n\nRitchie, Hannah, Edouard Mathieu, Max Roser, y Esteban Ortiz-Ospina. 2023. ¬´Internet¬ª. Our World in Data. https://ourworldindata.org/internet.",
    "crumbs": [
      "Introducci√≥n a redes",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n a las Redes de Ordenadores</span>"
    ]
  },
  {
    "objectID": "ch/part_networks/network_intro/network_intro.html#footnotes",
    "href": "ch/part_networks/network_intro/network_intro.html#footnotes",
    "title": "1¬† Introducci√≥n a las Redes de Ordenadores",
    "section": "",
    "text": "Enrutamiento es una adaptaci√≥n al espa√±ol del t√©rmino ingl√©s routing. Aunque no est√° reconocida oficialmente por la RAE (2025) y el t√©rmino normativo ser√≠a encaminamiento, en estos apuntes se utilizar√° enrutamiento por ser la forma m√°s habitual en el √°mbito de las redes y telecomunicaciones.‚Ü©Ô∏é\nAlgunos componentes de Internet tienen una arquitectura h√≠brida, como los ISPs grandes y DNS.‚Ü©Ô∏é\nLos routers comparten y propagan informaci√≥n de congesti√≥n y destinos disponibles con los routers adyacentes.‚Ü©Ô∏é\nT√©cnicamente s√≠ pueden afectar ciertos factores, por ejemplo, campos magn√©ticos intensos o interferencias electromagn√©ticas sobre el cable Ethernet.‚Ü©Ô∏é\nLa resistencia del cable se incrementa linealmente con la distancia, aumenta la probabilidad de interferencias electromagn√©ticas, y se degrada la relaci√≥n se√±al-ruido, entre otros factores.‚Ü©Ô∏é\nEl rendimiento de ambas tecnolog√≠as puede degradarse significativamente en √°reas de alta densidad poblacional o durante horas pico debido a la congesti√≥n del medio compartido.‚Ü©Ô∏é\nLa radiaci√≥n c√≥smica produce cambios de bits en dispositivos electr√≥nicos, que se denominan SEU (Single Event Upset). Estos cambios suelen afectar a las DRAM, SRAM y ASICs. Contrario a la intuici√≥n, es algo relativamente frecuente, y ocurre con una tasa aproximada de 1 error por cada 256MB por d√≠a a nivel del mar. Cuanto m√°s altitud (o dicho de otra forma, m√°s cerca del espacio), esta tasa se incrementa considerablemente. A nivel de red esto suele ocurrir en los routers.‚Ü©Ô∏é",
    "crumbs": [
      "Introducci√≥n a redes",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n a las Redes de Ordenadores</span>"
    ]
  },
  {
    "objectID": "ch/part_networks/access_layer/access_layer.html",
    "href": "ch/part_networks/access_layer/access_layer.html",
    "title": "2¬† Capa de Acceso a la Red",
    "section": "",
    "text": "2.1 Funciones principales de la Capa de Acceso a la Red\nLa Capa de Acceso a la Red se encarga de la transmisi√≥n f√≠sica de datos entre dispositivos directamente conectados en una red local, manejando tanto los aspectos f√≠sicos de la transmisi√≥n como el control de acceso al medio compartido. Esta capa combina las funciones de las capas f√≠sica y de enlace de datos del modelo OSI, proporcionando una interfaz entre los protocolos de red de nivel superior y el hardware de red espec√≠fico. Su principal responsabilidad es garantizar que los datos puedan transmitirse de manera confiable entre nodos adyacentes en la red.\nEl cap√≠tulo se divide en un apartado donde veremos las principales funciones de la red y despu√©s veremos los protocolos definidos en esta capa. Para guiar el aprendizaje, antes veremos un ejemplo del funcionamiento de la Capa de Acceso a Red. No os preocup√©is si no entend√©is por ahora todos los conceptos, los iremos viendo a lo largo de este cap√≠tulo.\nConsideremos una red Ethernet t√≠pica con un switch central conectando cuatro computadoras (A, B, C, D) con las siguientes direcciones MAC:\nComo ejemplo, vamos a ver los pasos para el env√≠o de un mensaje desde A a C. Pod√©is ver la representaci√≥n en un diagrama de secuencia en la Figura¬†2.1. Los pasos ser√≠an los siguientes:\nLa Capa de Acceso a la Red desempe√±a m√∫ltiples funciones cr√≠ticas que trabajan en conjunto para garantizar una comunicaci√≥n eficiente y confiable entre dispositivos en la red local.",
    "crumbs": [
      "Introducci√≥n a redes",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Capa de Acceso a la Red</span>"
    ]
  },
  {
    "objectID": "ch/part_networks/access_layer/access_layer.html#funciones-principales-de-la-capa-de-acceso-a-la-red",
    "href": "ch/part_networks/access_layer/access_layer.html#funciones-principales-de-la-capa-de-acceso-a-la-red",
    "title": "2¬† Capa de Acceso a la Red",
    "section": "",
    "text": "2.1.1 Control de Acceso al Medio (MAC)\nLa funci√≥n de control de acceso al medio (MAC) es fundamental para coordinar c√≥mo m√∫ltiples dispositivos comparten un medio de transmisi√≥n com√∫n. Esta funci√≥n implementa diversos algoritmos y protocolos seg√∫n la tecnolog√≠a de red utilizada. Su eficiencia determina directamente el rendimiento y la escalabilidad de toda la red local. En redes Ethernet tradicionales de half-duplex (s√≥lo pueden transmitir en una direcci√≥n a la vez), los dispositivos emplean el m√©todo CSMA/CD (Carrier Sense Multiple Access with Collision Detection), donde primero escuchan el medio antes de transmitir para verificar que est√© libre, permiten que m√∫ltiples dispositivos accedan al mismo medio compartido, y detectan colisiones durante la transmisi√≥n implementando algoritmos de backoff exponencial para programar retransmisiones inteligentes.\nLas redes inal√°mbricas, por el contrario, utilizan CSMA/CA (Carrier Sense Multiple Access with Collision Avoidance) debido a que la detecci√≥n de colisiones es impr√°ctica en el medio radioel√©ctrico. En este esquema, los dispositivos esperan un tiempo aleatorio antes de transmitir para reducir la probabilidad de colisiones, utilizan mecanismos de acknowledgment para confirmar que la transmisi√≥n fue recibida correctamente, e implementan el protocolo RTS/CTS (Request to Send/Clear to Send) para resolver el problema del nodo oculto donde algunos dispositivos no pueden detectar las transmisiones de otros.\nComplementariamente, los mecanismos de control de flujo evitan que transmisores r√°pidos saturen receptores m√°s lentos mediante t√©cnicas como Pause Frames en Ethernet full-duplex (se puede transmitir en ambas direcciones a la vez) que permiten al receptor solicitar pausas temporales, buffer management en switches para absorber r√°fagas de tr√°fico sin p√©rdida de datos, y rate limiting para controlar din√°micamente la velocidad de transmisi√≥n seg√∫n las condiciones de la red.\n\n\n2.1.2 Direccionamiento F√≠sico\nEl direccionamiento f√≠sico opera a nivel de hardware y es independiente de los protocolos de capa superior. Utiliza direcciones MAC √∫nicas para identificar cada interfaz de red en el segmento local. Este sistema de direccionamiento es esencial para la entrega precisa de tramas entre dispositivos directamente conectados. Las direcciones MAC son como el DNI del dispositivo, son √∫nicas, est√°ticas y cada dispositivo tiene una. Est√°n formadas por 48 bits siguen una estructura espec√≠fica donde los primeros 24 bits constituyen el OUI (Organizationally Unique Identifier) asignado por IEEE a cada fabricante, los √∫ltimos 24 bits forman el identificador √∫nico del dispositivo asignado por el fabricante, y bits especiales indican si la direcci√≥n es individual o grupal y si est√° administrada universalmente o localmente. Las MAC se representan mediante octetos 6 octetos separados por dos ‚Äú:‚Äù, como por ejemplo ‚Äú00:1A:2B:3C:4D:5E‚Äù.\n\n\n\n\n\n\nTipDirecci√≥n MAC\n\n\n\nUna direcci√≥n MAC es un identificador √∫nico asignado a cada tarjeta de red. Est√°n formados por 48 bits donde la primera parte identifica al fabricante, despu√©s el dispositivo dentro del fabricante, y por √∫ltimo tiene unos bits especiales.\n\n\nEl sistema soporta tres tipos principales de direccionamiento: unicast para comunicaci√≥n dirigida a un √∫nico dispositivo espec√≠fico, broadcast utilizando la direcci√≥n especial FF:FF:FF:FF:FF:FF para alcanzar todos los dispositivos del segmento simult√°neamente, y multicast para dirigir tr√°fico a grupos espec√≠ficos de dispositivos identificados por el primer bit configurado en 1.\n\n\n2.1.3 Detecci√≥n y Correcci√≥n de Errores\nEsta funci√≥n garantiza la integridad de los datos transmitidos a trav√©s del medio f√≠sico. Implementa algoritmos como C√≥digos de Redundancia C√≠clica (CRC) para detectar errores de transmisi√≥n y mecanismos de retransmisi√≥n cuando es necesario. Sin esta funci√≥n, los datos corruptos podr√≠an propagarse por la red causando problemas de comunicaci√≥n. Los c√≥digos de CRC son ampliamente utilizados y generan un polinomio matem√°tico basado en los datos originales, agregan el resultado como Frame Check Sequence (FCS) al final de cada trama, y permiten al receptor recalcular el CRC para compararlo con el recibido, detectando efectivamente errores de un solo bit y muchos errores de m√∫ltiples bits. Para aplicaciones menos cr√≠ticas existen checksums simples que realizan una suma aritm√©tica de todos los bytes de datos, son menos robustos que CRC pero requieren menos procesamiento computacional.\nLas t√©cnicas m√°s avanzadas incluyen Forward Error Correction (FEC) que no solo detecta sino que corrige errores autom√°ticamente, utiliza c√≥digos como Hamming para correcci√≥n de errores de un solo bit y Reed-Solomon para errores en r√°fagas, y es especialmente importante en medios inal√°mbricos donde la interferencia y las condiciones ambientales pueden causar errores frecuentes.\n\n\n2.1.4 Control de tama√±o\nEsta funci√≥n maneja las limitaciones de tama√±o impuestas por diferentes tecnolog√≠as de red. Cada tecnolog√≠a de red define un Maximum Transmission Unit (MTU) espec√≠fico que determina el tama√±o m√°ximo de datos que puede transportar una sola trama, donde Ethernet maneja 1500 bytes de datos, Token Ring t√≠picamente 4464 bytes, FDDI 4352 bytes, y PPP sobre enlaces seriales utiliza valores variables aunque com√∫nmente 1500 bytes para mantener compatibilidad. Cuando los datos de capas superiores exceden el MTU disponible, la Capa de Acceso a la Red descarta autom√°ticamente el paquete.\n\n\n2.1.5 Sincronizaci√≥n y Temporizaci√≥n\nEsta funci√≥n coordina el timing entre dispositivos para asegurar la correcta interpretaci√≥n de las se√±ales digitales. Establece marcos de tiempo comunes para la transmisi√≥n y recepci√≥n de datos. Es especialmente cr√≠tica en redes de alta velocidad donde peque√±as diferencias de timing pueden causar errores de comunicaci√≥n. La sincronizaci√≥n de reloj es esencial para el funcionamiento correcto de cualquier comunicaci√≥n digital, abarcando la sincronizaci√≥n de bit para determinar precisamente los l√≠mites temporales de cada bit transmitido, la sincronizaci√≥n de trama para identificar inequ√≠vocamente el inicio y fin de cada trama de datos, y la sincronizaci√≥n de s√≠mbolo necesaria en modulaciones complejas como QAM donde m√∫ltiples bits se codifican en un solo s√≠mbolo.\n\n\n2.1.6 Gesti√≥n de Topolog√≠a\nEsta funci√≥n se encarga de descubrir y mantener informaci√≥n sobre la estructura f√≠sica de la red. Implementa protocolos para detectar enlaces, prevenir bucles y optimizar rutas de comunicaci√≥n. Permite que la red se adapte autom√°ticamente a cambios en la topolog√≠a como fallos de enlaces o adici√≥n de nuevos dispositivos. El mantenimiento continuo de enlaces se logra mediante mensajes de tipo keepalive que detectan proactivamente fallos de enlace antes de que afecten el tr√°fico de usuarios. Los protocolos de detecci√≥n de topolog√≠a como CDP (Cisco Discovery Protocol) y LLDP (Link Layer Discovery Protocol) permiten que los dispositivos se identifiquen mutuamente y compartan informaci√≥n sobre sus capacidades, mientras que Spanning Tree Protocol previene bucles peligrosos en topolog√≠as redundantes que podr√≠an causar tormentas de broadcast.\n\n\n2.1.7 Control de Calidad de Servicio (QoS)\nEsta funci√≥n prioriza diferentes tipos de tr√°fico seg√∫n su importancia y requisitos de rendimiento. Es fundamental para el funcionamiento adecuado de aplicaciones en tiempo real como voz y v√≠deo. Esto se logra implementando mecanismos de gesti√≥n de buffers y scheduling para garantizar que aplicaciones cr√≠ticas reciban el ancho de banda necesario, y se realiza bajo est√°ndares de clasificaci√≥n. Los mecanismos de gesti√≥n de buffers aseguran que diferentes tipos de tr√°fico reciban el tratamiento apropiado mediante Weighted Fair Queuing que asigna recursos proporcionalmente seg√∫n la importancia de cada clase de tr√°fico, priority queuing que garantiza que el tr√°fico m√°s cr√≠tico siempre tenga precedencia sobre tr√°fico menos importante, y Random Early Detection que previene congesti√≥n descartando proactivamente paquetes menos cr√≠ticos antes de que los buffers se saturen completamente.",
    "crumbs": [
      "Introducci√≥n a redes",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Capa de Acceso a la Red</span>"
    ]
  },
  {
    "objectID": "ch/part_networks/access_layer/access_layer.html#dispositivos-de-la-capa-de-acceso-a-la-red",
    "href": "ch/part_networks/access_layer/access_layer.html#dispositivos-de-la-capa-de-acceso-a-la-red",
    "title": "2¬† Capa de Acceso a la Red",
    "section": "2.2 Dispositivos de la Capa de Acceso a la Red",
    "text": "2.2 Dispositivos de la Capa de Acceso a la Red\nLos switches son dispositivos de red que operan en la Capa de Acceso a la Red, espec√≠ficamente en la subcapa de enlace de datos. Funcionan como elementos centrales que conectan m√∫ltiples dispositivos en una red local, creando dominios de colisi√≥n separados para cada puerto. Es decir, que la informaci√≥n de dispositivos conectados por diferentes puertos no colisiona entre s√≠, ya que no est√°n en el mismo medio. Estos dispositivos evolucionaron desde los bridges tradicionales (que conectaban solo 2-4 segmentos) hasta reemplazar los hubs tradicionales, donde todos los puertos operaban igual con colisiones frecuentes a un sistema donde cada puerto opera independientemente con capacidades full-duplex que permiten transmisi√≥n y recepci√≥n simult√°nea, duplicando efectivamente el ancho de banda disponible. Su importancia radica en funcionalidades clave como el aprendizaje autom√°tico de direcciones MAC donde construyen din√°micamente tablas que asocian cada direcci√≥n con su puerto espec√≠fico, el reenv√≠o selectivo que env√≠a tramas √∫nicamente al puerto de destino reduciendo tr√°fico innecesario.\nLos switches se categorizan principalmente en dos tipos seg√∫n sus capacidades de gesti√≥n:\n\nno gestionados: son plug-and-play y se utilizan generalmente en redes peque√±as y dom√©sticas.\ngestionados: ofrecen un control m√°s granular y m√°s capacidades, como seguridad, monitorizaci√≥n y medidas QoS.\n\nLos puntos de acceso son dispositivos fundamentales para la conectividad inal√°mbrica en la Capa de Acceso a la Red que act√∫an como traductores entre medios cableados e inal√°mbricos, manejan la asociaci√≥n y autenticaci√≥n de dispositivos inal√°mbricos, e implementan CSMA/CA para coordinar el acceso al medio y evitar colisiones en el espectro radioel√©ctrico compartido.\nLos repetidores extienden el alcance de las redes regenerando se√±ales digitales sin filtrar tr√°fico ni reducir colisiones, simplemente reciben, amplifican y retransmiten las se√±ales para superar las limitaciones de distancia de los medios f√≠sicos. Los amplificadores incluyen RF amplifiers que aumentan la potencia de se√±ales inal√°mbricas y optical amplifiers que amplifican se√±ales en fibra √≥ptica sin conversi√≥n el√©ctrica, todos debiendo cumplir estrictas regulaciones de potencia de transmisi√≥n para evitar interferencia con otros sistemas.\nLos conversores de medio facilitan la interoperabilidad convirtiendo entre diferentes medios f√≠sicos como fibra √≥ptica y cobre, adaptando autom√°ticamente velocidades, y permitiendo extensi√≥n de redes existentes o migraci√≥n gradual a tecnolog√≠as m√°s avanzadas.\nTabla de resumen:\n\n\n\n\n\n\n\n\n\nDispositivo\nFunci√≥n Principal\nCaracter√≠sticas Clave\nAplicaci√≥n T√≠pica\n\n\n\n\nSwitches No Gestionados\nConectividad b√°sica LAN\nPlug-and-play, aprendizaje MAC autom√°tico, full-duplex\nRedes peque√±as y dom√©sticas\n\n\nSwitches Gestionados\nConectividad LAN avanzada\nVLANs, QoS, SNMP, seguridad 802.1X, port mirroring\nRedes empresariales\n\n\nPuntos de acceso\nConectividad inal√°mbrica\nCSMA/CA, traducci√≥n cableado-wireless, beamforming\nRedes Wi-Fi empresariales\n\n\nRepetidores\nExtensi√≥n de alcance\nRegeneraci√≥n de se√±al, sin filtrado\nSuperaci√≥n de l√≠mites de distancia\n\n\nAmplificadores\nAmplificaci√≥n de se√±al\nAumento de potencia RF/√≥ptica\nEnlaces de larga distancia\n\n\nConversores de medio\nConversi√≥n de medios\nFibra ‚ÜîÔ∏é cobre, adaptaci√≥n de velocidades\nMigraci√≥n gradual, extensi√≥n\n\n\nModulador\nConectividad modular\nSFP/SFP+/QSFP, intercambiables\nFlexibilidad en tipos de conexi√≥n",
    "crumbs": [
      "Introducci√≥n a redes",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Capa de Acceso a la Red</span>"
    ]
  },
  {
    "objectID": "ch/part_networks/access_layer/access_layer.html#protocolos",
    "href": "ch/part_networks/access_layer/access_layer.html#protocolos",
    "title": "2¬† Capa de Acceso a la Red",
    "section": "2.3 Protocolos",
    "text": "2.3 Protocolos\n\n2.3.1 Ethernet (IEEE 802.3)\nEthernet es el protocolo dominante en redes cableadas locales. Define tanto el formato de las tramas como los m√©todos de acceso al medio. Su √©xito radica en la simplicidad de implementaci√≥n, la robustez del dise√±o, y la capacidad de evolucionar continuamente para satisfacer las demandas crecientes de ancho de banda en entornos empresariales y dom√©sticos. Al principio en Ethernet se ten√≠a una arquitectura de medio compartida, y por ello, se ten√≠an que utilizar t√©cnicas como CSMA/CD para minimizar colisiones. Esto hac√≠a que eficiencia de la red disminuyese. Con la llegada de los bridges y switches, se introdujo una topolog√≠a de estrella, donde todos est√°n conectados al switch y este crea dominios de colisi√≥n independientes, volviendo innecesario el CSMA/CD y mejorando considerablemente la eficiencia de la red.\nLa estructura de las tramas Ethernet sigue un formato estandarizado que garantiza la interoperabilidad entre dispositivos de diferentes fabricantes. Cada trama comienza con un pre√°mbulo de 8 bytes que proporciona sincronizaci√≥n entre el transmisor y receptor, estableciendo el timing necesario para la correcta interpretaci√≥n de los bits que siguen. Las direcciones MAC de destino y origen, de 6 bytes cada una, identifican inequ√≠vocamente los dispositivos involucrados en la comunicaci√≥n, mientras que el campo Tipo/Longitud de 2 bytes especifica qu√© protocolo de capa superior procesa los datos o la longitud de la carga √∫til cuando es menor a 1536 bytes. El contenido √∫til reside en el campo de data/payload que puede contener entre 46 y 1500 bytes de informaci√≥n √∫til, con padding autom√°tico cuando los datos son menores al m√≠nimo requerido, y finalmente el Frame Check Sequence de 4 bytes implementa detecci√≥n de errores CRC permitiendo al receptor verificar la integridad de toda la trama recibida.\n\n\n\n\n\n\n\n\npacket-beta\n    0-63: \"Pre√°mbulo (8 bytes) - Sincronizaci√≥n\"\n    64-111: \"Direcci√≥n MAC Destino (6 bytes)\"\n    112-159: \"Direcci√≥n MAC Origen (6 bytes)\"\n    160-175: \"Tipo/Longitud (2 bytes)\"\n    176-191: \"Data/Payload\"\n    192-207: \"(46-1500 bytes)\"\n    208-223: \"Frame Check Sequence\"\n    224-255: \"FCS - CRC (4 bytes)\"\n\n\n\n\n\n\n\n\nFigura¬†2.2: Cabeceras de un paquete de Ethernet.\n\n\n\nLa evoluci√≥n de Ethernet ha sido extraordinaria, comenzando con 10Base-T que maneja 10 Mbps sobre cable trenzado CAT3/5, evolucionando hasta 10GBase-T con 10 Gbps sobre CAT6A/7. En contextos intensivas, o en nodos centrales, se cuenta con implementaciones de mayor velocidad. Todo esto se ha conseguido a trav√©s de diferentes estandares de modelos f√≠sicos y la mejora de rendimiento en el hardware. Tambi√©n se ha vuelto posible combinar la transmisi√≥n de datos y energ√≠a el√©ctrica por un mismo cable, simplificando los dispositivos de red.\n\n\n\n\n\n\nNotaLimite de longitud\n\n\n\nEn los cables de pares trenzados hechos de cobre el l√≠mite m√°ximo de trasmisi√≥n es de 100 metros. Es decir, que cada 100 metros hay que a√±adir un dispositivo de red que regenere la se√±al, como switches o repetidores, para evitar la degradaci√≥n y p√©rdida de datos. Esta limitaci√≥n se debe a la atenuaci√≥n de la se√±al y la interferencia electromagn√©tica que se acumulan con la distancia. Para superar esta restricci√≥n se utilizan alternativas como fibra √≥ptica (alcanza kil√≥metros sin regeneraci√≥n), extensores Ethernet (hasta 300m), o tecnolog√≠as inal√°mbricas. En entornos empresariales, esto determina la ubicaci√≥n estrat√©gica de closets de telecomunicaciones en la arquitectura de red.\n\n\n\n\n2.3.2 Wi-Fi (IEEE 802.11)\nEl protocolo Wi-Fi maneja la comunicaci√≥n inal√°mbrica y debe lidiar con desaf√≠os √∫nicos como la interferencia y la movilidad de dispositivos. A diferencia de las redes cableadas donde el medio f√≠sico est√° claramente definido y controlado, las redes inal√°mbricas operan en un espectro electromagn√©tico compartido donde m√∫ltiples factores pueden afectar la calidad de la transmisi√≥n. Esta complejidad ha llevado al desarrollo de sofisticados mecanismos de control y t√©cnicas avanzadas de modulaci√≥n que permiten comunicaciones confiables incluso en entornos con alta densidad de dispositivos. Uno de los m√©todos principales es la utilizaci√≥n de CSMA/CA (Carrier Sense Multiple Access with Collision Avoidance).\nLa trama Wi-Fi (802.11) es considerablemente m√°s compleja que Ethernet debido a los desaf√≠os √∫nicos del medio inal√°mbrico. El Frame Control contiene informaci√≥n cr√≠tica sobre el tipo de trama, versi√≥n del protocolo, y flags especiales para funciones como gesti√≥n de energ√≠a y fragmentaci√≥n. El campo Duration/ID implementa el mecanismo de reserva virtual del medio, permitiendo que otros dispositivos sepan cu√°nto tiempo estar√° ocupado el canal. La caracter√≠stica m√°s distintiva son las m√∫ltiples direcciones MAC (hasta 4) que manejan la complejidad de las redes inal√°mbricas. Address 1 identifica al receptor inmediato, Address 2 al transmisor inmediato, Address 3 proporciona filtrado adicional (a menudo el BSSID del punto de acceso), y Address 4 se utiliza √∫nicamente en sistemas de distribuci√≥n inal√°mbrica cuando los access points se comunican entre s√≠. Los campos opcionales reflejan la evoluci√≥n del est√°ndar: QoS Control permite priorizaci√≥n de tr√°fico para aplicaciones sensibles al tiempo, HT Control habilita caracter√≠sticas de alto rendimiento como MIMO y beamforming, y el Sequence Control maneja la ordenaci√≥n de tramas y detecci√≥n de duplicados, cr√≠tico en un medio donde las transmisiones pueden perderse o duplicarse debido a interferencia.\n\n\n\n\n\n\n\n\npacket-beta\n    0-15: \"Frame Control (2 bytes)\"\n    16-31: \"Duration/ID (2 bytes)\"\n    32-79: \"Address 1 - Receiver (6 bytes)\"\n    80-127: \"Address 2 - Transmitter (6 bytes)\"\n    128-175: \"Address 3 - BSSID/Filter (6 bytes)\"\n    176-191: \"Sequence Control (2 bytes)\"\n    192-239: \"Address 4 (6 bytes) - Optional\"\n    240-255: \"QoS Control (2 bytes) - Optional\"\n    256-287: \"HT Control (4 bytes) - Optional\"\n    288-319: \"Data Payload\"\n    320-335: \"(0-2304 bytes)\"\n    336-367: \"Frame Check Sequence\"\n    368-383: \"FCS - CRC (4 bytes)\"\n\n\n\n\n\n\n\n\nFigura¬†2.3: Cabeceras de un paquete Wi-Fi\n\n\n\nAl igual que en Ethernet, la evoluci√≥n de Wi-Fi ha sido enorme. Los primeros est√°ndares, 802.11n (Wi-Fi 4), contaban con velocidades de hasta 600 Mbps, mientras que Wi-Fi 7 (802.11be) promete hasta 46 Gbps. Las mejoras se han enfocado en t√©cnicas para reducir interferencias entre redes y colisiones entre dispositivos, y la inclusi√≥n de m√°s bandas:\n\n2.4 GHz: mayor alcance y penetraci√≥n, pero menor velocidad.\n5 GHz: mayor velocidad pero menor alcance.\n6 GHz: mejor rendimiento, aunque requiere de hardware espec√≠fico y tiene el mejor alcance.\n\n\n\n2.3.3 Point-to-Point Protocol (PPP)\nPPP se utiliza para conexiones directas entre dos dispositivos, com√∫nmente en enlaces seriales y conexiones de acceso telef√≥nico. Este protocolo fue dise√±ado espec√≠ficamente para superar las limitaciones de protocolos m√°s antiguos como SLIP (Serial Line Internet Protocol), proporcionando un marco robusto y flexible para comunicaciones punto a punto. Aunque su uso ha disminuido con la proliferaci√≥n de tecnolog√≠as de banda ancha, PPP sigue siendo relevante en conexiones de respaldo, enlaces satelitales, y ciertas implementaciones de VPN donde se requiere control granular sobre la conexi√≥n. PPP utiliza un formato de trama mucho m√°s simple que Ethernet o Wi-Fi, reflejando su naturaleza punto a punto donde no hay necesidad de direccionamiento complejo, permitiendo un procesamiento eficiente en enlaces de baja velocidad y dispositivos con recursos limitados.\nLas caracter√≠sticas avanzadas de PPP lo distinguen de protocolos m√°s simples al integrar detecci√≥n y correcci√≥n de errores que garantizan la integridad de los datos transmitidos incluso en enlaces propensos a interferencia, capacidades de autenticaci√≥n mediante PAP (Password Authentication Protocol) o el m√°s seguro CHAP (Challenge Handshake Authentication Protocol), y configuraci√≥n autom√°tica de direcciones IP que negocia din√°micamente par√°metros de red eliminando la necesidad de configuraci√≥n manual en ambos extremos.\n\n\n2.3.4 Frame Relay\nFrame Relay es un protocolo de capa de enlace utilizado en redes WAN que proporciona conexiones virtuales entre sitios remotos. Frame Relay fue desarrollado como una evoluci√≥n m√°s eficiente de X.25, eliminando muchas de las verificaciones y controles redundantes que hac√≠an lento al protocolo anterior. Aunque ha sido en gran medida reemplazado por tecnolog√≠as m√°s modernas como MPLS y VPN sobre Internet, Frame Relay estableci√≥ conceptos fundamentales de redes WAN que siguen siendo relevantes en tecnolog√≠as contempor√°neas.\nLa arquitectura de Frame Relay se basa en conmutaci√≥n de tramas utilizando identificadores de circuito virtual que permiten m√∫ltiples conexiones l√≥gicas sobre una sola interfaz f√≠sica, simplificando la gesti√≥n de conectividad entre m√∫ltiples sitios remotos. El protocolo implementa un control de congesti√≥n sofisticado.\n\n\n2.3.5 Address Resolution Protocol (ARP)\nARP es fundamental para la operaci√≥n de redes IP sobre Ethernet, proporcionando la traducci√≥n entre direcciones IP (Capa de Red) y direcciones MAC (Capa de Acceso a la Red). Este protocolo resuelve uno de los problemas m√°s b√°sicos pero cr√≠ticos en redes: c√≥mo traducir direcciones l√≥gicas que los humanos y aplicaciones entienden f√°cilmente a direcciones f√≠sicas que el hardware de red requiere para la transmisi√≥n real.\nEl proceso ARP opera mediante un mecanismo de solicitud y respuesta que minimiza el tr√°fico de red mientras proporciona la informaci√≥n necesaria. Cuando un dispositivo necesita comunicarse con otro pero solo conoce su direcci√≥n IP, env√≠a un ARP Request como broadcast preguntando ‚Äú¬øQui√©n tiene la IP X.X.X.X?‚Äù a todos los dispositivos del segmento local. El dispositivo que posee esa direcci√≥n IP espec√≠fica responde con un ARP Reply unicast que incluye su direcci√≥n MAC, permitiendo al solicitante establecer la asociaci√≥n necesaria. Para optimizar el rendimiento, estas asociaciones IP-MAC se almacenan en una cach√© ARP local con temporizadores que eliminan autom√°ticamente entradas obsoletas, evitando repetir el proceso de resoluci√≥n para comunicaciones frecuentes.\nARP soporta m√∫ltiples modalidades de operaci√≥n que se adaptan a diferentes necesidades de red y escenarios operativos. ARP Est√°tico permite crear entradas manuales permanentes que nunca expiran, √∫til para dispositivos cr√≠ticos como gateways y servidores donde se requiere m√°xima predictibilidad. ARP Din√°mico constituye el modo normal de operaci√≥n donde las entradas se aprenden autom√°ticamente con tiempo de vida configurable, balanceando eficiencia con actualizaci√≥n autom√°tica cuando los dispositivos cambian.",
    "crumbs": [
      "Introducci√≥n a redes",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Capa de Acceso a la Red</span>"
    ]
  },
  {
    "objectID": "ch/part_networks/network_layer/network_layer.html",
    "href": "ch/part_networks/network_layer/network_layer.html",
    "title": "3¬† Capa de red",
    "section": "",
    "text": "3.1 Funciones Fundamentales de la Capa de Red\nLa capa de red es el segundo nivel del modelo de capas TCP/IP y forma el n√∫cleo del sistema de comunicaciones de Internet. Su principal funci√≥n es proporcionar una comunicaci√≥n end-to-end entre dispositivos, potencialmente separados por m√∫ltiples redes intermedias, independientemente de la tecnolog√≠a de subyacente. Es decir, la comunicaci√≥n funciona de igual forma si estamos conectados a trav√©s de WiFi, Ethernet o 5G, a pesar de que sean diferentes medios. Esta clara delimitaci√≥n de capas permite combinar de forma m√°s sencilla diferentes tecnolog√≠as y dispositivo hardware.\nComo es habitual, vamos a ver un ejemplo simplificado donde un dispositivo quiere mandarle un mensaje a otro dispositivo que no est√° en la misma red. Este ejemplo simula una situaci√≥n real como acceder desde casa a un servidor web de Google. Habr√° conceptos que no os suenen pero los veremos a lo largo del cap√≠tulo. El dispositivo A (tu ordenador en casa), con IP (192.168.1.10) quiere enviarle un mensaje al dispositivo B (servidor web de Google), con IP (142.250.184.3). Durante el ejemplo vamos a realizar una simplificaci√≥n y utilizaremos siempre la IP del emisor como 192.168.1.10, pero esto no es v√°lido como veremos posteriormente ya que se trata de una IP privada y el Router-A utilizar√≠a NAT. La estructura de la red es la siguiente:\nLos pasos de los que constar√≠a este ejemplo simplificado est√°n recogidos en la Figura¬†3.2 y ser√≠an los siguientes:\nAunque este ejemplo sea una simplificaci√≥n, nos ayuda a introducir la funcionalidad de la capa de red, en concreto, de los routers y del protocolo IP. Generalmente, entre el Router-A y Router-B habr√≠a m√∫ltiples routers intermedios, pero proceso seguir√≠a siendo el mismo. En los siguientes apartados profundizaremos en las funcionalidades de la capa de red a trav√©s de los routers y el protocolo IP.\nLa Capa de Red tiene dos funciones clave: el enrutamiento y el reenv√≠o. El enrutamiento representa el proceso global mediante el cual la red determina las rutas √≥ptimas que seguir√°n los paquetes de datos desde su origen hasta su destino final. Este proceso considera toda la topolog√≠a de la red y puede tomar desde segundos hasta minutos para converger completamente. Los algoritmos de enrutamiento m√°s comunes son RIP, OSPF y BGP.\nEn contraste, el reenv√≠o constituye un proceso local y extremadamente r√°pido que se encarga de mover los paquetes desde el puerto de entrada hasta el puerto de salida espec√≠fico dentro del mismo router. Esta operaci√≥n debe completarse en microsegundos para mantener el rendimiento de la red, por lo que se implementa directamente en hardware. El proceso se basa exclusivamente en la direcci√≥n IP de destino y utiliza √∫nicamente la tabla de reenv√≠o local del router para tomar decisiones inmediatas.\nLa interacci√≥n entre ambos procesos forma un sistema integrado donde los algoritmos de enrutamiento como RIP, OSPF y BGP generan la tabla de enrutamiento con rutas completas, la cual se traduce en una tabla de reenv√≠o optimizada que contiene √∫nicamente la informaci√≥n del siguiente salto (next-hop). Esta tabla de reenv√≠o es la que finalmente permite tomar las decisiones de reenv√≠o paquete por paquete de manera eficiente, creando un flujo continuo desde la planificaci√≥n estrat√©gica de rutas hasta la ejecuci√≥n t√°ctica del movimiento de datos.\nLas responsabilidades de la capa de red var√≠an seg√∫n el tipo de dispositivo y su posici√≥n en el flujo de comunicaci√≥n. En el host emisor, la capa de red recibe segmentos de TCP o UDP y los encapsula en datagramas IP a√±adiendo las cabeceras correspondientes. Durante este proceso, debe fragmentar los datagramas si exceden el MTU del enlace de salida y determinar si el destino es local (dentro de la misma red) o remoto para enviarlo. En el extremo opuesto, el host receptor debe reensamblar los fragmentos cuando sea necesario, verificar la integridad de los datos mediante el checksum de cabecera, extraer los segmentos y entregarlos a la capa de transporte apropiada, adem√°s de procesar las opciones de cabecera IP cuando est√©n presentes.\nLos routers intermedios desempe√±an un papel diferente pero crucial en este ecosistema. Su funci√≥n principal consiste en examinar los campos de la cabecera IP, especialmente la direcci√≥n de destino, consultar sus tablas de enrutamiento para determinar el siguiente salto apropiado, y reenviar los paquetes por la interfaz de salida correspondiente.",
    "crumbs": [
      "Introducci√≥n a redes",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Capa de red</span>"
    ]
  },
  {
    "objectID": "ch/part_networks/network_layer/network_layer.html#modelos-de-servicio",
    "href": "ch/part_networks/network_layer/network_layer.html#modelos-de-servicio",
    "title": "3¬† Capa de red",
    "section": "3.2 Modelos de servicio",
    "text": "3.2 Modelos de servicio\nExisten dos paradigmas fundamentales para implementar servicios de capa de red, cada uno con filosof√≠as y mecanismos completamente diferentes. La elecci√≥n entre estos modelos determina aspectos cruciales como performance, confiabilidad, complejidad y escalabilidad de la red.\nLas redes de circuitos virtuales (VC) emulan el comportamiento de los circuitos telef√≥nicos tradicionales estableciendo ‚Äúcaminos virtuales‚Äù dedicados entre origen y destino. Su funcionamiento se desarrolla en tres fases claramente definidas: primero, el establecimiento de conexi√≥n mediante el env√≠o de un mensaje SETUP desde el host origen, donde cada router intermedio reserva recursos como ancho de banda y buffers, crea una entrada en su tabla VC con un identificador √∫nico local, y reenv√≠a la solicitud hasta que el host destino confirma con un mensaje ACK. Durante la fase de transferencia de datos, los paquetes solo necesitan llevar el VC ID asignado en lugar de la direcci√≥n de destino completa, permitiendo un reenv√≠o r√°pido mediante consulta a la tabla VC, garantizando calidad de servicio (QoS) y manteniendo una ruta fija para todos los paquetes del flujo. Finalmente, la terminaci√≥n se realiza mediante un mensaje TEARDOWN que libera los recursos previamente reservados y elimina las entradas de las tablas VC.\nEsta arquitectura ofrece ventajas significativas como QoS predecible con garant√≠as de rendimiento, overhead reducido en las cabeceras al usar solo el VC ID, control de flujo extremo a extremo y orden garantizado de los paquetes. Sin embargo, presenta desventajas importantes incluyendo la complejidad en el establecimiento y mantenimiento de conexiones, la necesidad de mantener estado por cada conexi√≥n en todos los routers, rigidez ante cambios en la topolog√≠a de red y overhead adicional por la se√±alizaci√≥n requerida. Tecnolog√≠as como ATM, Frame Relay, X.25 y MPLS implementan este modelo de circuitos virtuales para aplicaciones que requieren garant√≠as espec√≠ficas de rendimiento.\nLas redes de datagramas adoptan un enfoque completamente diferente al tratar cada paquete de manera independiente sin establecer conexiones previas entre origen y destino. Este modelo se caracteriza por la ausencia de estado de conexi√≥n en los routers, eliminando la necesidad de un proceso de setup inicial, y basa el reenv√≠o en la direcci√≥n de destino completa contenida en cada paquete. Cada router procesa los paquetes independientemente. Como resultado, diferentes paquetes del mismo flujo puedan seguir rutas distintas a trav√©s de la red.\nEl modelo de datagramas presenta ventajas sustanciales en t√©rminos de simplicidad de dise√±o e implementaci√≥n, robustez excepcional ante fallos de red ya que no depende de estados de conexi√≥n preestablecidos, flexibilidad para implementar balanceo din√°mico de carga, escalabilidad superior al no requerir mantener estado por cada flujo, y adaptabilidad inmediata a cambios en la topolog√≠a de red. Estas caracter√≠sticas hacen que las redes de datagramas sean especialmente adecuadas para entornos din√°micos y de gran escala como Internet.\nNo obstante, el modelo de datagramas tambi√©n presenta limitaciones significativas que incluyen la ausencia de garant√≠as de calidad de servicio (QoS), la posibilidad de que los paquetes lleguen fuera de orden al destino debido a las diferentes rutas que pueden tomar, el overhead adicional generado por incluir la direcci√≥n de destino completa en cada paquete, y la prestaci√≥n √∫nicamente de un servicio de mejor esfuerzo (best-effort) sin compromisos espec√≠ficos de rendimiento. A pesar de estas limitaciones, el modelo de datagramas se ha convertido en el fundamento de Internet debido a su simplicidad, robustez y capacidad de adaptaci√≥n a las condiciones cambiantes de la red.\nResumen comparativo:\n\n\n\nAspecto\nCircuitos Virtuales\nDatagramas\n\n\n\n\nEstablecimiento\nRequerido\nNo requerido\n\n\nEstado en routers\nS√≠, por conexi√≥n\nNo\n\n\nDireccionamiento\nVC ID\nDirecci√≥n IP completa\n\n\nEnrutamiento\nRuta fija\nRuta por paquete\n\n\nQoS\nGarant√≠as posibles\nBest effort\n\n\nRecuperaci√≥n fallos\nDif√≠cil\nAutom√°tica\n\n\nEscalabilidad\nLimitada\nAlta\n\n\nOverhead\nSetup/teardown\nPor paquete",
    "crumbs": [
      "Introducci√≥n a redes",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Capa de red</span>"
    ]
  },
  {
    "objectID": "ch/part_networks/network_layer/network_layer.html#dispositivos-f√≠sicos-de-la-capa-de-red",
    "href": "ch/part_networks/network_layer/network_layer.html#dispositivos-f√≠sicos-de-la-capa-de-red",
    "title": "3¬† Capa de red",
    "section": "3.3 Dispositivos f√≠sicos de la Capa de Red",
    "text": "3.3 Dispositivos f√≠sicos de la Capa de Red\nLos dispositivos de capa de red son los componentes hardware que hacen posible la interconexi√≥n de redes y la implementaci√≥n de las funciones de enrutamiento y reenv√≠o. Estos dispositivos var√≠an considerablemente en complejidad, desde simples switches Layer 3 hasta routers core de alta capacidad.\n\n3.3.1 Routers (Enrutadores)\nLos routers constituyen la columna vertebral de Internet y las redes empresariales modernas. Su funci√≥n principal es interconectar diferentes redes y determinar la ruta √≥ptima para el reenv√≠o de paquetes de datos. A diferencia de los switches que operan en la Capa de Acceso a la Red, los routers trabajan en la Capa de Red, tomando decisiones basadas en direcciones IP y manteniendo una visi√≥n global de la topolog√≠a de red.\nLa arquitectura b√°sica consta de cuatro componentes principales:\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ\n‚îÇ  Puertos de     ‚îÇ    ‚îÇ   Procesador    ‚îÇ    ‚îÇ  Puertos de     ‚îÇ\n‚îÇ   Entrada       ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ      de         ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ   Salida        ‚îÇ\n‚îÇ                 ‚îÇ    ‚îÇ  Enrutamiento   ‚îÇ    ‚îÇ                 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n         ‚ñ≤                        ‚îÇ                        ‚ñ≤\n         ‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ\n         ‚îÇ              ‚îÇ                   ‚îÇ              ‚îÇ\n         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ Fabric de         ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                        ‚îÇ Conmutaci√≥n       ‚îÇ\n                        ‚îÇ                   ‚îÇ\n                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\nEn los routers diferenciamos dos planos claramente separados:\n\nplano de control: ejecuta el proceso de enrutamiento mediante software especializado y generan tablas de enrutamiento que contienen rutas completas hacia todos los destinos conocidos.\nplano de datos: ejecuta el proceso de reenvio mediante hardware especializado para m√°xima eficiencia. Utiliza la tabla de enrutamiento generado en el plano de control.\n\nLos puertos de entrada constituyen las puertas de recepci√≥n del router y realizan tres funciones cr√≠ticas organizadas en secuencia. La terminaci√≥n f√≠sica proporciona la interfaz con medios de transmisi√≥n como cables de cobre o fibra √≥ptica, convirtiendo las se√±ales el√©ctricas u √≥pticas en datos digitales. El procesamiento de la capa de enlace maneja protocolos espec√≠ficos como Ethernet, PPP o Frame Relay, extrayendo el datagrama IP de la trama correspondiente. La funci√≥n de b√∫squeda IP consulta la tabla de reenv√≠o usando el algoritmo de coincidencia de prefijo m√°s largo para determinar hacia d√≥nde dirigir cada paquete. Esta funci√≥n debe ejecutarse a la velocidad del enlace para evitar crear cuellos de botella en el sistema.\nLos puertos de salida gestionan el tr√°fico que abandona el router mediante un proceso inverso al de entrada. La bufferizaci√≥n y scheduling implementa sistemas de colas sofisticados que aplican pol√≠ticas de calidad de servicio, decidiendo qu√© paquetes enviar primero seg√∫n sus prioridades. El procesamiento de la capa de enlace encapsula el datagrama IP en la trama apropiada para el protocolo del enlace de salida. Finalmente, la terminaci√≥n f√≠sica convierte los datos digitales en se√±ales el√©ctricas u √≥pticas para su transmisi√≥n.\nEl procesador de enrutamiento funciona como el cerebro del sistema, ejecutando los protocolos de enrutamiento que intercambian informaci√≥n con otros routers para mantener actualizado el conocimiento de la topolog√≠a de red. Tambi√©n gestiona funciones administrativas como SNMP para monitoreo remoto, procesamiento ICMP para herramientas de diagn√≥stico como ping y traceroute, y la computaci√≥n de las tablas de reenv√≠o optimizadas a partir de las tablas de enrutamiento.\nPor √∫ltimo, NAT es un protocolo que opera entre ambas capas (lo veremos despu√©s). Al principio operaba s√≥lo en el plano de control, tomando un tiempo significativo. En la actualidad, opera en el plano de control para manejar las sesiones y el resto en hardware especializado en el plano de datos.\n\n3.3.1.1 Proceso de Reenv√≠o de Paquetes\nEl proceso de reenv√≠o sigue una secuencia precisa y optimizada que se ejecuta para cada paquete:\n\nRecepci√≥n y procesamiento inicial: El paquete llega al puerto de entrada desde el enlace f√≠sico, se procesa la cabecera de la capa de enlace correspondiente y se extrae el datagrama IP.\nVerificaci√≥n de integridad: Se verifica el checksum de la cabecera IP para detectar posibles errores de transmisi√≥n y se comprueba que el valor TTL sea mayor que cero.\nExtracci√≥n de informaci√≥n de destino: Se extrae la direcci√≥n IP de destino de la cabecera del datagrama para utilizarla en la decisi√≥n de reenv√≠o.\nConsulta de tabla de reenv√≠o: Se aplica el algoritmo de coincidencia de prefijo m√°s largo en la tabla de reenv√≠o para determinar la interfaz de salida apropiada y obtener la direcci√≥n del siguiente salto.\nModificaci√≥n del paquete: Se decrementa el campo TTL en una unidad y se recalcula el checksum de la cabecera IP para mantener la integridad de los datos. Si el TTL llega a cero despu√©s del decremento, el router descarta el paquete y env√≠a un mensaje ICMP ‚ÄúTime Exceeded‚Äù al host origen, evitando as√≠ loops infinitos en la red.\nResoluci√≥n de direcciones: Si es necesario, se resuelve la direcci√≥n MAC del dispositivo del siguiente salto mediante el protocolo ARP.\nEncapsulaci√≥n y env√≠o: Se encapsula el datagrama IP en una nueva trama seg√∫n el protocolo de la capa de enlace del puerto de salida y se transmite por la interfaz f√≠sica correspondiente.\n\n\n\n\n3.3.2 Switches de Capa 3\nA medida que las redes locales crecieron en complejidad, surgi√≥ la necesidad de dispositivos que combinaran la velocidad del switching con las capacidades del routing. Los switches Layer 3 llenan este nicho espec√≠fico. La principal diferencia es la implementaci√≥n a nivel de hardware del procesamiento, haci√©ndolo mucho m√°s r√°pido. A modo de comparativa ten√©is la siguiente tabla:\n\n\n\nAspecto\nRouter Tradicional\nSwitch L3\n\n\n\n\nReenv√≠o\nSoftware/ASIC\nHardware puro\n\n\nLatencia\nMicrosegundos\nNanosegundos\n\n\nThroughput\nLimitado por CPU\nWire-speed\n\n\nCosto\nMayor\nMenor\n\n\nFlexibilidad\nAlta\nLimitada",
    "crumbs": [
      "Introducci√≥n a redes",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Capa de red</span>"
    ]
  },
  {
    "objectID": "ch/part_networks/network_layer/network_layer.html#protocolos",
    "href": "ch/part_networks/network_layer/network_layer.html#protocolos",
    "title": "3¬† Capa de red",
    "section": "3.4 Protocolos",
    "text": "3.4 Protocolos\n\n3.4.1 Protocolo IP\nIP es el protocolo principal de la capa de red en la arquitectura TCP/IP. Define la estructura de datagramas, direccionamiento y mecanismos b√°sicos de entrega. Las caracter√≠sticas principales de IP son:\n\nSin conexi√≥n: No requiere establecimiento previo.\nNo confiable: No garantiza entrega, orden, o integridad.\nBest effort: Hace el ‚Äúmejor esfuerzo‚Äù por entregar paquetes.\nIndependiente del medio: Funciona sobre cualquier tecnolog√≠a de enlace.\n\nDentro de IP hay dos versiones. IPv4 dise√±ado en los a√±os 70 y IPv6, como evoluci√≥n de IPv4 enfocado a solventar las limitaciones de IPv4, en especial el n√∫mero de IPs disponibles. Empezaremos por IPv4.\n\n\n\n\n\n\n\n\n---\nconfig:\n  packet:\n    showBits: true\n---\npacket-beta\n\ntitle IPv4 Header Format\n0-3: \"Version (4)\"\n4-7: \"IHL (4)\"\n8-15: \"Type of Service (8)\"\n16-31: \"Total Length (16)\"\n32-47: \"Identification (16)\"\n48-50: \"Flags (3)\"\n51-63: \"Fragment Offset (13)\"\n64-71: \"Time to Live (8)\"\n72-79: \"Protocol (8)\"\n80-95: \"Header Checksum (16)\"\n96-127: \"Source Address (32)\"\n128-159: \"Destination Address (32)\"\n160-191: \"Options (variable)\"\n192-223: \"Padding\"\n\n\n\n\n\n\n\n\nFigura¬†3.3: Formato de cabeceras de IPv4.\n\n\n\nEl datagrama IPv4 es la unidad b√°sica de informaci√≥n que viaja por Internet (Ver estructura en Figura¬†3.3). Utiliza una cabecera de longitud variable (m√≠nimo 20 bytes) que contiene la informaci√≥n esencial para el enrutamiento y entrega de paquetes a trav√©s de Internet. Los campos m√°s cr√≠ticos incluyen las direcciones IP de origen y destino que determinan los puntos de comunicaci√≥n, el campo TTL que previene loops infinitos al decrementarse en cada router, el campo Protocol que identifica el protocolo de capa superior (TCP, UDP, ICMP), y los campos de fragmentaci√≥n (Identification, Flags, Fragment Offset) que permiten dividir y reensamblar datagramas que exceden el MTU del enlace. El checksum protege √∫nicamente la cabecera, delegando la protecci√≥n de los datos a las capas superiores, mientras que el campo Total Length especifica el tama√±o completo del datagrama para su procesamiento correcto.\nEl sistema de direccionamiento IPv4, llamadas IP, es un identificador √∫nico de un dispositivo dentro de una red. En IPv4 tienen un formato de 32 bits que se organiza en 4 octetos separados por puntos. Por ejemplo, 192.168.1.1 o 10.0.1.50. Debido a la longitud de 32 bits, el n√∫mero de direcciones IP posibles son \\(2^{32}\\), aproximadamente 4.3 miles de millones. Estas direcciones se organizan en dos partes, la parte de red y la parte de host, adem√°s tenemos la m√°scara de red que nos ayuda a distinguir ambas partes. Por ejemplo, 192.168.1.1 con m√°scara de red 255.255.255.0 o 10.0.1.50 con m√°scara de red 255.255.0.0, siendo la parte azul la parte de red y la roja la parte del host. Para obtener la direcci√≥n de red utilizamos el operador binario AND: 192.168.1.1 & 255.255.255.0 = 192.168.1.0. En CIDR, que veremos m√°s adelante, esta m√°scara 255.255.255.0 se representa como /24.\nEsta divisi√≥n entre parte de red y parte de host permite representar jer√°rquicamente la estructura de direccionamiento, como se muestra en la Figura¬†3.4. Los routers pueden tomar decisiones de reenv√≠o bas√°ndose √∫nicamente en la parte de red de la direcci√≥n destino, consultando sus tablas locales para determinar la interfaz de salida. Gracias a esta organizaci√≥n, es posible la agregaci√≥n de rutas, donde varias redes peque√±as se resumen en una sola entrada de mayor alcance. Por ejemplo, dos subredes /28 contiguas (192.168.1.0/28 y 192.168.1.16/28) pueden representarse como un √∫nico bloque /27 (192.168.1.0/27), reduciendo de dos entradas a una. Este mecanismo permite que los routers mantengan informaci√≥n consolidada sobre redes remotas sin necesidad de conocer cada host o subred en detalle, lo que disminuye dr√°sticamente el tama√±o de las tablas de reenv√≠o y hace escalable la infraestructura global de Internet.\n\n\n\n\n\n\n\n\ngraph TD\n    A[Internet Global] --&gt; B[Red 192.168.0.0/16]\n    A --&gt; C[Red 10.0.0.0/8]\n    A --&gt; D[Red 172.16.0.0/12]\n    \n    B --&gt; B1[Subred 192.168.1.0/24]\n    B --&gt; B2[Subred 192.168.2.0/24]\n    B --&gt; B3[Subred 192.168.3.0/24]\n    \n    C --&gt; C1[Subred 10.0.1.0/24]\n    C --&gt; C2[Subred 10.0.2.0/24]\n    \n    B1 --&gt; B1A[Host 192.168.1.1]\n    B1 --&gt; B1B[Host 192.168.1.2]\n    B1 --&gt; B1C[Host 192.168.1.10]\n    \n    B2 --&gt; B2A[Host 192.168.2.5]\n    B2 --&gt; B2B[Host 192.168.2.100]\n    \n    C1 --&gt; C1A[Host 10.0.1.50]\n    C1 --&gt; C1B[Host 10.0.1.75]\n\n    classDef network fill:#e1f5fe\n    classDef subnet fill:#f3e5f5\n    classDef host fill:#fff3e0\n    \n    class A,B,C,D network\n    class B1,B2,B3,C1,C2 subnet\n    class B1A,B1B,B1C,B2A,B2B,C1B,C1A host\n\n\n\n\n\n\n\n\nFigura¬†3.4: Ejemplo de estructuras de subredes.\n\n\n\nLa estructura de direccionamiento IPv4, que permite distinguir entre red y host para generar una arquitectura jer√°rquica de redes, inicialmente utilizaba un sistema de clases. En este sistema de clases, las direcciones IPv4 se categorizaban en tres grupos principales seg√∫n los bits iniciales del primer octeto, determinando la divisi√≥n entre bits de red y host. La Clase A comenzaba con bit 0, la Clase B con bits ‚Äú10‚Äù, y la Clase C con bits ‚Äú110‚Äù, creando saltos enormes entre las capacidades de cada categor√≠a que generaban ineficiencias significativas en la asignaci√≥n. La estructura de direccionamiento IPv4, que permite distinguir entre red y host para generar una arquitectura jer√°rquica de redes, inicialmente utilizaba un sistema de clases. En este sistema de clases, las direcciones IPv4 se categorizaban en tres grupos principales seg√∫n los bits iniciales del primer octeto, determinando la divisi√≥n entre bits de red y host. La Clase A comenzaba con bit 0, la Clase B con bits ‚Äú10‚Äù, y la Clase C con bits ‚Äú110‚Äù, creando saltos enormes entre las capacidades de cada categor√≠a que generaban ineficiencias significativas en la asignaci√≥n.\n\n\n\n\n\n\n\n\n\n\n\n\n\nClase\nRango de Direcciones\nPrimer Bit(s)\nBits de Red\nBits de Host\nRedes Disponibles\nHosts por Red\nUso T√≠pico\n\n\n\n\nA\n0.0.0.0 - 127.255.255.255\n0\n7\n24\n1261\n16,777,214\nISPs, gobiernos, organizaciones masivas\n\n\nB\n128.0.0.0 - 191.255.255.255\n10\n14\n16\n16,384\n65,534\nUniversidades, empresas medianas\n\n\nC\n192.0.0.0 - 223.255.255.255\n110\n21\n8\n2,097,152\n254\nEmpresas peque√±as, oficinas locales\n\n\n\nSin embargo, la rigidez del sistema de clases generaba problemas cr√≠ticos. Una organizaci√≥n con 1,000 hosts enfrentaba un dilema: elegir una red Clase B desperdiciando 64,534 direcciones (99.5% de ineficiencia) o gestionar m√∫ltiples redes Clase C con mayor complejidad administrativa. Esta inflexibilidad aceler√≥ el agotamiento del espacio IPv4 y motiv√≥ el desarrollo de alternativas m√°s eficientes.\nPara solventar este problema se introdujo CIDR. La innovaci√≥n fundamental consisti√≥ en la notaci√≥n /x que indica exactamente cu√°ntos bits destinan a la parte de red. Por ejemplo, 192.168.1.0/24 significa que los primeros 24 bits identifican la red, dejando 8 bits para hosts (254 hosts utilizables). CIDR permite asignar direcciones en bloques de cualquier tama√±o potencia de 2, eliminando el desperdicio masivo del sistema anterior. Una organizaci√≥n que necesite 500 hosts puede recibir un /23 (510 hosts) en lugar de desperdiciar una Clase B completa. Esta flexibilidad aument√≥ la utilizaci√≥n del espacio IPv4 del 20-30% tradicional al 95-98% actual y la simplificaci√≥n de las tablas de enrutamiento globales mediante la agregaci√≥n de rutas.\nPara funcionar, CIDR requiere el algoritmo de longest prefix matching para b√∫squedas en tablas de enrutamiento. Cuando un router recibe un paquete, eval√∫a todas las rutas que coinciden con la direcci√≥n destino y selecciona aquella con el prefijo m√°s espec√≠fico. En una tabla con rutas 192.168.0.0/16, 192.168.1.0/24 y 192.168.1.128/25, el destino 192.168.1.200 coincide con las dos primeras pero selecciona 192.168.1.0/24 por tener el prefijo m√°s largo (24 bits vs 16 bits). Este mecanismo garantiza que el tr√°fico tome siempre la ruta m√°s espec√≠fica disponible.\nIndependientemente del sistema de direccionamiento utilizado (clases o CIDR), IPv4 mantiene direcciones especiales con prop√≥sitos espec√≠ficos:\n\n0.0.0.0/32: This host on this network. Referencia un host sin IP configurada. Se utiliza en el proceso de configuraci√≥n (DHCP).\n127.0.0.0/8: Loopback. Los paquetes no salen del host local y se utiliza para servicios y pruebas. Un ejemplo com√∫n es localhost, con IP 127.0.0.1.\n255.255.255.255/32: Limited broadcast. Broadcast a todos los hosts en red local. No atraviesa routers.\nx.x.x.0: Direcci√≥n de red. Todos los bits del host a 0 (con la m√°scara de red). Identifica a la red misma.\nx.x.x.255: Directed broadcast. Todos los bits de host a 1. Broadcast dirigido a una red espec√≠fica.\n\nEn el sistema de clases, las direcciones de red y broadcast segu√≠an patrones fijos seg√∫n la clase, pero con CIDR se adaptan din√°micamente a la m√°scara de subred espec√≠fica utilizada.\nAmbos sistemas establecen una serie de rangos, determinadas privadas, que son exclusivas para redes internas. Estas direcciones no son enrutables en Internet p√∫blico, ya que los routers globales est√°n configurados para descartarlas, evitando conflictos de direccionamiento. La principal ventaja radica en que m√∫ltiples organizaciones pueden reutilizar los mismos rangos internamente sin interferir entre s√≠, conservando el escaso espacio IPv4 p√∫blico. Para acceder a Internet, estas redes requieren NAT, que traduce direcciones privadas a p√∫blicas. Los rangos delimitados son: 10.0.0.0/8 (16.7 millones de hosts, para grandes organizaciones), 172.16.0.0/12 (1 mill√≥n de hosts, para empresas medianas) y 192.168.0.0/16 (65,000 hosts, para hogares y oficinas peque√±as).\nPor √∫ltimo, en el protocolo IP hay una tama√±o m√°ximo para el datagrama. Este tama√±o se conoce como MTU (del ingl√©s, Maximum Transmission Unit), y puede variar dependiendo de la tecnolog√≠a subyacente, por ejemplo, en Ethernet es 1500 bytes y en Token Ring es 4464 bytes. Cuando el tama√±o del datagrama es superior al MTU, el datagrama se fragmenta en trozos m√°s peque√±os y se desfragmentar√° posteriormente en el destino. Una consideraci√≥n importante es que el protocolo IP s√≠ mantiene el orden de la informaci√≥n del datagrama. Es decir, si yo env√≠o un datagrama que se tiene que fragmentar, IP garantiza que al desfragmentarlo la integridad de los datos estar√° preservada. Cuando decimos que no garantiza el orden es que si primero env√≠o el datagrama A y despu√©s otro datagrama B (independientes), puede que la aplicaci√≥n reciba primero el datagrama B y despu√©s el A, y no tendr√© forma de saber si uno va antes que el otro.\n\n3.4.1.1 IPv6\nIPv6 surge como respuesta a las limitaciones cr√≠ticas de IPv4, principalmente el agotamiento de su espacio de direcciones de 32 bits que solo proporciona 4.3 √ó 10^{9} direcciones √∫nicas. Adem√°s, IPv4 presenta problemas de fragmentaci√≥n ineficiente que requiere procesamiento en routers intermedios, configuraci√≥n manual compleja sin capacidades de autoconfiguraci√≥n, implementaci√≥n de seguridad como complemento opcional (IPSec), y limitaciones en calidad de servicio con campos TOS poco efectivos. Estos desaf√≠os hacen insostenible IPv4 para el crecimiento exponencial de dispositivos conectados a Internet.\nIPv6 revoluciona el protocolo con un espacio de direcciones masivo de 128 bits que proporciona 2^{128} = 3.4 √ó 10^{38} direcciones, utilizando notaci√≥n hexadecimal con reglas de compresi√≥n para simplificar su representaci√≥n. La cabecera, ver Figura¬†3.5, se simplifica a un formato fijo de 40 bytes eliminando el checksum para reducir el procesamiento en routers, e integra caracter√≠sticas avanzadas como autoconfiguraci√≥n SLAAC, seguridad IPSec obligatoria, y mejor calidad de servicio mediante campos Traffic Class y Flow Label. Debido a la cantidad de dispositivos en la red, la migraci√≥n de IPv4 a IPv6 se realiza de forma gradual mediante estrategias que permiten la interoperabilidad entre ambos protocolos.\n\n\n\n\n\n\n\n\n---\nconfig:\n  packet:\n    showBits: true\n---\npacket-beta\n\n0-3: \"Version (4)\"\n4-11: \"Traffic Class (8)\"\n12-31: \"Flow Label (20)\"\n32-47: \"Payload Length (16)\"\n48-55: \"Next Header (8)\"\n56-63: \"Hop Limit (8)\"\n64-127: \"Source Address (64 bits - first half)\"\n128-191: \"Source Address (64 bits - second half)\"\n192-255: \"Destination Address (64 bits - first half)\"\n256-319: \"Destination Address (64 bits - second half)\"\n\n\n\n\n\n\n\n\nFigura¬†3.5: Formato de cabeceras de IPv6.\n\n\n\n\n\n\n3.4.2 Protocolo ICMP (Internet Control Message Protocol)\nICMP es un protocolo complementario a IP que proporciona mecanismos de control, diagn√≥stico y reporte de errores en redes. Utiliza IP para su transporte (protocolo n√∫mero 1) pero opera como herramienta de gesti√≥n de red. Es no orientado a conexi√≥n, no garantiza entrega, y est√° implementado obligatoriamente en todos los dispositivos IP. Su formato b√°sico incluye campos Type, Code, Checksum y datos adicionales seg√∫n el tipo de mensaje.\nLos mensajes ICMP se clasifican en dos categor√≠as principales: mensajes de error y mensajes de consulta. Los mensajes de error incluyen ‚ÄúDestination Unreachable‚Äù (Type 3) que indica problemas de alcance como red, host o puerto inaccesible; ‚ÄúTime Exceeded‚Äù (Type 11) usado cuando el TTL expira en tr√°nsito; ‚ÄúParameter Problem‚Äù (Type 12) para errores de configuraci√≥n; o ‚ÄúPacket Too Big‚Äù en el mecanismo de MTU Discovery de IPv6. Los mensajes de consulta incluyen ‚ÄúEcho Request/Reply‚Äù (Type 8/0) utilizados por ping para verificar conectividad y medir latencia, y ‚ÄúTimestamp Request/Reply‚Äù (Type 13/14) para sincronizaci√≥n temporal.\nPing - Verificaci√≥n de conectividad:\n$ ping 8.8.8.8\nPING 8.8.8.8 (8.8.8.8): 56 data bytes\n64 bytes from 8.8.8.8: icmp_seq=0 ttl=55 time=15.1 ms\n64 bytes from 8.8.8.8: icmp_seq=1 ttl=55 time=14.9 ms\nEste ejemplo muestra ping enviando Echo Request (Type 8) al servidor DNS de Google y recibiendo Echo Reply (Type 0) exitosamente. Las respuestas muestran latencias de ~15ms, TTL=55, y confirman conectividad funcional.\nTraceroute - Descubrimiento de ruta:\n$ traceroute google.com\n 1  192.168.1.1 (192.168.1.1)  3.414 ms  3.863 ms  1.752 ms\n 2  100.70.0.1 (100.70.0.1)  5.245 ms  4.996 ms  4.405 ms\n 3  10.14.0.53 (10.14.0.53)  7.091 ms  4.812 ms  4.892 ms\n 4  10.14.246.6 (10.14.246.6)  4.209 ms  4.406 ms  4.230 ms\n 5  * * *\n 6  72.14.195.182 (72.14.195.182)  4.665 ms\n    72.14.194.132 (72.14.194.132)  3.950 ms\n    72.14.195.182 (72.14.195.182)  4.968 ms\n 7  74.125.245.171 (74.125.245.171)  5.109 ms  5.751 ms  5.791 ms\n 8  142.251.49.55 (142.251.49.55)  4.185 ms\n    142.251.49.53 (142.251.49.53)  5.317 ms\n    142.251.49.55 (142.251.49.55)  3.791 ms\n 9  mad41s11-in-f14.1e100.net (142.250.185.14)  4.722 ms  6.253 ms  4.893 ms\nEste ejemplo revela la ruta completa hacia google.com incrementando TTL progresivamente. Cada router responde ‚ÄúTime Exceeded‚Äù (Type 11, Code 0) mostrando su IP. El salto 5 muestra timeouts (*), el salto 6 y 8 muestra balanceadores de carga, y finalmente alcanza el servidor de Google en el salto 9.\n\n\n3.4.3 NAT (Network Address Translation)\nNAT surgi√≥ como una soluci√≥n al problema del agotamiento de direcciones IPv4, permitiendo que m√∫ltiples dispositivos en una red privada compartan una sola direcci√≥n IP p√∫blica. Esta t√©cnica se basa en el uso de direcciones privadas que pueden reutilizarse sin conflictos. El dispositivo NAT, t√≠picamente integrado en routers de acceso dom√©stico o empresarial, act√∫a como intermediario entre la red interna y externa, traduciendo direcciones y puertos en tiempo real.\nEl funcionamiento de NAT se basa en mantener una tabla de traducci√≥n que mapea combinaciones de direcci√≥n IP privada y puerto interno con la direcci√≥n IP p√∫blica y un puerto externo √∫nico. Cuando un dispositivo interno inicia una conexi√≥n hacia Internet, el router NAT reemplaza la direcci√≥n IP de origen privada y el puerto por su direcci√≥n IP p√∫blica y un puerto disponible de su pool, registrando esta asociaci√≥n en su tabla. Cuando llega la respuesta desde Internet, el router consulta su tabla de traducci√≥n para determinar a qu√© dispositivo interno debe entregar el paquete, revirtiendo la traducci√≥n antes de reenviarlo a la red local.\nEn la Figura¬†3.6 podemos ver dos ejemplos de NAT. El Host A env√≠a un paquete desde 192.168.1.10:12345 hacia 8.8.8.8:80. El router NAT lo intercepta, reemplaza el origen por 203.0.113.100:5001 y crea una entrada en su tabla: 192.168.1.10:12345 ‚ÜîÔ∏é 5001. Cuando el servidor responde a 203.0.113.100:5001, el router consulta su tabla NAT, encuentra la correspondencia y reenv√≠a el paquete a 192.168.1.10:12345. El proceso en el Host B ser√≠a id√©ntico, y gracias a NAT habr√≠amos podido comunicarnos con dos dispositivos a trav√©s de una √∫nica IP.\n\n\n\nRed Interna (192.168.1.0/24)          NAT Router          Internet\n                                    (203.0.113.100)\n                                                           \n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇHost A       ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ             ‚îÇ ‚îÄ‚îÄ‚îÄ ‚îÇServidor Web ‚îÇ\n‚îÇ192.168.1.10 ‚îÇ Src: 192.168.1.10  ‚îÇ             ‚îÇ     ‚îÇ8.8.8.8:80   ‚îÇ\n‚îÇPort: 12345  ‚îÇ Dst: 8.8.8.8:80    ‚îÇ   Tabla     ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îÇ     NAT     ‚îÇ            ‚ñ≤\n                                   ‚îÇ             ‚îÇ            ‚îÇ\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îÇ192.168.1.10:‚îÇ Src: 203.0.113.100\n‚îÇHost B       ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ12345 ‚Üí 5001 ‚îÇ Dst: 8.8.8.8:80\n‚îÇ192.168.1.20 ‚îÇ Src: 192.168.1.20  ‚îÇ             ‚îÇ            ‚îÇ\n‚îÇPort: 54321  ‚îÇ Dst: 8.8.8.8:80    ‚îÇ192.168.1.20:‚îÇ            ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îÇ54321 ‚Üí 5002 ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n                Traducci√≥n Salida              Traducci√≥n Entrada\n    192.168.1.10:12345 ‚Üí 203.0.113.100:5001    203.0.113.100:5001 ‚Üí 192.168.1.10:12345\n    192.168.1.20:54321 ‚Üí 203.0.113.100:5002    203.0.113.100:5002 ‚Üí 192.168.1.20:54321\n\n\nFigura¬†3.6: Ejemplo de NAT con dos Host que se comunican con un servidor web utiliz√°ndo una √∫nica IP p√∫blica.\n\n\n\nSin embargo, NAT presenta limitaciones significativas como la imposibilidad de establecer conexiones entrantes sin configuraci√≥n manual de port forwarding, complicaciones con aplicaciones que embeben direcciones IP en sus datos (como algunos protocolos VoIP), y la p√©rdida del principio end-to-end de Internet. A pesar de estas limitaciones, NAT se ha convertido en ubicuo en redes dom√©sticas y empresariales, siendo una pieza fundamental que ha permitido que Internet contin√∫e funcionando mientras se desarrolla la transici√≥n hacia IPv6.\nLa limitaci√≥n de conexiones entrantes impide que otros dispositivos sean capaces de conectarse a nosotros directamente. Esto impide, por ejemplo, que dos personas puedan conectarse entre s√≠ desde sus casas. Por otra parte, tambi√©n hace m√°s seguro estar conectado a la red. En determinados casos, conectarse entre s√≠ puede mejorar la experiencia, mejorar la privacidad, o reducir la necesidad de servidores intermedios y sus consecuentes recursos. Para ello, se pueden utilizar diferentes t√©cnicas que permiten saltarse las limitaciones del NAT:\n\nHole punching: T√©cnica donde ambos dispositivos intentan conectarse simult√°neamente al otro a trav√©s de sus respectivos NATs. El NAT crea temporalmente ‚Äúagujeros‚Äù en su tabla de traducci√≥n cuando detecta tr√°fico saliente, permitiendo que la respuesta del otro extremo pase. Funciona peor (es m√°s dif√≠cil) con NAT sim√©trico y requiere coordinaci√≥n temporal precisa.\nSTUN (Session Traversal Utilities for NAT): Protocolo que permite a un dispositivo descubrir su direcci√≥n IP p√∫blica y el tipo de NAT que tiene. Un servidor STUN externo ayuda al cliente a determinar c√≥mo el NAT modifica sus paquetes, informaci√≥n crucial para establecer conexiones directas. Es especialmente √∫til para aplicaciones de tiempo real como VoIP.\nTURN (Traversal Using Relays around NAT): Cuando el hole punching falla, TURN proporciona un servidor relay que act√∫a como intermediario. Aunque no elimina completamente la necesidad de servidores, centraliza el tr√°fico en un punto controlado. Es m√°s confiable pero consume m√°s ancho de banda y recursos del servidor.\nUPnP (Universal Plug and Play): Permite que las aplicaciones configuren autom√°ticamente el router para abrir puertos espec√≠ficos. El dispositivo solicita al router que cree reglas de port forwarding temporales o permanentes. Es conveniente pero requiere que el router soporte UPnP y puede presentar riesgos de seguridad si no se gestiona adecuadamente.",
    "crumbs": [
      "Introducci√≥n a redes",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Capa de red</span>"
    ]
  },
  {
    "objectID": "ch/part_networks/network_layer/network_layer.html#footnotes",
    "href": "ch/part_networks/network_layer/network_layer.html#footnotes",
    "title": "3¬† Capa de red",
    "section": "",
    "text": "Las direcciones 0.0.0.0/8 y 127.0.0.0/8 est√°n reservadas para funciones especiales.‚Ü©Ô∏é",
    "crumbs": [
      "Introducci√≥n a redes",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Capa de red</span>"
    ]
  },
  {
    "objectID": "ch/part_networks/transport_layer/transport_layer.html",
    "href": "ch/part_networks/transport_layer/transport_layer.html",
    "title": "4¬† Capa de transporte",
    "section": "",
    "text": "4.1 Funciones principales\nLa capa de transporte proporciona comunicaci√≥n l√≥gica entre procesos de aplicaci√≥n que se ejecutan en diferentes hosts. Los protocolos de transporte se ejecutan en los hosts finales, no en el n√∫cleo de la red. Los protocolos m√°s comunes son UDP y TCP, que representan los dos lados del espectro en cuanto a funcionalidades. UDP contiene lo m√≠nimo para ser un protocolo de comunicaci√≥n en la capa de transporte y TCP es un protocolo mucho m√°s complejo pero con m√°s garant√≠as. La elecci√≥n entre uno y otro depender√° del dominio y la aplicaci√≥n.\nPrimero, vamos a ver un ejemplo simplificado donde un Cliente A le manda 5 paquetes a un Servidor B. Entre medias, asumimos que hay una red, Internet, donde no profundizaremos por simplicidad, pero ser√≠a como en el Cap√≠tulo 3. Pod√©is ver un ejemplo del escenario en Figura¬†4.1. En este escenario, un proceso Cliente A le env√≠a 5 paquetes a un proceso del Servidor B. El Servicio B est√° referenciado a trav√©s de la IP (8.8.8.8), y dentro de B podemos identificar el proceso a trav√©s del puerto, en este caso, 80. El Cliente A env√≠a un total de 5 paquetes, llegando al servidor, en el siguiente orden: 1, 2, 4, 3. Aqu√≠ pasan varias cosas. Lo primero, en paquete 5 no ha llegado, se ‚Äúperdi√≥‚Äù en Internet. Aproximadamente el 1% de los paquetes se pierden en condiciones normales. En UDP el paquete se perder√≠a, y no nos enterar√≠amos. En TCP, el proceso se reintentar√≠a. La segunda cosa que os puede llamar la atenci√≥n es que el paquete 4 llega antes que el 3. Esto puede ocurrir tambi√©n, ya que los paquetes pueden tomar diferentes caminos. En UDP no tenemos informaci√≥n para corregir el orden, as√≠ que se entregar√≠a primero el 4 y despu√©s el 3. En cambio, TCP cuenta con mecanismos para corregir el orden.\nEn los siguientes apartados veremos las funcionalidades de la Capa de Transporte, y profundizaremos en los protocolos TCP y UDP, tambi√©n veremos una peque√±a comparativa de juegos utilizando TCP y UDP.\nLas funciones principales de la capa de transporte son dividir los mensajes en el emisor en segmentos y pasarlos a la capa de red, y posteriormente en el receptor recomponer los segmentos en mensajes y pasarlos a la capa de aplicaci√≥n. La interfaz entre la capa de transporte y la capa de aplicaci√≥n se llama sockets y la veremos en detalle en el cap√≠tulo de la Capa de Aplicaci√≥n. Por ahora, s√≥lo es necesario tener en cuenta que a trav√©s de los sockets podemos enviar y recibir informaci√≥n. Es la forma que tenemos que utilizar la Capa de Transporte desde la Capa de Aplicaci√≥n.\nLos protocolos m√°s comunes en la capa de transporte son TCP y UDP, que veremos a lo largo de este cap√≠tulo. Los dispositivos tienen generalmente en su kernel implementados estos protocolos y es un proceso del sistema. A trav√©s de los sockets nos podemos conectar a TCP o UDP. Este socket corre en un proceso, ya que en la Capa de Aplicaci√≥n lo que se comunican son procesos entre s√≠. Para distinguir entre los diferentes sockets, se les otorga una identificaci√≥n:\nLos puertos son identificadores num√©ricos desde 1 a 65535. Esta asignaci√≥n puede ser manual o autom√°tica. Cuando creamos un socket en un servidor, la asignaci√≥n generalmente es manual y siempre la misma, de tal forma que los procesos que se comunican lo pueden saber ‚Äúde memoria‚Äù. Cuando abrimos un socket desde un cliente para conectarnos con un servidor, la asignaci√≥n del puerto del cliente es aleatoria, ya que el puerto espec√≠fico del cliente no es relevante.\nAhora que lo hemos visto de forma intuitiva vamos a definirlo un poco m√°s formalmente. En la capa de transporte los protocolos tienen dos tareas comunes, la multiplexaci√≥n y la demultiplexaci√≥n. La multiplexaci√≥n es el proceso por el cual recogemos informaci√≥n de diferentes sockets y lo enviamos por un √∫nico medio. Por el contrario, la demultiplexaci√≥n es el proceso por el cual recibimos los segmentos por el medio √∫nico y lo enviamos a los sockets correspondientes. A modo de analog√≠a se puede ver como un proceso de env√≠o de cartas. La multiplexaci√≥n ser√≠a el buz√≥n de correos donde dejamos las cartas. La demultiplexaci√≥n ser√≠a el personal de correos cogiendo las cartas y llev√°ndolas a sus destinatarios. Posteriormente veremos alguna particularidad respecto a la multiplexaci√≥n y demultiplexaci√≥n entre TCP y UDP.\nOtro concepto interesante es la tranferencia fiable, que es b√°sicamente aquella en la que la informaci√≥n llega tal cual se envi√≥. Es decir, no se corrompe ning√∫n bit, no se pierde informaci√≥n (paquetes) y la informaci√≥n se entrega en un orden correcto. Cuando queremos una transferencia fiable tenemos dos opciones, o bien utilizamos protocolos fiables que ya lo implementen nosotros, o implementamos nosotros esas caracter√≠sticas de tal forma que podamos tener una comunicaci√≥n fiable sobre un medio no fiable.\nEn las siguientes secciones veremos los protocolos UDP y TCP con m√°s detalle.",
    "crumbs": [
      "Introducci√≥n a redes",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Capa de transporte</span>"
    ]
  },
  {
    "objectID": "ch/part_networks/transport_layer/transport_layer.html#funciones-principales",
    "href": "ch/part_networks/transport_layer/transport_layer.html#funciones-principales",
    "title": "4¬† Capa de transporte",
    "section": "",
    "text": "En TCP los sockets se identifican por (IP origen, puerto origen, IP destino, puerto destino).\nEn UDP los sockets se identifican por (IP origen, puerto origen).",
    "crumbs": [
      "Introducci√≥n a redes",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Capa de transporte</span>"
    ]
  },
  {
    "objectID": "ch/part_networks/transport_layer/transport_layer.html#protocolos",
    "href": "ch/part_networks/transport_layer/transport_layer.html#protocolos",
    "title": "4¬† Capa de transporte",
    "section": "4.2 Protocolos",
    "text": "4.2 Protocolos\n\n4.2.1 UDP (User Datagram protocol)\nUDP (User Datagram protocol) es un protocolo minimalista dentro de la familia de protocolos de la capa de transporte. Implementa el m√≠nimo que debe hacer un protocolo de transporte [RFC 768]. UDP sacrifica las garant√≠as de entrega por algo m√°s valioso en ciertos escenarios: velocidad pura y simplicidad. Esto es especialmente √∫til en videojuegos interactivos, DNS o transmisi√≥n de v√≠deos. Las caracter√≠sticas principales de UDP son las siguientes:\n\nProtocolo ligero y simple: Es un protocolo basado en el principio best-effort. Esta aproximaci√≥n significa que hace todo lo posible por entregar los datos al destinatario, pero no ofrece ninguna garant√≠a sobre la entrega de los mismos, ni nos enteraremos sino se entregan debido a que se pierden o tienen errores.\nNo orientado a conexi√≥n: Cuando vamos a enviar informaci√≥n no es necesario establecer una conexi√≥n previa entre receptor y emisor. Podr√≠amos decir que cada paquete que se env√≠a es autosuficiente, tiene toda la informaci√≥n necesaria para representar el ‚Äúestado‚Äù de la conexi√≥n. Si se pierde, no hay mecanismo para recuperarlo. Esta independencia tiene grandes consecuencias. Primero, simplifica la implementaci√≥n. Segundo, se elimina la necesidad del proceso de handshake t√≠pico de los protocolos orientados a conexi√≥n, reduciendo tanto la latencia inicial como la complejidad del protocolo. Tercero, reduce considerablemente los recursos necesarios en el servidor, ya que este no tiene que mantener ning√∫n estado.\nEntrega no fiable y sin orden: UDP no ofrece ninguna garant√≠a de entrega sobre la informaci√≥n que se env√≠a. Esta informaci√≥n puede perderse, puede duplicarse, o pueden llegar desordenados. A veces se denomina UDP como protocolo ‚Äúfire-and-forget‚Äù, es decir, que env√≠as el paquete y te olvidas de que ha existido, independientemente de que llegue o no.\nIntegridad b√°sica: UDP tiene una comprobaci√≥n de integridad a trav√©s de un checksum. Cuando el paquete llega a su receptor, UDP comprueba que el checksum es correcto, y en caso negativo, el paquete se descarta de forma silenciosa.\nMultiplexaci√≥n y demultiplexaci√≥n: La multiplexaci√≥n y demultiplexaci√≥n se realiza mediante el uso de n√∫meros de puerto, que identifican de manera √∫nica los puntos finales de comunicaci√≥n dentro de un host.\n\nRespecto a las caracter√≠sticas no proporcionadas, tenemos el control de flujo, control de congesti√≥n, temporizaci√≥n, tasa de transferencias m√≠nima y seguridad. Para implementar control de flujo, control de congesti√≥n y temporizaci√≥n necesitar√≠amos tener un estado en cliente y servidor, as√≠ como enviar mensajes de control, lo cual entra en conflicto con el principio de best-effort y no ser orientado a conexi√≥n. La tasa de transferencia m√≠nima no es posible siendo agn√≥sticos del medio de transporte y requerir√≠a de estado en los routers, lo cual va en contra de la estructura actual de Internet y dificultar√≠a su escalabilidad. Por √∫ltimo, la seguridad, dependiendo del tipo de algoritmo, probablemente requirir√≠a compartir informaci√≥n previamente de forma segura (claves de cifrado) o autoridades centrales como en el caso de HTTPS. En ambos casos, se complicar√≠a el protocolo.\nLa simplicidad de UDP nos ofrece sin embargo, otra opci√≥n. Implementar nosotros mismos a nivel de capa de aplicaci√≥n las garant√≠as que consideremos necesarias y no pagar el ‚Äúprecio‚Äù por las que no vamos a utilizar. Por ejemplo, supongamos que vamos a desarrollar un juego y enviamos las actualizaciones del jugador con estos requisitos:\n\nSe ignorar√°n los paquetes fuera de orden. Si enviamos (A B C), y UDP recibe (A C B), a nivel de aplicaci√≥n descatar√≠amos B, resultando en (A C).\nSe ignorar√°n los duplicados. Si enviamos (A B C), UDP recibe (A A B), a nivel de aplicaci√≥n descartamos la segunda A, resultando en (A B).\n\nPara esta implementaci√≥n nuestro protocolo podr√≠a a√±adir un n√∫mero de paquete en los primeros bytes de UDP (antes de la actualizaci√≥n del juego), y el servidor tener un estado del √∫ltimo paquete que recibi√≥. Cada vez que recibimos un paquete lo aceptamos si el n√∫mero de paquete del servidor &lt; n√∫mero del paquete recibido, y lo rechazamos de otra forma. Con este peque√±o y sencillo protocolo hemos conseguido ignorar paquetes fuera de orden y duplicado con una sobrecarga m√≠nima en el protocolo, y sin la sobrecarga del resto de funcionalidades que no son necesarias.\nLa estructura de paquete de UDP es la siguiente:\n\n\n\n\n\n---\ntitle: Estructura del paquete UDP\n---\npacket-beta\n\n    0-15: \"Source Port\"\n    16-31: \"Destination Port\"\n    32-47: \"Length\"\n    48-63: \"Checksum\"\n    64-95: \"Data (longitud variable)\"\n\n\n\n\n\n\nComo pod√©is ver la estructura del paquete es realmente simple en comparaci√≥n con el resto de protocolos. El puerto de destino le permite a UDP demultiplexar correctamente el paquete, mientras el de origen le permite al servidor contestar. La longitud indica el tama√±o de los datos, que es un n√∫mero de 16 bits, es decir, que podr√≠a ser hasta 65535 (no incluido), pero en la pr√°ctica est√° limitado por el MTU. Por √∫ltimo, el checksum que es una forma de verificar la integridad del paquete. Esta verificaci√≥n es contra cambios accidentales, pero puede ser manipulada.\nEl c√°lculo del checksum UDP sigue un procedimiento sistem√°tico que garantiza la verificaci√≥n de integridad de todo el datagrama:\n\nPreparaci√≥n de datos: Se concatena la pseudo-cabecera IP, la cabecera UDP (con checksum inicializado a cero) y los datos de aplicaci√≥n, a√±adiendo un byte de padding si la longitud total es impar.\nC√°lculo aritm√©tico: Los datos se dividen en palabras de 16 bits que se suman usando aritm√©tica de complemento a uno, incorporando cualquier carry al resultado final.\nComplemento final: Se calcula el complemento a uno del resultado y se inserta en el campo checksum de la cabecera UDP.\n\nEl proceso de verificaci√≥n en el receptor utiliza el mismo algoritmo pero incluye el checksum recibido en el c√°lculo, esperando obtener 0xFFFF si no hay errores. Si el resultado difiere de 0xFFFF, el datagrama se descarta silenciosamente sin notificaci√≥n al emisor. La pseudo-cabecera proporciona verificaci√≥n adicional del direccionamiento correcto, validaci√≥n del protocolo UDP, y consistencia entre las longitudes reportadas por IP y UDP. Es importante tener en cuenta, que el mecanismo solo detecta errores pero no los corrige, y UDP no implementa retransmisi√≥n autom√°tica de datagramas corruptos.\n\n\n\n\n\n\nTipC√°lculo de checksum en UDP\n\n\n\n\n\nfunction calculateUDPChecksum(srcIP, dstIP, srcPort, dstPort, data) {\n    // Convert string data to Uint8Array if needed\n    if (typeof data === 'string') {\n        data = new TextEncoder().encode(data);\n    }\n    \n    const udpLength = 8 + data.length;\n    \n    // Build complete packet: pseudo-header + UDP header + data\n    const packet = [\n        // Pseudo-header (12 bytes)\n        ...srcIP.split('.').map(x =&gt; parseInt(x)),           // Source IP (4 bytes)\n        ...dstIP.split('.').map(x =&gt; parseInt(x)),           // Dest IP (4 bytes)\n        0, 17,                                               // Zero + Protocol UDP (2 bytes)\n        (udpLength &gt;&gt; 8) & 0xFF, udpLength & 0xFF,          // UDP length (2 bytes)\n        \n        // UDP header (8 bytes)\n        (srcPort &gt;&gt; 8) & 0xFF, srcPort & 0xFF,              // Source port (2 bytes)\n        (dstPort &gt;&gt; 8) & 0xFF, dstPort & 0xFF,              // Dest port (2 bytes)\n        (udpLength &gt;&gt; 8) & 0xFF, udpLength & 0xFF,          // UDP length (2 bytes)\n        0, 0,                                                // Checksum placeholder (2 bytes)\n        \n        // Data payload\n        ...Array.from(data)\n    ];\n    \n    // Calculate 16-bit one's complement checksum\n    let sum = 0;\n    for (let i = 0; i &lt; packet.length - 1; i += 2) {\n        sum += (packet[i] &lt;&lt; 8) + packet[i + 1];\n    }\n    \n    // Handle odd length\n    if (packet.length % 2 === 1) {\n        sum += packet[packet.length - 1] &lt;&lt; 8;\n    }\n    \n    // Add carry bits and return one's complement\n    while (sum &gt;&gt; 16) sum = (sum & 0xFFFF) + (sum &gt;&gt; 16);\n    return (~sum) & 0xFFFF;\n}\n\n\n\nUDP es especialmente adecuado para aplicaciones donde la velocidad prima sobre la garant√≠a de entrega, incluyendo multimedia streaming (tolerante a p√©rdidas menores pero sensible a interrupciones por control de congesti√≥n), consultas DNS que requieren respuestas r√°pidas, protocolos de administraci√≥n de red como SNMP, sistemas de enrutamiento como RIP, gaming online donde la latencia baja es cr√≠tica, y como base para protocolos modernos de transporte como QUIC/HTTP3 que implementan sus propios mecanismos de confiabilidad optimizados.\n\n\n4.2.2 TCP (Transmission Control Protocol)\nTCP (Transmission Control Protocol) es el protocolo de transporte m√°s utilizado en Internet y representa el extremo opuesto a UDP en t√©rminos de garant√≠as y complejidad [RFC 793]. TCP prioriza la confiabilidad y el orden de los datos sobre la velocidad pura, siendo fundamental para aplicaciones como navegadores web, correo electr√≥nico, transferencia de archivos y cualquier servicio que requiera integridad absoluta de los datos. Las caracter√≠sticas principales de TCP son las siguientes:\n\nProtocolo confiable y complejo: TCP implementa m√∫ltiples mecanismos para garantizar que todos los datos enviados lleguen al destinatario en el orden correcto y sin errores. Esta confiabilidad viene al costo de mayor complejidad, latencia y overhead del protocolo.\nOrientado a conexi√≥n: Antes de enviar cualquier dato, TCP requiere establecer una conexi√≥n formal entre cliente y servidor mediante un proceso de handshaking de tres fases. Esta conexi√≥n mantiene estado en ambos extremos, permitiendo el seguimiento de cada byte enviado y recibido.\nEntrega fiable y ordenada: TCP garantiza que todos los datos enviados lleguen al destinatario exactamente una vez y en el mismo orden en que fueron enviados. Implementa mecanismos de detecci√≥n de p√©rdidas, duplicados y reordenamiento autom√°tico.\nControl de flujo: TCP implementa mecanismos para evitar que el emisor sature al receptor, ajustando autom√°ticamente la velocidad de env√≠o seg√∫n la capacidad de procesamiento del destinatario a trav√©s del campo ‚ÄúWindow‚Äù.\nControl de congesti√≥n: TCP detecta y responde a la congesti√≥n de la red, reduciendo autom√°ticamente su tasa de transmisi√≥n cuando detecta p√©rdidas o aumentos en la latencia, contribuyendo as√≠ a la estabilidad general de Internet.\nMultiplexaci√≥n y demultiplexaci√≥n: Al igual que UDP, TCP utiliza n√∫meros de puerto para identificar los diferentes servicios y aplicaciones en un mismo host.\n\nRespecto a las caracter√≠sticas que TCP no proporciona, tenemos la temporizaci√≥n espec√≠fica, tasa m√≠nima garantizada de transferencia y seguridad nativa. TCP no puede garantizar una tasa m√≠nima de transferencia porque debe adaptarse din√°micamente a las condiciones cambiantes de la red. La temporizaci√≥n espec√≠fica no es posible debido a la naturaleza variable de Internet y los mecanismos de retransmisi√≥n que pueden introducir retrasos impredecibles. La seguridad debe implementarse en capas superiores (como TLS/SSL) ya que TCP se centra √∫nicamente en la confiabilidad del transporte.\nLa robustez de TCP permite que las aplicaciones se enfoquen en su l√≥gica de negocio sin preocuparse por los detalles de la transmisi√≥n de datos. Por ejemplo, cuando un navegador web solicita una p√°gina:\n\nTCP garantiza que todos los bytes del HTML, CSS, JavaScript e im√°genes lleguen completos y en orden.\nSi alg√∫n paquete se pierde en la red, TCP lo detecta y retransmite autom√°ticamente.\nSi la red se congestiona, TCP reduce su velocidad para no empeorar la situaci√≥n.\nEl navegador recibe los datos como si fuera un flujo continuo y confiable de bytes.\n\nLa estructura de paquete de TCP es considerablemente m√°s compleja que UDP:\n\n\n\n\n\n---\ntitle: Estructura del paquete TCP\n---\npacket-beta\n  0-15: \"Source Port\"\n  16-31: \"Destination Port\"\n  32-63: \"Sequence Number\"\n  64-95: \"Acknowledgment Number\"\n  96-99: \"Data Offset\"\n  100-105: \"Reserved\"\n  106: \"URG\"\n  107: \"ACK\"\n  108: \"PSH\"\n  109: \"RST\"\n  110: \"SYN\"\n  111: \"FIN\"\n  112-127: \"Window\"\n  128-143: \"Checksum\"\n  144-159: \"Urgent Pointer\"\n  160-191: \"Options (variable)\"\n  192-255: \"Data (variable length)\"\n\n\n\n\n\n\nComo se puede observar, la cabecera TCP es mucho m√°s rica en informaci√≥n que UDP. Los puertos de origen y destino funcionan igual que en UDP para la multiplexaci√≥n. El n√∫mero de secuencia identifica la posici√≥n del primer byte de datos en el flujo, mientras que el n√∫mero de acknowledgment indica el siguiente byte que el receptor espera recibir, implementando as√≠ el mecanismo de confirmaci√≥n acumulativa.\nLos flags de control son cruciales para el funcionamiento de TCP:\n\nSYN: Utilizado para sincronizar n√∫meros de secuencia durante el establecimiento de conexi√≥n.\nACK: Indica que el campo de acknowledgment es v√°lido.\nFIN: Se√±ala el fin de los datos del emisor.\nRST: Fuerza el reinicio de la conexi√≥n.\nPSH: Solicita entrega inmediata al proceso aplicaci√≥n.\nURG: Indica datos urgentes.\n\nEl campo Window implementa el control de flujo, indicando cu√°ntos bytes est√° dispuesto a recibir el destinatario. El checksum funciona de manera similar a UDP pero cubriendo todo el segmento TCP.\n\n4.2.2.1 Establecimiento de Conexi√≥n: Handshake de Tres Fases\nEl proceso de establecimiento de conexi√≥n TCP es un ejemplo de sincronizaci√≥n distribuida:\n\n\n\n\n\nsequenceDiagram\n    participant CS as Cliente Socket\n    participant SS as Server Socket (listen)\n    participant NS as Nuevo Socket\n    \n    Note over CS: Estado: CLOSED\n    Note over SS: Estado: LISTEN\n    CS-&gt;&gt;SS: SYN=1, seq=x\n    Note over CS: Estado: SYN_SENT\n    Note over SS: accept() crea nuevo socket\n    SS-&gt;&gt;NS: Deriva conexi√≥n\n    Note over NS: Estado: SYN_RCVD\n    NS-&gt;&gt;CS: SYN=1, ACK=1, seq=y, ack=x+1\n    Note over CS: Estado: ESTABLISHED\n    CS-&gt;&gt;NS: ACK=1, seq=x+1, ack=y+1\n\n\n\n\n\n\nFase 1 - SYN: El cliente env√≠a un segmento con SYN=1 y un n√∫mero de secuencia inicial aleatorio (x). Este n√∫mero aleatorio es crucial para la seguridad, evitando ataques de predicci√≥n de secuencia.\nFase 2 - SYN+ACK: El servidor responde con SYN=1, ACK=1, su propio n√∫mero de secuencia inicial (y) y confirma el n√∫mero del cliente incrementado en uno (ack=x+1).\nFase 3 - ACK: El cliente confirma el n√∫mero de secuencia del servidor (ack=y+1), estableciendo oficialmente la conexi√≥n bidireccional.\nDurante este proceso se negocian par√°metros importantes como el MSS (Maximum Segment Size), opciones de ventana deslizante y otras extensiones TCP.\n\n\n4.2.2.2 Mecanismos de Confiabilidad\nTCP implementa varios mecanismos para garantizar la entrega confiable. N√∫meros de Secuencia y ACKs: Cada byte en el flujo TCP tiene un n√∫mero de secuencia √∫nico. Los ACKs son acumulativos, lo que significa que un ACK para el byte N confirma la recepci√≥n correcta de todos los bytes desde el inicio hasta N-1. Detecci√≥n de P√©rdidas: TCP utiliza dos m√©todos principales:\n\nTimeout: Si no recibe ACK en un tiempo determinado, asume p√©rdida y retransmite.\nACKs duplicados: Si recibe tres ACKs duplicados para el mismo n√∫mero de secuencia, asume p√©rdida del siguiente segmento y retransmite inmediatamente (Fast Retransmit).\n\n\n\n\n\n\n\n\nsequenceDiagram\n    participant E as Emisor\n    participant R as Receptor\n    E -&gt;&gt; X: seq=100, data=\"A\", Paquete perdido\n    Note over E: Timeout de seq:100, reenvio\n    E -&gt;&gt; R: seq=100, data=\"A\",\n\n\n\n\n\n\n\n\n\n\n\n\nsequenceDiagram\n    participant E as Emisor\n    participant R as Receptor\n    E -&gt;&gt; X: seq=100, data=\"A\", Paquete perdido\n    E -&gt;&gt; R: seq=101, data=\"B\"\n    E -&gt;&gt; R: seq=102, data=\"C\"\n    E -&gt;&gt; R: seq=103, data=\"D\"\n    R -&gt;&gt; E: ACK=100\n    R -&gt;&gt; E: ACK=100\n    R -&gt;&gt; E: ACK=100\n    Note over E,R: Retransmisi√≥n r√°pida\n    E -&gt;&gt; R: seq=100, data=\"A\"\n\n\n\n\n\n\n\n\n\n\n4.2.2.3 Control de Flujo\nTCP mantiene buffers tanto en emisi√≥n como en recepci√≥n, permitiendo el manejo de segmentos fuera de orden y la optimizaci√≥n del flujo de datos. El control de flujo TCP es un mecanismo sofisticado que previene el desbordamiento del receptor:\n\n\n\n\n\nsequenceDiagram\n    participant E as Emisor\n    participant R as Receptor\n    \n    Note over R: Buffer: 4KB libres\n    R-&gt;&gt;E: ACK=1000, Window=4096\n    E-&gt;&gt;R: seq=1000, data=2KB\n    Note over R: Buffer: 2KB libres\n    R-&gt;&gt;E: ACK=3000, Window=2048\n    E-&gt;&gt;R: seq=3000, data=2KB\n    Note over R: Buffer: 0KB libres (lleno)\n    R-&gt;&gt;E: ACK=5000, Window=0\n    Note over E: Detiene env√≠o, inicia probe timer\n    Note over R: Aplicaci√≥n lee datos, libera 1KB\n    E-&gt;&gt;R: seq=5000, data=1 byte (window probe)\n    R-&gt;&gt;E: ACK=5001, Window=1024\n    E-&gt;&gt;R: seq=5001, data=1KB\n\n\n\n\n\n\nLa VentanaRecepcion se calcula como:\nVentanaRecepcion = BufferRecepcion - (UltimoByteRecibido - UltimoByteLeido)\nEl emisor debe asegurar que:\nUltimoByteEnviado - UltimoByteReconocido ‚â§ VentanaRecepcion\nCuando la ventana de recepci√≥n se reduce a cero, el emisor detiene el env√≠o pero contin√∫a sondeando peri√≥dicamente con segmentos de un byte para detectar cu√°ndo hay espacio disponible nuevamente.\n\n\n4.2.2.4 Control de Congesti√≥n\nEl control de congesti√≥n TCP es uno de los algoritmos m√°s importantes de Internet. Utiliza la ventana de congestion para regular la velocidad de env√≠o. La ventana de congesti√≥n es una variable del emisor que representa el n√∫mero m√°ximo de bytes que pueden estar en el ‚Äúaire‚Äù en la red, es decir, el n√∫mero m√°ximo de bytes que pueden ser enviados sin que sean reconocidos (ack). Se combina con la ventana de recepci√≥n para determinar la tasa de env√≠o actual, siendo la tasa efectiva el m√≠nimo de ambas. La ventana de congesti√≥n se regula en base a dos mecanismos:\n\nSlow start (arranque lento): Se inicia con una ventana de congesti√≥n igual a 1 MSS. Duplica la ventana cada RTT (ver ejemplo en (slow-start?)) hasta detectar p√©rdida o alcanzar un umbral. Es decir, el tama√±o crece exponencialmente y es ideal para descubrir el ancho de banda.\nCongestion avoidance (evitaci√≥n de congesti√≥n): Tiene un comportamiento m√°s conservador. Incrementa 1 MSS por cada RTT (ver el ejemplo en (congestion-avoidance?)).\n\ny dos eventos que regulan el paso entre los dos mecanismos:\n\nSalta un temporizador: P√©rdida severa. Se reduce la ventana de congesti√≥n a 1 MSS y pasamos a modo slow start.\nTres ACK duplicados: P√©rdida no tan severa, se reduce la ventana de congesti√≥n a la mitad.\n\n\n\n\n\n\n\nsequenceDiagram\n    participant E as Emisor\n    participant R as Receptor\n    \n    Note over E: Slow Start: cwnd=1 MSS\n    E-&gt;&gt;R: seq=1000, MSS=1KB\n    R-&gt;&gt;E: ACK=2000\n    Note over E: cwnd=2 MSS\n    E-&gt;&gt;R: seq=2000, MSS=1KB\n    E-&gt;&gt;R: seq=3000, MSS=1KB\n    R-&gt;&gt;E: ACK=3000\n    R-&gt;&gt;E: ACK=4000\n    Note over E: cwnd=4 MSS (crecimiento exponencial)\n    Note over E: ... contin√∫a hasta threshold o detectar p√©rdida ...\n\n\n\nMecanismo de congesti√≥n slow start.\n\n\n\n\n\n\n\n\nsequenceDiagram\n    participant E as Emisor\n    participant R as Receptor\n    \n    Note over E: Congestion Avoidance: cwnd=1 MSS\n\n    E-&gt;&gt;R: seq=1000, MSS=1KB\n    R-&gt;&gt;E: ACK=2000\n\n    Note over E: cwnd=2 MSS\n\n    E-&gt;&gt;R: seq=2000, MSS=1KB\n    E-&gt;&gt;R: seq=3000, MSS=1KB\n    R-&gt;&gt;E: ACK=3000\n    R-&gt;&gt;E: ACK=4000\n\n    Note over E: cwnd=3 MSS (crecimiento lineal)\n    Note over E: ... contin√∫a hasta detectar p√©rdida ...\n\n\n\nMecanismo de congesti√≥n congestion avoidance.\n\n\n\n\n\n\nEste mecanismo crea el caracter√≠stico patr√≥n de ‚Äúdiente de sierra‚Äù en el throughput de TCP, donde la ventana crece gradualmente hasta detectar congesti√≥n, se reduce dr√°sticamente, y vuelve a crecer.\n\n\n&lt;Figure size 1344x768 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\n\n4.2.2.5 Terminaci√≥n de Conexi√≥n\nLa terminaci√≥n de conexi√≥n TCP requiere un proceso de cuatro fases debido a su naturaleza full-duplex:\n\n\n\n\n\nsequenceDiagram\n    participant C as Cliente\n    participant S as Servidor\n    \n    Note over C,S: Conexi√≥n establecida - transferencia de datos\n    C-&gt;&gt;S: FIN=1, seq=x\n    Note over C: Estado: FIN_WAIT_1\n    Note over S: Estado: CLOSE_WAIT\n    S-&gt;&gt;C: ACK=1, ack=x+1\n    Note over C: Estado: FIN_WAIT_2\n    Note over S: Aplicaci√≥n termina, cierra socket\n    S-&gt;&gt;C: FIN=1, ACK=1, seq=y, ack=x+1\n    Note over S: Estado: LAST_ACK\n    Note over C: Estado: TIME_WAIT\n    C-&gt;&gt;S: ACK=1, seq=x+1, ack=y+1\n    Note over S: Estado: CLOSED\n    Note over C: Espera 2*MSL (TIME_WAIT)\n    Note over C: Estado: CLOSED\n\n\n\n\n\n\n\nFIN del Cliente: El cliente env√≠a FIN indicando que termin√≥ de enviar datos\nACK del Servidor: El servidor confirma la recepci√≥n del FIN\nFIN del Servidor: El servidor env√≠a su propio FIN cuando termina de enviar\nACK del Cliente: El cliente confirma y entra en estado TIME_WAIT\n\nEl estado TIME_WAIT es crucial para manejar ACKs retrasados y asegurar que la conexi√≥n se cierre completamente.\n\n\n4.2.2.6 Equidad y Coexistencia\nTCP est√° dise√±ado para ser ‚Äúfair‚Äù cuando m√∫ltiples conexiones comparten el mismo enlace. El algoritmo de control de congesti√≥n asegura que N conexiones TCP compartan equitativamente un enlace de capacidad R, obteniendo aproximadamente R/N cada una.\nSin embargo, esta equidad tiene limitaciones:\n\nAplicaciones UDP: No implementan control de congesti√≥n, pueden monopolizar ancho de banda.\nConexiones paralelas: Una aplicaci√≥n puede abrir m√∫ltiples conexiones TCP para obtener mayor throughput.\nRTT diferentes: Conexiones con menor RTT pueden obtener ventaja.",
    "crumbs": [
      "Introducci√≥n a redes",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Capa de transporte</span>"
    ]
  },
  {
    "objectID": "ch/part_networks/transport_layer/transport_layer.html#comparativa-de-tcp-vs-udp-para-videojuegos",
    "href": "ch/part_networks/transport_layer/transport_layer.html#comparativa-de-tcp-vs-udp-para-videojuegos",
    "title": "4¬† Capa de transporte",
    "section": "4.3 Comparativa de TCP vs UDP para videojuegos",
    "text": "4.3 Comparativa de TCP vs UDP para videojuegos\nLa decisi√≥n de elegir entre TCP y UDP depende de la interactividad y la tolerancia a p√©rdidas de informaci√≥n del juego. Por ejemplo, si se requiere de latencias de menos de 50ms, con actualizaciones frecuentes y la informaci√≥n nueva es m√°s valiosa que la vieja, UDP es el claro ganador. Esto se consigue gracias a unas cabeceras mucho m√°s peque√±as y la ausencia de tr√°fico de control. Otro aspecto positivo es que el servidor necesita menos recursos, al no tener que gestionar la l√≥gica de gesti√≥n ni mantener el estado. Algunos videojuegos donde UDP es mejor opci√≥n es en shooters o juegos de lucha debido a su alta interactividad.\nPor contra, si la latencia es de 100ms a 200ms, se necesita una entrega ordenada garantizada y detecci√≥n y correcci√≥n de errores, TCP es la mejor opci√≥n. Con tolerancias de latencia mayores, no tenemos que preocuparnos por bloqueo de cabeza de l√≠nea, es decir, que un paquete perdido impida el procesamiento de los posteriores que ya llegaron. Tambi√©n tendr√≠amos que tener en cuenta las latencias variables, debido a retransmisiones, lo cual podr√≠a generar saltos de estado, incluso con tolerancias de 100ms. Por √∫ltimo, habr√≠a que considerar tambi√©n que incurriremos en un mayor tr√°fico de red, tanto por el tr√°fico de control como por el mayor tama√±o de los paquetes TCP. Los juegos de rol y por turnos son ejemplos de juegos que se adaptan muy bien a TCP.\nPasando a ejemplos concretos, World of Warcraft es un ejemplo de juego implementado sobre TCP. Los hechizos y ataques necesitan entrega garantizada para mantener la consistencia, as√≠ como la actualizaciones del inventario y estado de las misiones. Generalmente los MMORPGs pueden soportar latencias de 100s a 200ms.\nEn el caso de Counter Strike se utiliza UDP debido a que la retroalimentaci√≥n inmediata es m√°s importante que la entrega garantizada. Por ejemplo, las actualizaciones de posici√≥n y disparos necesitan una latencia muy baja. Es tan importante, que a√∫n con UDP, es necesario utilizar t√©cnicas de interpolaci√≥n de estados en los clientes para conseguir transiciones suaves. Esta interpolaci√≥n limita el efecto de paquetes perdidos.",
    "crumbs": [
      "Introducci√≥n a redes",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Capa de transporte</span>"
    ]
  },
  {
    "objectID": "ch/part_networks/application_layer/application_layer.html",
    "href": "ch/part_networks/application_layer/application_layer.html",
    "title": "5¬† Capa de aplicaci√≥n",
    "section": "",
    "text": "5.1 Socket\nLa capa de aplicaci√≥n define los protocolos que utilizar√°n las aplicaciones para intercambiar datos. Las aplicaciones generalmente se representan con procesos, y por lo tanto, la capa de aplicaci√≥n se centra en la comunicaci√≥n entre procesos. Este nivel de ejecuci√≥n nos va a quedar m√°s claro si tenemos en cuenta que podemos crear nuestros propios protocolos que se ejecuten a nivel de capa de aplicaci√≥n.\nA continuaci√≥n veremos un ejemplo de protocolo definido en la capa de aplicaci√≥n, que realiza una funci√≥n de ‚Äúecho‚Äù, es decir, repite la informaci√≥n que recibe. Adem√°s, este peque√±o ejemplo nos servir√° para introducir los tipos de arquitecturas que pueden tener una aplicaci√≥n de red. En concreto, este ejemplo utilizar√° una arquitectura cliente - servidor. En este tipo de arquitectura, tenemos un host (servidor) que est√° siempre activo con una direcci√≥n IP conocida y que ofrece servicio a otros hosts (clientes). Estos clientes podr√°n estar activos o no, y no se comunican entre ellos, s√≥lo con el servidor. En este ejemplo tendremos un servidor, cuya funcionalidad ser√° devolver la informaci√≥n recibida, con el formato ‚ÄúEcho: {message}‚Äù, donde {message} es el contenido recibido. El servidor continuar√° contestando la petici√≥n de los clientes hasta que reciba el mensaje ‚Äúquit‚Äù, mediante el cual se cerrar√° la conexi√≥n entre ambos.\nA continuaci√≥n se muestra el servidor. Est√° programado en JavaScript, que veremos en la siguiente parte del libro. No os preocup√©is si no entend√©is todo, es simplemente a modo de ilustraci√≥n.\nEste servidor est√° formado por dos funciones, la funci√≥n ‚ÄúhandleClient‚Äù y la funci√≥n ‚ÄúechoServer‚Äù. Empezando por ‚ÄúechoServer‚Äù, en las primeras l√≠neas se crea un servidor TCP usando el m√≥dulo ‚Äònet‚Äô de Node.js. El servidor utiliza el modelo basado en eventos de JavaScript - cuando se conecta un cliente, se dispara autom√°ticamente el evento ‚Äòconnection‚Äô, que delega el procesamiento del cliente a ‚ÄúhandleClient‚Äù. La funci√≥n ‚ÄúhandleClient‚Äù define el ‚Äúprotocolo‚Äù mediante eventos: escucha el evento ‚Äòdata‚Äô de forma indefinida hasta que se reciba un mensaje con la palabra ‚Äúquit‚Äù, procesa los datos recibidos y los devuelve al cliente con el formato ‚ÄúEcho: {message}‚Äù. Esta ejecuci√≥n tambi√©n puede terminar cuando se disparan los eventos ‚Äòclose‚Äô (cliente desconecta) o ‚Äòerror‚Äô (error en la conexi√≥n), que son manejados autom√°ticamente por el sistema de eventos de Node.js. Si os fij√°is en esta funci√≥n trabajamos con la variable ‚Äúsocket‚Äù, que es la interfaz entre la capa de aplicaci√≥n y la capa de transporte. Dicho de otra forma, es la interfaz que tenemos de interactuar con la capa inferior, y la capa inferior con nosotros. El servidor queda escuchando en localhost:8888 y puede manejar m√∫ltiples clientes simult√°neamente gracias al bucle de eventos as√≠ncrono de Node.js.\nAhora pasaremos a la parte del cliente:\nEn este caso el c√≥digo est√° hecho con Python, no es un requisito necesario y podr√≠a estar en JavaScript, pero quer√≠a remarcar que la definici√≥n de protocolos en red permite la comunicaci√≥n entre dos procesos que est√°n en la misma u otra m√°quina, independientemente de su lenguage de programaci√≥n 1. En este cliente de Python tenemos una √∫nica funci√≥n que representa al cliente, ‚Äúecho_client‚Äù, donde en las primeras l√≠neas establecemos una conexi√≥n con el servidor de JavaScript. Fijaros en el ('localhost', 8888), con esta combinaci√≥n de identificador de m√°quina, ‚Äúlocalhost‚Äù, podemos identificar el host donde est√° el servidor, y con el puerto, 8888, podemos identificar el proceso que corresponde al servidor. Como en el anterior ejemplo, tenemos un ‚Äúsocket‚Äù que permite una interacci√≥n bidireccional con la capa de transporte. No os preocup√©is por estos detalles, los veremos en el siguiente cap√≠tulo.\nCon este ejemplo hemos ilustrado los tres conceptos clave de este cap√≠tulo, los protocolos de la capa de aplicaci√≥n, la arquitectura de las aplicaciones de red 2, y los sockets que permiten la interacci√≥n entre la capa de aplicaci√≥n y la capa de transporte. En los siguientes apartados profundizaremos en estos temas. Primero, veremos en detalle los sockets. Despu√©s, indagaremos en las arquitecturas de aplicaciones en red. Posteriormente veremos protocolos utilizados en la actualidad como HTTP que utilizamos cuando navegamos por la web, SMTP, IMAP y POP que utilizamos en las aplicaciones de correo, entre otros.\nLos sockets son la interfaz de programaci√≥n que permite a las aplicaciones comunicarse con la capa de transporte. Act√∫an como un punto de conexi√≥n bidireccional entre la capa de aplicaci√≥n y la capa de transporte, proporcionando una abstracci√≥n que oculta los detalles de bajo nivel de la comunicaci√≥n en red. En esencia, un socket es un endpoint de comunicaci√≥n que permite que los procesos intercambien datos, ya sea en la misma m√°quina o a trav√©s de una red. La API de sockets fue introducida en BSD4.1 UNIX en 1981. Fue expl√≠citamente creada, usada y lanzada por las aplicaciones de red. Est√° basada en el paradigma cliente/servidor.\nCuando una aplicaci√≥n necesita comunicarse a trav√©s de la red, crea un socket que especifica el protocolo de transporte a utilizar (TCP o UDP), la direcci√≥n IP del host de destino, y el n√∫mero de puerto del proceso receptor. El socket encapsula toda la informaci√≥n necesaria para establecer y mantener una conexi√≥n de red, proporcionando una interfaz uniforme independientemente del protocolo de transporte subyacente. Los sockets se pueden clasificar seg√∫n el protocolo de transporte que utilizan, siendo los m√°s comunes los sockets TCP y UDP, cada uno con caracter√≠sticas y casos de uso espec√≠ficos. Los detalles del funcionamiento interno de TCP y UDP los veremos en el cap√≠tulo de la capa de transporte.\nPara identificar un proceso se necesita:",
    "crumbs": [
      "Introducci√≥n a redes",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Capa de aplicaci√≥n</span>"
    ]
  },
  {
    "objectID": "ch/part_networks/application_layer/application_layer.html#socket",
    "href": "ch/part_networks/application_layer/application_layer.html#socket",
    "title": "5¬† Capa de aplicaci√≥n",
    "section": "",
    "text": "IP del host: Direcci√≥n √∫nica de 32 bits (IPv4)\nN√∫mero de puerto: Asociado con el proceso en el host\nEjemplos: HTTP (puerto 80), HTTPS (puerto 443), DNS (puerto 53)\n\n\n5.1.1 Sockets TCP\nLos sockets TCP (Transmission Control Protocol) proporcionan una comunicaci√≥n confiable y orientada a conexi√≥n entre procesos. Antes de que los datos puedan ser intercambiados, se debe establecer una conexi√≥n expl√≠cita entre el cliente y el servidor, lo que garantiza que ambos extremos est√©n listos para la comunicaci√≥n. Las caracter√≠sticas principales del socket TCP son las siguientes:\n\nOrientado a conexi√≥n: Requiere establecer una conexi√≥n antes del intercambio de datos.\nConfiabilidad: Garantiza que todos los datos enviados lleguen al destino sin errores y en orden.\nControl de flujo: Evita que el emisor sature al receptor.\nControl de congesti√≥n: Adapta la velocidad de env√≠o seg√∫n las condiciones de la red.\nFull-duplex: Permite comunicaci√≥n bidireccional simult√°nea.\n\nPara crear un socket TCP de tipo servidor, es decir, que siempre est√° activo y est√° esperando las conexiones de los clientes (arquitectura cliente-servidor), utilizaremos el m√≥dulo net de Javascript. Dentro de este m√≥dulo, utilizaremos la funci√≥n ‚ÄúcreateServer‚Äù para crear un socket de tipo servidor de TCP. Posteriormente, utilizaremos el m√©todo ‚Äúlisten‚Äù para escuchar en un puerto en concreto. En este caso, el 8888. El segundo par√°metro, que en este caso es ‚Äúlocalhost‚Äù, es opcional, y quiere decir que los clientes tienen que estar en esa red. Si obviamos el par√°metro, los clientes podr√°n conectarse desde cualquier otra m√°quina. Finalmente, el √∫ltimo par√°metro es un ‚Äúcallback‚Äù que se ejecutar√° una vez el servidor socket est√© escuchando en el puerto correctamente.\nconst net = require('net');\n\n// Crear servidor TCP\nconst server = net.createServer();\n\n// Configurar el servidor para escuchar en puerto 8888\nserver.listen(8888, 'localhost', () =&gt; {\n    console.log('Servidor TCP escuchando en localhost:8888');\n});\nPor ahora hemos bloqueado un puerto dentro de nuestra m√°quina y estamos esperando a que se conecten los clientes. Ahora, tenemos que gestionar los eventos de conexi√≥n. Para ello, utilizaremos el m√©todo ‚Äúserver.on‚Äù, especific√°ndole que el evento que queremos escuchar es la conexi√≥n ‚Äúconnection‚Äù (primer par√°metro). El segundo par√°metro es un manejador de conexi√≥n (una funci√≥n), que recibe un ‚Äúsocket‚Äù, y que ser√° invocada por el servidor socket por cada cliente que se conecte. Recordemos que TCP est√° orientado a conexi√≥n. En nuestro c√≥digo esa conexi√≥n con el cliente se realizar√° a trav√©s del ‚Äúsocket‚Äù que recibe el manejador.\n// Manejar nuevas conexiones\nserver.on('connection', (socket) =&gt; {\n    console.log('Cliente conectado:', socket.remoteAddress);\n    // El socket est√° listo para intercambiar datos\n});\nSobre este socket que hemos recibido en el manejador podemos escuchar diferentes eventos. El primer evento que veremos es ‚Äúdata‚Äù. Este evento se invocar√° cada vez que el socket reciba informaci√≥n desde el otro socket. Estos datos se procesan a trav√©s de un manejador que le pasaremos cuando escuchamos el evento ‚Äúdata‚Äù. El manejador recibir√° un par√°metro, que en el siguiente c√≥digo se denomina ‚Äúdata‚Äù, y contendr√° los datos enviados por el otro integrante de la conexi√≥n.\nsocket.on('data', (data) =&gt; {\n\n})\nPor contextualizar, supongamos que tenemos un juego con dos jugadores que est√°n en diferentes m√°quinas y estos se comunican con un servidor central. En este m√©todo recibir√≠amos por ejemplo las actualizaciones de estado de cada uno de los jugadores, y tendr√≠amos que actualizar el estado del servidor y notificar al otro jugador.\nEl siguiente evento es ‚Äúclose‚Äù. Este evento se invocar√° cuando la conexi√≥n se haya cerrado. En el manejador que le pasamos como par√°metro tendremos que realizar las operaciones oportunas en base al protocolo que estemos definiendo.\nsocket.on('close', () =&gt; {\n    console.log(`[${socket.remoteAddress}] Disconnected`);\n});\nSiguiendo con el ejemplo, este evento podr√≠a invocarse si uno de los jugadores se desconecta. En ese caso, se invocar√≠a ese m√©todo, el servidor deber√≠a actualizar a finalizado el estado del juego, y notificar al otro jugador de que la partida ha terminado.\nPor √∫ltimo, tenemos el evento ‚Äúerror‚Äù. Este puede ocurrir cuando se cierra la conexi√≥n de forma inesperada, por ejemplo, te desconectas de la red. En este caso tambi√©n se ejecutar√° el manejador de ‚Äúclose‚Äù, as√≠ que es recomendable poner la l√≥gica de limpieza all√≠, ya que el ‚Äúclose‚Äù se ejecutar√° si la conexi√≥n se cierra tanto de forma natural como inesperada, mientras que el ‚Äúerror‚Äù solo cuando es de forma inesperada. Otro posible caso en el que se ejecuta el ‚Äúerror‚Äù es si estamos tratando de escribir en un socket que est√° cerrado. Tambi√©n puede ocurrir si salta un evento de ‚Äútimeout‚Äù durante el env√≠o de datos.\nsocket.on('error', (err) =&gt; {\n    console.log(`[${socket.remoteAddress}] Error: ${err.message}`);\n});\nAhora que sabemos como manejar los eventos, s√≥lo nos falta ver como enviar informaci√≥n a trav√©s de un socket. Para ello, utilizaremos el m√©todo ‚Äúwrite‚Äù. El segundo par√°metro es un manejador que utilizaremos para capturar los errores durante el envi√≥ de informaci√≥n.\nsocket.write('Hello', (err) =&gt; {\n\n});\nEste m√©todo lo utilizar√≠amos para enviar por ejemplo las actualizaciones de estado.\nUna vez vista la parte del servidor veremos la del cliente. Para ello necesitaremos tambi√©n el m√≥dulo ‚Äúnet‚Äù y crearemos un socket con ‚Äúnew net.Socket()‚Äù. Una vez creado el socket, lo conectaremos mediante la instrucci√≥n ‚Äúsocket.connect‚Äù. El primer par√°metro es el puerto donde est√° escuchando el servidor socket en la m√°quina identificada por el segundo par√°metro. En este caso, la conexi√≥n es a ‚Äúlocalhost‚Äù y el puerto 8888. El tercer par√°metro es un callback que se ejecutar√° una vez la conexi√≥n se haya establecido.\nconst net = require('net');\n\n// Crear socket TCP\nconst socket = new net.Socket();\n\n// Conectar al servidor (establece la conexi√≥n TCP)\nsocket.connect(8888, 'localhost', () =&gt; {\n    console.log('Conectado al servidor TCP');\n    // El socket est√° listo para intercambiar datos\n});\nRespecto a los m√©todos por la parte del cliente, son los mismos que explicamos con el socket del servidor (es decir, una vez establecida la conexi√≥n). Una vez se establece la conexi√≥n, no hay diferencia entre ambos. Como matiz, en el manejador de error del cliente tenemos algunos errores a mayores, como por ejemplo si no se puede establecer la conexi√≥n.\nAmbos socket tienen que ser cerrados para liberar recursos una vez hayamos terminado. Para ello utilizaremos el m√©todo ‚Äúclose‚Äù:\nsocket.close()\nEn el caso del servidor tambi√©n:\nserver.close()\nSi no lo hacemos el bucle de eventos seguir√° activo y la aplicaci√≥n no terminar√°.\n\n\n5.1.2 Sockets UDP\nLos sockets UDP (User Datagram Protocol) proporcionan una comunicaci√≥n sin conexi√≥n y de mejor esfuerzo. El mejor esfuerzo se refiere a que va a intentar lo mejor que pueda enviar la informaci√≥n al destinatario, pero en caso de que falle, no va a volver a intentarlo ni te notificar√°. Esto contrasta con TCP que si lo reintenta y en caso de no poder te notifica. Sus caracter√≠sticas principales son las siguientes:\n\nSin conexi√≥n: No requiere establecer conexi√≥n previa\nMejor esfuerzo: No garantiza entrega, orden ni integridad de datos\nBaja latencia: Menor overhead que TCP\nSimplicidad: Protocolo m√°s simple y directo\nBroadcast/Multicast: Soporte nativo para env√≠o a m√∫ltiples destinatarios\n\nPara recibir paquetes de UDP, crearemos un servidor de UDP utilizando el paquete ‚Äúdgram‚Äù. El socket se crea mediante la expresi√≥n ‚Äúdgram.createSocket(‚Äòudp4‚Äô)‚Äù. En este caso se utiliza ‚Äúudp4‚Äù ya que utilizamos IPv4, pero si queremos utilizar IPv6 ser√≠a ‚Äúudp6‚Äù. Veremos las diferencias en el cap√≠tulo de capa de red. Una vez creado el socket, nos mantenemos a la escucha con la instrucci√≥n ‚Äúbind‚Äù. En este caso, el puerto 8888. El segundo par√°metro, en este caso ‚Äúlocalhost‚Äù, indica que solo aceptaremos peticiones de la red ‚Äúlocalhost‚Äù. Como en TCP, si lo dejamos vacio ser√° cualquier red. Tambi√©n podremos especificar otras redes. Finalmente tenemos un manejador que se invocar√° si el socket empieza a escuchar en el puerto 8888 correctamente.\nconst dgram = require('dgram');\n\n// Crear socket UDP\nconst server = dgram.createSocket('udp4');\n\n// Vincular el socket al puerto 8888\nserver.bind(8888, 'localhost', () =&gt; {\n    console.log('Servidor UDP escuchando en localhost:8888');\n});\nPara recibir mensajes, a√±adimos un manejador al evento ‚Äúmessage‚Äù. Este manejador recibe dos par√°metros. El mensaje, que es lo que nos han enviado desde el socket UDP cliente y el par√°metro rinfo, que contiene la informaci√≥n necesaria para identificar el socket que nos env√≠a informaci√≥n.\n// Escuchar mensajes entrantes\nserver.on('message', (msg, rinfo) =&gt; {\n    console.log(`Mensaje recibido de ${rinfo.address}:${rinfo.port}`);\n    // No hay conexi√≥n establecida, cada mensaje es independiente\n});\nTambi√©n podremos a√±adir un manejador de errores con el evento ‚Äúerror‚Äù. Los errores podr√≠an ser que no se puede hacer el bind al puerto. Esto puede ocurrir si el puerto ya est√° en uso o es un puerto reservado y no tenemos los permisos necesarios.\nsocket.on('error', (err) =&gt; {\n    console.error('Socket error:', err.message);\n\n});\nPara enviar los mensajes, tendremos que crear un socket con el m√≥dulo ‚Äúdgram‚Äù. Posteriormente, utilizaremos ‚ÄúcreateSocket‚Äù para crear el socket cliente que nos permitir√° enviar informaci√≥n.\nconst dgram = require('dgram');\n\n// Crear socket UDP\nconst client = dgram.createSocket('udp4');\nPara enviar la informaci√≥n utilizaremos el m√©todo send. Como no tenemos una conexi√≥n como en TCP, cada vez que enviemos informaci√≥n tenemos que indicarle cu√°l es el puerto de destino (8888) y la IP de destino (localhost). El manejador se invocar√° indic√°ndonos si ha habido un error durante el env√≠o o no. Algunos errores pueden ser que el destino no se pueda alcanzar, que el buffer de UDP est√© lleno, entre otros. Como hemos comentado, que el mensaje se haya enviado no quiere decir que el destinatario lo reciba.\nclient.send('Hola servidor UDP', 8888, 'localhost', (err) =&gt; {\n    if (err) throw err;\n    console.log('Mensaje enviado al servidor UDP');\n});\nUna pregunta que os puede surgir con UDP es, ¬øC√≥mo le escribe de vuelta el actual ‚Äúservidor‚Äù al ‚Äúcliente‚Äù? La respuesta es simple, invirtiendo los roles. Cuando creamos nuestro ‚Äúsocket cliente‚Äù sin decirle que haga un bind a un puerto determinado, cuando enviamos un mensaje se hace un bind a un puerto aleatorio que est√© libre. A trav√©s del ‚Äúrinfo‚Äù anterior tenemos tanto ‚Äúrinfo.address‚Äù como ‚Äúrinfo.port‚Äù que son la IP y el puerto. Por lo tanto, podemos escribir al cliente utilizando esa informaci√≥n.\nPara recepcionar ese mensaje, en el cliente tendr√≠amos que escuchar el evento de ‚Äúmessage‚Äù:\nclient.on('message', (msg, rinfo) =&gt; {\n    console.log(`Mensaje recibido de ${rinfo.address}:${rinfo.port}`);\n    // No hay conexi√≥n establecida, cada mensaje es independiente\n});\ny tambi√©n podr√≠amos como hicimos antes capturar el evento de errores. Con esto podemos llegar a una interesante conclusi√≥n. Tanto el socket del cliente como el del servidor son iguales. La √∫nica diferencia es que en el servidor, le indicamos especificamente en que puerto queremos escuchar. Esto lo hacemos para facilitar que los dem√°s sepan donde est√° ubicado. En el caso del cliente no tenemos esa necesidad. Podemos escoger un puerto aleatorio. Cuando enviemos un mensaje al servidor el sabr√° el puerto del cliente y podr√° escribirle tambi√©n.\nFinalmente, es necesario cerrar tanto el cliente:\nclient.close()\ncomo el servidor\nserver.close()\nSi no el bucle de eventos seguir√° activo y la ejecuci√≥n no terminar√°. Tambi√©n se liberar√°n los recursos.\n\n\n5.1.3 Servicios Requeridos y elecci√≥n de capa de transporte\nLas aplicaciones de red tienen diferentes requisitos en cuanto a los servicios que necesitan de la capa de transporte. Estos requisitos determinan qu√© protocolo de transporte es m√°s apropiado para cada aplicaci√≥n espec√≠fica.\nTransferencia Confiable: Algunas aplicaciones requieren que todos los datos enviados lleguen al destino sin errores ni p√©rdidas. Esta caracter√≠stica es fundamental para aplicaciones donde la integridad de la informaci√≥n es cr√≠tica. Ejemplos de aplicaciones que requieren una confiabilidad total son la transferencia de archivos, correo electr√≥nico, navegaci√≥n web, banca online, comercio electr√≥nico. En estos casos, la p√©rdida de datos podr√≠a resultar en archivos corruptos, mensajes incompletos o transacciones fallidas. Por otra parte, algunas aplicaciones son tolerantes a la p√©rdida de informaci√≥n, como el streaming de audio/v√≠deo, videoconferencias, juegos en tiempo real. Estas aplicaciones pueden funcionar adecuadamente incluso si se pierden algunos paquetes ocasionalmente, ya que el contenido perdido puede ser interpolado o simplemente ignorado sin afectar significativamente la experiencia del usuario.\nTemporizaci√≥n (Timing): El tiempo de respuesta es crucial para aplicaciones interactivas y en tiempo real. Algunas aplicaciones son sensibles a la latencia, como los juegos multijugador online, trading de alta frecuencia, aplicaciones de realidad virtual, control remoto de dispositivos. Estas aplicaciones requieren tiempos de respuesta muy bajos (t√≠picamente menos de 50-100ms) para proporcionar una experiencia fluida. En otros casos no es tan importante, como en el correo electr√≥nico, transferencia de archivos en segundo plano, respaldos autom√°ticos. Estas aplicaciones pueden funcionar correctamente con latencias m√°s altas sin afectar significativamente la experiencia del usuario.\nAncho de Banda: Las necesidades de ancho de banda var√≠an enormemente entre aplicaciones. Ejemplos de aplicaciones sensibles al ancho de banda son el streaming de v√≠deo 4K/8K, videoconferencias de alta calidad, transferencia de archivos grandes, respaldos de bases de datos. Estas aplicaciones requieren una tasa m√≠nima garantizada de transferencia para funcionar correctamente. Cuando una aplicaci√≥n no es sensible, a veces se denominan el√°sticas, es decir, estas aplicaciones pueden adaptarse al ancho de banda disponible, funcionando m√°s lento con conexiones limitadas pero manteni√©ndose operativas. Algunos ejemplos son: Navegaci√≥n web, correo electr√≥nico, mensajer√≠a instant√°nea.\nSeguridad: Los requisitos de seguridad incluyen varios aspectos:\n\nConfidencialidad: Garantizar que solo los destinatarios autorizados puedan leer los datos (mediante cifrado).\nIntegridad: Asegurar que los datos no han sido modificados durante la transmisi√≥n.\nAutenticaci√≥n: Verificar la identidad de las partes que se comunican.\nNo repudio: Garantizar que el emisor no pueda negar haber enviado los datos.\n\nAplicaciones como banca online, comercio electr√≥nico, mensajer√≠a privada y transferencia de documentos confidenciales requieren m√∫ltiples aspectos de seguridad, mientras que aplicaciones como streaming p√∫blico o noticias pueden tener requisitos de seguridad m√°s relajados.\nLa elecci√≥n entre sockets TCP y UDP depende de los requisitos espec√≠ficos de la aplicaci√≥n:\nUsar TCP cuando:\n\nLa integridad de datos es cr√≠tica\nSe necesita garantizar el orden de los mensajes\nLa aplicaci√≥n puede tolerar mayor latencia\nSe transfieren archivos o datos importantes\n\nUsar UDP cuando:\n\nLa velocidad y baja latencia son prioritarias\nLa aplicaci√≥n puede manejar p√©rdida ocasional de datos\nSe implementan aplicaciones en tiempo real\nSe necesita comunicaci√≥n multicast o broadcast\n\nAlgunos ejemplos de elecci√≥n son los siguientes:\n\n\n\n\n\n\n\n\n\n\n\nAplicaci√≥n\nConfiabilidad\nTemporizaci√≥n\nAncho de Banda\nSeguridad\nProtocolo T√≠pico\n\n\n\n\nTransferencia de archivos\nS√≠\nNo cr√≠tica\nEl√°stica\nSeg√∫n contenido\nTCP\n\n\nCorreo electr√≥nico\nS√≠\nNo cr√≠tica\nEl√°stica\nS√≠\nTCP\n\n\nNavegaci√≥n web\nS√≠\nModerada\nEl√°stica\nS√≠ (HTTPS)\nUDP (HTTP/3) / TCP (HTTP/1.1-2)\n\n\nStreaming de v√≠deo\nTolerante\nCr√≠tica\nM√≠nima garantizada\nSeg√∫n contenido\nUDP/TCP\n\n\nJuegos en tiempo real\nTolerante\nMuy cr√≠tica\nModerada\nS√≠\nUDP\n\n\nVideoconferencia\nTolerante\nCr√≠tica\nM√≠nima garantizada\nS√≠\nUDP/TCP\n\n\nDNS\nTolerante\nCr√≠tica\nEl√°stica\nCreciente (DoH/DoT)\nUDP/TCP\n\n\n\nEn esta tabla igual hay un detalle que os llama la atenci√≥n. Hemos dicho que UDP no es confiable. Se puede perder informaci√≥n o incluso llegar en distinto orden. Sin embargo, en la navegaci√≥n web que requiere de confiabilidad, se indica que se utiliza UDP cuando el protocolo es HTTP/3. ¬øC√≥mo es esto posible? La respuesta es QUIC, que veremos posteriormente en este cap√≠tulo. Lo interesante en este caso es darnos cuenta de que podemos tener una comunicaci√≥n confiable (QUIC) a trav√©s de un medio no confiable (UDP). Para ello, el protocolo QUIC a√±ade una nueva capa (encapsular) con la informaci√≥n y l√≥gica necesaria para garantizar la confiabilidad en ambos extremos. Otra forma de verlo es que a veces podemos movernos entre TCP y UDP a√±adiendo los requisitos que necesitemos a UDP, que es el protocolo m√°s b√°sico, y evitar algunas de las desventajas de TCP.",
    "crumbs": [
      "Introducci√≥n a redes",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Capa de aplicaci√≥n</span>"
    ]
  },
  {
    "objectID": "ch/part_networks/application_layer/application_layer.html#arquitecturas-de-aplicaciones-distribuidas",
    "href": "ch/part_networks/application_layer/application_layer.html#arquitecturas-de-aplicaciones-distribuidas",
    "title": "5¬† Capa de aplicaci√≥n",
    "section": "5.2 Arquitecturas de Aplicaciones Distribuidas",
    "text": "5.2 Arquitecturas de Aplicaciones Distribuidas\nLas arquitecturas en las aplicaciones distribuidas, es decir, con m√°s de un nodo, indican c√≥mo se conectan entre s√≠ los nodos y cu√°l ser√° el rol de cada uno de los nodos. A grandes rasgos, distinguimos tres tipos de arquitecturas: cliente - servidor, peer-to-peer e h√≠brida. La arquitectura cliente - servidor la mencionamos en el ejemplo anterior. En el caso de peer-to-peer, tenemos un conjunto de nodos que se conectan entre s√≠. La topolog√≠a de las conexiones no tiene por qu√© ser un grafo completo, y puede variar a lo largo del tiempo. En este caso la funcionalidad est√° distribuida por los nodos. Un ejemplo de peer-to-peer es BitTorrent. Finalmente, las arquitecturas h√≠bridas son una mezcla entre ambas, teniendo generalmente autoridades centrales que permiten mantener la red en funcionamiento, o determinadas funcionalidades. Las arquitecturas h√≠bridas son m√°s comunes que las puramente peer-to-peer.\nEn los siguientes apartados exploraremos estas tres arquitecturas, as√≠ como las aplicaciones populares y juegos para cada una de ellas.\n\n5.2.1 Arquitectura Cliente/Servidor\nLa arquitectura cliente-servidor es un modelo fundamental de computaci√≥n distribuida donde m√∫ltiples clientes solicitan servicios, recursos o datos de un servidor centralizado. En este paradigma, el servidor act√∫a como el punto central de control y coordinaci√≥n, mientras que los clientes consumen los servicios proporcionados. Esta arquitectura se caracteriza por tener un host siempre activo (el servidor) que atiende las peticiones de numerosos hosts clientes, los cuales pueden conectarse y desconectarse din√°micamente sin afectar el funcionamiento del sistema. Los clientes poseen direcciones IP din√°micas y no se comunican directamente entre s√≠, sino que toda la comunicaci√≥n se canaliza a trav√©s del servidor.\nEn el funcionamiento t√≠pico de esta arquitectura, el cliente inicia la comunicaci√≥n enviando una solicitud al servidor, especificando qu√© servicio o recurso necesita. El servidor procesa esta petici√≥n, accede a los datos o recursos necesarios, y env√≠a una respuesta de vuelta al cliente. Este modelo permite la centralizaci√≥n de recursos, datos y l√≥gica de negocio, facilitando el mantenimiento, la seguridad y la consistencia del sistema. El servidor debe tener una direcci√≥n IP fija y conocida para que los clientes puedan localizarlo, y t√≠picamente opera de forma continua para estar disponible cuando los clientes lo necesiten.\nLos requerimientos de infraestructura para sistemas cliente-servidor populares son considerables. Los servidores deben ser capaces de manejar m√∫ltiples conexiones simult√°neas, procesar grandes vol√∫menes de datos y mantener alta disponibilidad. Esto frecuentemente requiere centros de datos con clusters de servidores, sistemas de balanceamiento de carga, redundancia y respaldo, as√≠ como conexiones de red de alto ancho de banda. Para aplicaciones con millones de usuarios, como las redes sociales o servicios de streaming, la infraestructura puede incluir m√∫ltiples centros de datos distribuidos geogr√°ficamente para optimizar la latencia y garantizar la disponibilidad del servicio.\nEjemplos cotidianos de arquitectura cliente-servidor incluyen aplicaciones web como Netflix, donde el cliente (navegador web o aplicaci√≥n m√≥vil) solicita contenido de v√≠deo al servidor, que almacena y transmite las pel√≠culas y series. Spotify funciona de manera similar, donde los clientes solicitan canciones y playlists que est√°n almacenadas en los servidores de la plataforma. Instagram representa otro caso t√≠pico donde los clientes suben fotos y v√≠deos a los servidores, y otros usuarios pueden solicitar y visualizar este contenido. Los servicios de correo electr√≥nico como Gmail operan bajo este modelo, donde los servidores almacenan y gestionan los mensajes mientras los clientes acceden a ellos a trav√©s de aplicaciones web o m√≥viles.\nEn el contexto de los videojuegos, la arquitectura cliente-servidor se ha convertido en el est√°ndar para juegos multijugador masivos y competitivos. El servidor mantiene el estado autoritativo del juego, procesando todas las acciones de los jugadores y distribuyendo las actualizaciones correspondientes. Los clientes se encargan principalmente de la presentaci√≥n visual, la captura de entrada del usuario y la comunicaci√≥n con el servidor. Esta separaci√≥n permite que el servidor tenga control total sobre la l√≥gica del juego, previniendo trampas y garantizando la coherencia del estado del juego entre todos los participantes.\nEjemplos t√≠picos de esta arquitectura incluyen juegos como World of Warcraft, donde miles de jugadores se conectan a servidores dedicados que mantienen mundos persistentes. Counter-Strike: Global Offensive utiliza servidores dedicados para partidas competitivas, asegurando que todas las acciones sean validadas centralmente. League of Legends emplea esta arquitectura para sus partidas clasificatorias, donde el servidor procesa todos los movimientos, ataques y habilidades de los campeones. Fortnite Battle Royale tambi√©n implementa servidores dedicados para mantener la sincronizaci√≥n entre los 100 jugadores en cada partida.\nLos juegos de estrategia en tiempo real como StarCraft II y Age of Empires IV tambi√©n adoptan esta arquitectura para sus modos multijugador competitivos. En estos casos, el servidor procesa todas las √≥rdenes de construcci√≥n, movimiento de unidades y combates, garantizando que ambos jugadores vean exactamente el mismo estado del juego. Los MMORPGs como Final Fantasy XIV y Guild Wars 2 son ejemplos perfectos donde el servidor no solo mantiene el estado del juego sino tambi√©n la persistencia de los personajes, inventarios y progreso de los jugadores.\nUno de los principales problemas en juegos cliente-servidor es la latencia o ‚Äúlag‚Äù, que se refiere al tiempo que tarda una acci√≥n del jugador en ser procesada por el servidor y reflejada de vuelta al cliente. Esta latencia puede causar una experiencia de juego frustrante, especialmente en juegos de acci√≥n r√°pida como shooters en primera persona. Para mitigar este problema, muchos juegos implementan t√©cnicas como la predicci√≥n del lado del cliente, donde el cliente asume temporalmente el resultado de una acci√≥n antes de recibir la confirmaci√≥n del servidor.\nEl problema de la sincronizaci√≥n es otro desaf√≠o cr√≠tico en los juegos cliente-servidor. Cuando m√∫ltiples jugadores interact√∫an simult√°neamente, el servidor debe procesar las acciones en un orden espec√≠fico y comunicar los resultados a todos los clientes de manera coherente. Los juegos como Rocket League han tenido que implementar sistemas sofisticados de interpolaci√≥n y extrapolaci√≥n para mantener la fluidez del juego mientras se sincronizan las posiciones de la pelota y los veh√≠culos entre todos los jugadores.\nLos servidores sobrecargados representan un problema significativo, especialmente durante los lanzamientos de juegos populares o eventos especiales. Diablo III experiment√≥ problemas masivos en su lanzamiento debido a que sus servidores no pod√≠an manejar la cantidad de jugadores conectados simult√°neamente. World of Warcraft ha enfrentado desaf√≠os similares durante las expansiones, donde millones de jugadores intentan conectarse al mismo tiempo, causando colas de conexi√≥n y ca√≠das del servidor.\nLa p√©rdida de conexi√≥n con el servidor es otro problema com√∫n que puede arruinar la experiencia de juego. En juegos competitivos como Dota 2 o Overwatch, una desconexi√≥n del servidor puede resultar en penalizaciones para el jugador, incluso si la falta no fue suya. Los desarrolladores han implementado sistemas de reconexi√≥n autom√°tica y buffers de tolerancia para minimizar el impacto de desconexiones temporales, pero el problema persiste como una limitaci√≥n inherente del modelo cliente-servidor.\nLos costes de infraestructura representan un desaf√≠o econ√≥mico significativo para los desarrolladores de juegos que adoptan esta arquitectura. Mantener granjas de servidores, centros de datos distribuidos globalmente y el ancho de banda necesario para soportar millones de jugadores concurrentes requiere inversiones masivas. Epic Games, por ejemplo, ha invertido cientos de millones de d√≥lares en infraestructura para soportar Fortnite, incluyendo partnerships con proveedores de servicios en la nube como Amazon Web Services para escalar din√°micamente seg√∫n la demanda.\nA pesar de estos desaf√≠os, la arquitectura cliente-servidor sigue siendo la opci√≥n preferida para juegos multijugador serios debido a sus ventajas en t√©rminos de seguridad, control y escalabilidad. Los avances en tecnolog√≠as de red, computaci√≥n en la nube y t√©cnicas de optimizaci√≥n contin√∫an mejorando la viabilidad de esta arquitectura. Los desarrolladores modernos implementan soluciones h√≠bridas que combinan servidores dedicados con t√©cnicas de peer-to-peer para diferentes aspectos del juego, optimizando tanto la experiencia del jugador como los costes operativos.\n\n\n5.2.2 Arquitectura Peer-to-Peer (P2P)\nLa arquitectura peer-to-peer (P2P) es un modelo de computaci√≥n distribuida donde los participantes (pares o peers) comparten recursos directamente entre s√≠ sin depender de servidores centralizados. A diferencia del modelo cliente-servidor, en P2P no existe una entidad central que controle o coordine las comunicaciones; en su lugar, cada participante act√∫a simult√°neamente como cliente y servidor, compartiendo y consumiendo recursos de manera equitativa. Esta arquitectura se caracteriza por la ausencia de dependencia de servidores siempre activos, permitiendo que los pares se conecten de forma intermitente y estableciendo comunicaci√≥n directa entre ellos.\nEl funcionamiento de las redes P2P se basa en la colaboraci√≥n voluntaria de los participantes, donde cada peer contribuye con recursos computacionales, de almacenamiento o ancho de banda al conjunto de la red. Los peers pueden unirse o abandonar la red libremente sin comprometer significativamente su funcionamiento, ya que la arquitectura es inherentemente autoescalable: cuantos m√°s participantes se unen, m√°s recursos totales est√°n disponibles. Esta caracter√≠stica contrasta marcadamente con los sistemas centralizados, donde el servidor puede convertirse en un cuello de botella cuando aumenta el n√∫mero de usuarios.\nExisten diferentes clasificaciones de arquitecturas P2P seg√∫n su nivel de pureza y estructura:\n\nPor pureza, encontramos sistemas centralizados como Napster (que depend√≠a de un servidor central para indexar archivos) y BitTorrent (que utiliza trackers centrales para coordinar descargas), versus sistemas completamente descentralizados como Freenet y Gnutella, que no dependen de ning√∫n equipo espec√≠fico para su funcionamiento.\nPor paridad, las redes pueden ser estructuradas, donde existen categor√≠as espec√≠ficas de nodos con control sobre la estructura de la red, o desestructuradas, donde las conexiones y la topolog√≠a emergen de manera arbitraria seg√∫n las decisiones individuales de cada peer.\n\nTambi√©n existen diferentes tipos de topolog√≠as:\n\nLa topolog√≠a Full Mesh es la m√°s robusta pero tambi√©n la m√°s demandante en t√©rminos de recursos, ya que cada peer se conecta directamente con todos los dem√°s participantes de la red. Esta configuraci√≥n ofrece la m√°xima redundancia y la latencia m√°s baja posible entre cualquier par de nodos, pero el n√∫mero de conexiones crece exponencialmente con cada nuevo participante, haciendo que sea pr√°ctica solo para grupos muy peque√±os de peers.\nLa topolog√≠a Ring organiza los peers en una estructura circular donde cada nodo se conecta √∫nicamente con sus vecinos inmediatos, formando un anillo cerrado. Los datos viajan alrededor del anillo hasta llegar a su destino, lo que puede introducir latencia variable dependiendo de la distancia entre peers en la estructura circular. Esta topolog√≠a es m√°s eficiente en t√©rminos de conexiones que el full mesh, pero presenta vulnerabilidades ya que la falla de un solo peer puede interrumpir la comunicaci√≥n en todo el anillo, aunque existen implementaciones bidireccionales que mitigan este riesgo.\nLa topolog√≠a Star representa un enfoque pseudo-P2P donde un peer central act√∫a como hub para todos los dem√°s participantes. Aunque t√©cnicamente sigue siendo P2P porque no requiere un servidor dedicado, esta configuraci√≥n introduce un punto √∫nico de falla en el peer central. Sin embargo, es la m√°s eficiente en t√©rminos de gesti√≥n de conexiones y sincronizaci√≥n, ya que reduce significativamente la complejidad de coordinaci√≥n. Es com√∫n en juegos cooperativos donde el host del juego act√∫a como el nodo central, gestionando el estado del juego y redistribuyendo informaci√≥n a los otros jugadores.\nLas topolog√≠as H√≠bridas combinan elementos de diferentes enfoques seg√∫n los requerimientos espec√≠ficos del juego o aplicaci√≥n. Por ejemplo, un juego podr√≠a usar una topolog√≠a de star para la l√≥gica principal del juego mientras implementa conexiones mesh directas para comunicaci√≥n de voz entre jugadores. Estas implementaciones permiten optimizar diferentes aspectos del rendimiento, balanceando latencia, confiabilidad y eficiencia de recursos seg√∫n las necesidades particulares de cada funci√≥n dentro del sistema P2P.\n\n\n\n\n\n\n\n\ngraph TB\n    P1((Peer 1))\n    P2((Peer 2))\n    P3((Peer 3))\n    P4((Peer 4))\n    P5((Peer 5))\n    \n    P1 --- P2\n    P1 --- P3\n    P1 --- P4\n    P1 --- P5\n    P2 --- P3\n    P2 --- P4\n    P2 --- P5\n    P3 --- P4\n    P3 --- P5\n    P4 --- P5\n\n    classDef peerNode fill:#e1f5fe,stroke:#01579b,stroke-width:2px\n    classDef hubNode fill:#fff3e0,stroke:#e65100,stroke-width:3px\n\n    class P1,P2,P3,P4,P5,R1,R2,R3,R4,R5,S2,S3,S4,S5,H2,H3,H4,H5,H6 peerNode\n    class S1,H1 hubNode\n\n\n Full Mesh Topology \n\n\n\n\n\n\n\n\ngraph TB   \n    R1((Peer 1))\n    R2((Peer 2))\n    R3((Peer 3))\n    R4((Peer 4))\n    R5((Peer 5))\n    \n    R1 --- R2\n    R2 --- R3\n    R3 --- R4\n    R4 --- R5\n    R5 --- R1\n\n    classDef peerNode fill:#e1f5fe,stroke:#01579b,stroke-width:2px\n    classDef hubNode fill:#fff3e0,stroke:#e65100,stroke-width:3px\n\n    class P1,P2,P3,P4,P5,R1,R2,R3,R4,R5,S2,S3,S4,S5,H2,H3,H4,H5,H6 peerNode\n    class S1,H1 hubNode\n\n\n Ring Topology \n\n\n\n\n\n\n\ngraph TB\n    H1((Hub))\n    H2((Peer 2))\n    H3((Peer 3))\n    H4((Peer 4))\n    H5((Peer 5))\n    H6((Peer 6))\n    \n    H1 --- H2\n    H1 --- H3\n    H2 --- H3\n    H4 --- H5\n    H4 --- H6\n    H5 --- H6\n    H3 --- H4\n    \n    classDef peerNode fill:#e1f5fe,stroke:#01579b,stroke-width:2px\n    classDef hubNode fill:#fff3e0,stroke:#e65100,stroke-width:3px\n    \n    class P1,P2,P3,P4,P5,R1,R2,R3,R4,R5,S2,S3,S4,S5,H2,H3,H4,H5,H6 peerNode\n    class S1,H1 hubNode\n\n\nHybrid Topology\n\n\n\n\n\n\n\n\n\n\ngraph TB\n    S1((Host/Hub))\n    S2((Peer 2))\n    S3((Peer 3))\n    S4((Peer 4))\n    S5((Peer 5))\n    \n    S1 --- S2\n    S1 --- S3\n    S1 --- S4\n    S1 --- S5\n\n    classDef peerNode fill:#e1f5fe,stroke:#01579b,stroke-width:2px\n    classDef hubNode fill:#fff3e0,stroke:#e65100,stroke-width:3px\n\n    class P1,P2,P3,P4,P5,R1,R2,R3,R4,R5,S2,S3,S4,S5,H2,H3,H4,H5,H6 peerNode\n    class S1,H1 hubNode\n\n\n Star Topology (Pseudo-P2P) \n\n\n\n\n\nLas aplicaciones cotidianas de P2P incluyen sistemas de compartici√≥n de archivos como BitTorrent, donde los usuarios descargan fragmentos de archivos desde m√∫ltiples peers simult√°neamente, distribuyendo la carga y mejorando la velocidad de descarga. Skype utiliz√≥ originalmente arquitectura P2P (similar a la arquitectura h√≠brida en (hybrid-topology?)) para enrutar llamadas de voz a trav√©s de la red de usuarios, aprovechando el ancho de banda y poder computacional distribuido. Las criptomonedas como Bitcoin operan sobre redes P2P completamente descentralizadas, donde cada nodo mantiene una copia del blockchain y participa en la validaci√≥n de transacciones. Los sistemas de mensajer√≠a como Tox y Briar implementan comunicaci√≥n P2P directa para garantizar privacidad y resistencia a la censura.\nLas redes de distribuci√≥n de contenido P2P como IPFS (InterPlanetary File System) permiten almacenar y distribuir informaci√≥n de manera descentralizada, donde cada participante contribuye espacio de almacenamiento y ancho de banda. Los juegos masivos como algunos servidores privados de World of Warcraft han experimentado con arquitecturas P2P para distribuir actualizaciones y contenido. Las aplicaciones de videoconferencia como Jitsi Meet pueden operar en modo P2P para llamadas peque√±as, estableciendo conexiones directas entre participantes para reducir latencia y eliminar la dependencia de servidores centrales.\nEn el contexto de los videojuegos, la arquitectura P2P ofrece ventajas √∫nicas pero tambi√©n presenta desaf√≠os espec√≠ficos. Los juegos P2P eliminan la necesidad de servidores dedicados, reduciendo costos operativos y permitiendo que los jugadores contin√∫en partidas incluso si los servidores oficiales est√°n fuera de l√≠nea. Esta arquitectura es especialmente efectiva en juegos con pocos participantes donde la latencia directa entre jugadores puede ser menor que la latencia a un servidor centralizado. Cada peer mantiene su propia copia del estado del juego y sincroniza cambios con otros participantes.\nLos juegos de lucha como Street Fighter 6, Tekken 8 y Guilty Gear Strive utilizan arquitecturas P2P sofisticadas con tecnolog√≠a de rollback netcode. En estos juegos, ambos jugadores mantienen una simulaci√≥n completa del combate y sincronizan entradas peri√≥dicamente. Cuando hay discrepancias debido a latencia, el sistema ‚Äúretrocede‚Äù el estado del juego y lo recalcula con la informaci√≥n correcta, creando una experiencia fluida incluso con conexiones imperfectas. Esta implementaci√≥n es ideal para juegos 1v1 donde la latencia directa entre jugadores suele ser menor que la latencia a un servidor dedicado.\nLos juegos cooperativos como Portal 2, It Takes Two y A Way Out aprovechan las ventajas de P2P para ofrecer experiencias de baja latencia entre un peque√±o grupo de jugadores. En estos casos, uno de los peers act√∫a como ‚Äúhost‚Äù manteniendo el estado autoritativo del juego mientras otros se conectan directamente. Esta configuraci√≥n elimina la necesidad de servidores dedicados para experiencias cooperativas, permitiendo que los desarrolladores ofrezcan funcionalidad multijugador sin costos adicionales de infraestructura. Los juegos de estrategia en tiempo real como Age of Empires II y StarCraft: Brood War originalmente utilizaban P2P, donde todos los jugadores ejecutaban la misma simulaci√≥n y compart√≠an comandos.\nSin embargo, los juegos P2P enfrentan desaf√≠os significativos en t√©rminos de seguridad y prevenci√≥n de trampas. Dado que cada peer tiene acceso completo al estado del juego, es relativamente f√°cil para usuarios malintencionados modificar datos o implementar cheats. Los juegos como Dark Souls han experimentado problemas con hackers que pueden modificar estad√≠sticas de personajes o comportamientos del juego. La validaci√≥n distribuida es compleja y requiere que m√∫ltiples peers acuerden sobre la validez de las acciones, lo que puede ser problem√°tico cuando uno de los participantes est√° haciendo trampa.\nLa sincronizaci√≥n representa otro desaf√≠o mayor en juegos P2P, especialmente cuando el n√∫mero de participantes aumenta. En juegos con muchos jugadores, cada peer debe comunicarse con todos los dem√°s, creando un crecimiento cuadr√°tico en el tr√°fico de red. Minecraft multijugador en modo LAN ejemplifica este problema: funciona bien para grupos peque√±os pero se vuelve inmanejable con muchos jugadores. Los problemas de conectividad NAT tambi√©n complican las conexiones P2P, ya que muchos jugadores est√°n detr√°s de routers y firewalls que impiden conexiones directas, requiriendo t√©cnicas como hole punching o servidores de relay para establecer comunicaci√≥n entre peers.",
    "crumbs": [
      "Introducci√≥n a redes",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Capa de aplicaci√≥n</span>"
    ]
  },
  {
    "objectID": "ch/part_networks/application_layer/application_layer.html#protocolos",
    "href": "ch/part_networks/application_layer/application_layer.html#protocolos",
    "title": "5¬† Capa de aplicaci√≥n",
    "section": "5.3 Protocolos",
    "text": "5.3 Protocolos\n\n5.3.1 HTTP\nHTTP (HyperText Transfer Protocol) es un protocolo p√∫blico definido en un RFC que sirve para la transferencia de informaci√≥n en la World Wide Web. Es un protocolo de comunicaci√≥n que permite la transferencia de recursos (como p√°ginas web, im√°genes, documentos, etc.) entre clientes (navegadores web) y servidores web a trav√©s de Internet. El protocolo utiliza texto legible tanto para los comandos como para las respuestas. El protocolo opera t√≠picamente sobre TCP/IP, utilizando el puerto 80 para conexiones HTTP est√°ndar y el puerto 443 para conexiones HTTPS seguras.\nHTTP opera bajo el modelo cliente-servidor, donde los navegadores web (u otros programas) act√∫an como clientes que solicitan recursos, y los servidores web responden proporcionando el contenido solicitado. Esta arquitectura descentralizada permite que la web sea escalable y resiliente, distribuyendo la carga de trabajo entre diferentes servidores. Adem√°s, al ser un protocolo sin estado, se facilita su escalabilidad. Que no tenga estado implica que cada vez que se realiza una petici√≥n es completamente independiente de las anteriores.\nCada recurso en el servidor se identifica a trav√©s de una URL (Uniform Resource Locator), que especifica no solo la ubicaci√≥n del recurso sino tambi√©n el protocolo necesario para acceder a √©l. Una URL t√≠pica como ‚Äúhttps://www.ejemplo.com/pagina.html‚Äù contiene el protocolo (https), el nombre del host (www.ejemplo.com), y la ruta espec√≠fica del recurso (/pagina.html). Esta estructura jer√°rquica permite organizar y localizar millones de recursos de manera eficiente. Las URL pueden referenciar archivos HTML, hojas de estilo CSS, c√≥digo, binarios, etc.\nLas acciones en HTTP est√°n asociadas a un verbo que indica el objeto de las mismas. Los principales son los siguientes:\n\nGET: Pedir el objeto de la URL al servidor. Es una operaci√≥n idenpotente, si la repetimos varias veces el resultado deber√≠a de ser siempre el mismo. No cambia el estado del servidor. El cuerpo del mensaje est√° vacio. Cuando descargamos im√°genes en Instagram o similares, los comentarios, etc lo hacemos a trav√©s de GET.\nPOST: Se utiliza para pedir/enviar un objeto asociado a una URL cuando este depende de los datos de un formulario. Puede cambiar el estado del servidor. Por ejemplo, cuando nos registamos en una p√°gina estar√≠amos haciendo un POST.\nHEAD: Es igual que el GET pero no devuelve nada. Se utiliza para debuguear.\nPUT: Nos permite cargar un objeto en la URL. Es una operaci√≥n idempotente, si la repetimos varias veces el resultado ser√° siempre el mismo.\nDELETE: Borra el recurso asociado a la URL.\n\nCabe destacar que este uso esperado de los verbos lo tenemos que implementar nosotros. Nada nos quita de hacer que un GET borre cosas, o se utilice para acciones para las que no estaba dise√±ado. Sin embargo, seguir la especificaci√≥n nos va a permitir que otros usuarios de nuestra API la puedan utilizar correctamente de una forma m√°s sencilla.\nTodas estas acciones, que en la jerga de HTML se llaman peticiones, tienen asociada una respuesta. Esta respuesta est√° formada por un c√≥digo de respuesta, el cuerpo, y cookies. Los c√≥digos de respuesta son un identificador num√©rico de 3 cifras que indica el resultado de la petici√≥n y est√°n asociados a un identificador textual. Se dividen en 5 grupos:\n\n1XX: Respuesta informativa, se√±alan que la solicitud est√° siendo procesada.\n2XX: Respuesta satisfactoria, la solicitud se recibi√≥, entendi√≥ y se complet√≥ con √©xito. Por ejemplo, 200 OK.\n3XX: Redirecciones, informan que se necesita tomar una acci√≥n adicional para completar la solicitud. Por ejemplo, 301 Moved Permanently: Indica que el recurso se ha movido de forma permanente a una nueva URL.\n4XX: Error en los clientes, indican un error en la solicitud del cliente, como solicitar un recurso inexistente. Por ejemplo, 400 Bad Request, 403 Forbidden o 404 Not Found.\n5XX: Error en los servidores, se√±alan que el servidor no pudo completar una solicitud debido a un error interno. Por ejemplo, 500 Internal Server Error o 503 Service Unavailable.\n\nDependiendo de la versi√≥n de HTTP se utilizar√°n diferentes tipos de conexi√≥n para enviar las peticiones. En HTTP/1.0, se utilizaban conexiones no persistentes, y para cada recurso se creaba una nueva conexi√≥n, incurriendo en un retardo de 2 RTT por objeto y la sobrecarga de abrir y cerrar conexiones. A partir de HTTP/1.1, se utilizan conexiones persistentes, donde varios objetos pueden ser enviados en la misma conexi√≥n, y por lo tanto, teniendo un retardo de 1 RTT por objeto. La limitaci√≥n que ten√≠a HTTP/1.1, es que si uno de los recursos tardaba mucho, ralentizaba a los que iban detr√°s. Para solucionar este problema se utilizan m√∫ltiples streams independientes sobre una conexi√≥n, solucionando el problema de que un recurso bloquee a los posteriores.\n\n\n\n\n\n\nsequenceDiagram\n    participant C as Cliente (Navegador)\n    participant S as Servidor Web\n    Note over C,S: Solicitud del primer recurso\n    C-&gt;&gt;S: 1. SYN - Establecer conexi√≥n TCP\n    S-&gt;&gt;C: 2. SYN-ACK - Confirmar conexi√≥n\n    C-&gt;&gt;S: 3. ACK - Conexi√≥n establecida\n    \n    C-&gt;&gt;S: 4. GET /index.html HTTP/1.0\n    S-&gt;&gt;C: 5. HTTP/1.0 200 OK + contenido HTML\n    \n    C-&gt;&gt;S: 6. FIN - Cerrar conexi√≥n TCP\n    S-&gt;&gt;C: 7. FIN-ACK - Confirmar cierre\n    C-&gt;&gt;S: 8. ACK - Conexi√≥n cerrada\n\n    Note over C,S: Solicitud del segundo recurso\n    C-&gt;&gt;S: 9. SYN - Nueva conexi√≥n TCP\n    S-&gt;&gt;C: 10. SYN-ACK - Confirmar nueva conexi√≥n\n    C-&gt;&gt;S: 11. ACK - Nueva conexi√≥n establecida\n    \n    C-&gt;&gt;S: 12. GET /imagen.jpg HTTP/1.0\n    S-&gt;&gt;C: 13. HTTP/1.0 200 OK + imagen\n    \n    C-&gt;&gt;S: 14. FIN - Cerrar conexi√≥n TCP\n    S-&gt;&gt;C: 15. FIN-ACK - Confirmar cierre\n    C-&gt;&gt;S: 16. ACK - Conexi√≥n cerrada\n    Note over C,S: Tiempo total: 4 RTT + tiempo de transferencia\n\n\n\n\n\n\n\n\n\nsequenceDiagram\n    participant C as Cliente (Navegador)\n    participant S as Servidor Web\n    \n    C-&gt;&gt;S: 1. SYN - Establecer conexi√≥n TCP\n    S-&gt;&gt;C: 2. SYN-ACK - Confirmar conexi√≥n\n    C-&gt;&gt;S: 3. ACK - Conexi√≥n establecida\n    \n    C-&gt;&gt;S: 4. GET /index.html HTTP/1.1&lt;br/&gt;Host: ejemplo.com&lt;br/&gt;Connection: keep-alive\n    S-&gt;&gt;C: 5. HTTP/1.1 200 OK&lt;br/&gt;Connection: keep-alive&lt;br/&gt;+ contenido HTML\n        \n    C-&gt;&gt;S: 6. GET /imagen.jpg HTTP/1.1&lt;br/&gt;Host: ejemplo.com&lt;br/&gt;Connection: keep-alive\n    S-&gt;&gt;C: 7. HTTP/1.1 200 OK&lt;br/&gt;Connection: keep-alive&lt;br/&gt;+ imagen\n    \n    Note over C,S: M√°s recursos pueden solicitarse...\n    \n    C-&gt;&gt;S: 8. Connection: close (cuando termine)    \n    Note over C,S: Tiempo total: 1 RTT + tiempo de transferencia\n\n\n\n\n\n\n\nPor √∫ltimo, tiene un mecanismo adicional, las cookies que permiten guardar informaci√≥n en forma de pares de clave valor en el cliente. Las cookies se pueden configurar utilizando el campo de respuesta de la petici√≥n. En general se utilizan para mantener sesiones, personalizaci√≥n, an√°lisis o con fines publicitarios. Estas cookies pueden ser propias, cuando es de la web que estamos navegando, o de terceros, cuando es un servicio que utiliza la web. Adem√°s del par de clave valor, tambi√©n incluyen una fecha de expiraci√≥n y del dominio del servidor. Las cookies expiran cuando pasa la fecha de expiraci√≥n, aunque tambi√©n pueden ser permanentes. El dominio es por seguridad, ya que determinadas cookies s√≥lo queremos que sean accedidas por su dominio, con el fin de evitar suplantaciones de identidad.\nExiste una variante de HTTP denominada HTTPS (Secure HyperText Transfer Protocol) en la cual las peticiones y sus respuestas no van en texto plano y se ha convertido en el est√°ndar de la Web. De hecho algunos navegadores ya no dejan acceder a sitios a trav√©s de HTTP.\nEl protocolo opera generalmente sobre TCP, pero a partir de HTTP/3 opera sobre QUIC, que es un protocolo que implementa mecanismos de comunicaci√≥n fiables sobre UDP. HTTP/3 est√° soportado por la gran mayor√≠a de los navegadores actuales, y el soporte en los servidores est√° creciendo.\nEn determinadas situaciones para disminuir el tiempo de las peticiones se utilizan servidores proxy. Los servidores proxy son unos intermediarios, que analizan las peticiones, si pueden resolverlas ellos contestan directamente, y si no contestan a trav√©s de la petici√≥n al servidor. Las ventajas es que se obtiene una navegaci√≥n m√°s r√°pida, se reduce el tr√°fico, y adem√°s ganamos seguridad y anonimato. Suelen estar localizados en los navegadores (cach√© local), ISP o CDNs. En concreto, los servidores proxy cachean las peticiones GET, ya que es una operaci√≥n idempotente, y utilizan la herramienta del GET condicional donde en caso de que no haya actualizaci√≥n no devuelve nada, ahorrando el tiempo de env√≠o del recurso.\n\n\n5.3.2 DNS\nDNS (Domain Name System) es uno de los protocolos m√°s importantes de Internet. El objetivo de DNS es simple, traducir identificadores textuales que sean f√°cil de recordar por humanos a direcciones IP. Por ejemplo, traducir ‚Äúwww.google.es‚Äù a 142.250.200.67. El sistema de DNS est√° dise√±ado como un sistema distribuido sin servidores centrales, lo que le permite distribuir la carga entre diferentes nodos y ser tolerante a fallos.\nEl sistema distribuido de DNS est√° formado por una estructura jer√°rquica de 4 tipos de nodos:\n\nServidores ra√≠z: Son las ra√≠ces de la jerarqu√≠a DNS y representan el nivel m√°s alto del sistema. Existen 13 servidores ra√≠z l√≥gicos identificados con letras de la A a la M (a.root-servers.net hasta m.root-servers.net), aunque f√≠sicamente hay cientos de servidores distribuidos. Estos servidores conocen la ubicaci√≥n de todos los servidores TLD y responden a consultas sobre d√≥nde encontrar informaci√≥n de dominios de nivel superior.\nServidores TLD (Top Domain Level): Son responsables de los dominios de nivel superior como .com, .org, .net, .edu, y los dominios de pa√≠s como .es, .mx, .ar. Mantienen informaci√≥n sobre qu√© servidores autoritativos son responsables de cada dominio espec√≠fico dentro de su TLD.\nServidores autoritativos: Contienen la informaci√≥n definitiva y oficial sobre un dominio espec√≠fico. Son los que tienen la autoridad final sobre las zonas DNS que administran y proporcionan las respuestas definitivas sobre las direcciones IP de los hosts dentro de su dominio.\nServidores locales: Tambi√©n llamados servidores recursivos o resolvers, son los que reciben las consultas directamente de los clientes (como tu computadora). Se encargan de realizar todo el proceso de resoluci√≥n consultando a los diferentes niveles de la jerarqu√≠a DNS hasta obtener la respuesta final, que luego env√≠an de vuelta al cliente. Suelen mantener una cach√© para mejorar la eficiencia.\n\nPara entender el proceso vamos a realizar un ejemplo de c√≥mo ser√≠a la consulta para resolver la URL www.google.es a una IP con DNS. El diagrama de secuencia lo pod√©is ver en la (DNS-GOOGLE?). Los pasos para la resoluci√≥n del DNS son los siguientes:\n\nVerificaci√≥n de cach√© local del sistema operativo: Cuando escribes una URL en tu navegador, el sistema operativo primero verifica su cach√© local para ver si ya tiene almacenada la direcci√≥n IP correspondiente. Si la encuentra y no ha expirado, la utiliza inmediatamente sin necesidad de hacer consultas externas.\nConsulta al servidor DNS local: Si la informaci√≥n no est√° en cach√© o ha expirado, el cliente env√≠a una consulta al servidor DNS configurado (generalmente proporcionado por tu ISP o servicios como 8.8.8.8 de Google). Esta consulta es recursiva, lo que significa que el cliente espera una respuesta completa.\nEl servidor DNS local consulta al servidor ra√≠z: El servidor DNS local, al no tener la informaci√≥n solicitada, inicia el proceso de resoluci√≥n consultando a uno de los 13 servidores ra√≠z. Le pregunta: ‚Äú¬øQui√©n maneja el dominio de nivel superior de este nombre?‚Äù\nRespuesta del servidor ra√≠z: El servidor ra√≠z no conoce la direcci√≥n IP espec√≠fica, pero s√≠ sabe qu√© servidor TLD maneja ese tipo de dominio (.com, .org, .es, etc.). Responde con la direcci√≥n del servidor TLD apropiado.\nConsulta al servidor TLD: El servidor DNS local ahora consulta al servidor TLD correspondiente preguntando: ‚Äú¬øQu√© servidor autoritativo maneja este dominio espec√≠fico?‚Äù\nRespuesta del servidor TLD: El servidor TLD responde con la informaci√≥n del servidor autoritativo responsable del dominio consultado. Por ejemplo, si buscas www.ejemplo.com, te dir√° cu√°l es el servidor autoritativo para ejemplo.com.\nConsulta al servidor autoritativo: Finalmente, el servidor DNS local consulta al servidor autoritativo del dominio, que tiene la informaci√≥n definitiva sobre todos los registros de ese dominio.\nRespuesta del servidor autoritativo: El servidor autoritativo responde con la direcci√≥n IP correspondiente al nombre solicitado (registro A) o la informaci√≥n solicitada seg√∫n el tipo de consulta.\nRespuesta final al cliente: El servidor DNS local almacena la respuesta en su cach√© (con un tiempo de vida o TTL espec√≠fico) y env√≠a la direcci√≥n IP al cliente que origin√≥ la consulta.\n\n\n\n\n\n\n\nsequenceDiagram\n    participant Cliente as Cliente/SO\n    participant Local as Servidor DNS Local&lt;br/&gt;(Recursivo)\n    participant Raiz as Servidor Ra√≠z\n    participant TLD as Servidor TLD&lt;br/&gt;(.com, .org, etc.)\n    participant Auth as Servidor Autoritativo\n\n    Note over Cliente: Ejemplo: www.google.es\n    \n    Cliente-&gt;&gt;Cliente: 1. Verifica cach√© local del SO.\n    alt No est√° en cach√© local\n        Cliente-&gt;&gt;Local: 2. Consulta DNS: ¬øIP de www.google.es?\n        \n        Local-&gt;&gt;Local: Verifica cach√© DNS local\n        alt No est√° en cach√© DNS\n            Local-&gt;&gt;Raiz: 3. ¬øQui√©n maneja .es?\n            Raiz-&gt;&gt;Local: 4. Servidor TLD para .es: [IP_TLD]\n            \n            Local-&gt;&gt;TLD: 5. ¬øQui√©n maneja www.google.es?\n            TLD-&gt;&gt;Local: 6. Servidor autoritativo: [IP_AUTH]\n            \n            Local-&gt;&gt;Auth: 7. ¬øIP de www.google.es?\n            Auth-&gt;&gt;Local: 8. IP: 173.194.202.94\n        end\n        \n        Local-&gt;&gt;Cliente: 9. Respuesta: 173.194.202.94\n    end\n    \n    Note over Cliente,Auth: El cliente ahora puede conectarse&lt;br/&gt;directamente a 173.194.202.94\n\n\n\n\n\n\n\n\n\n5.3.3 SMTP, IMAP y POP\nLos protocolos SMTP, IMAP y POP son protocolos que definen el funcionamiento del correo electr√≥nico tal y como lo conocemos hoy en d√≠a. Cada uno tiene un prop√≥sito espec√≠fico en el proceso de env√≠o, almacenamiento y recuperaci√≥n de mensajes.\nSMTP es el protocolo est√°ndar para el env√≠o de correos electr√≥nicos a trav√©s de Internet. Funciona como un servicio de entrega que transporta mensajes desde el cliente de correo del remitente hasta el servidor de correo del destinatario. Es un protocolo ‚Äúpush‚Äù, empuja los mensajes desde el origen hacia el destino, y no maneja la recepci√≥n de los correos.\nPOP, especialmente POP3 (la versi√≥n m√°s actual), es un protocolo para descargar correos electr√≥nicos desde el servidor al dispositivo local. POP descarga los mensajes completos al dispositivo local, y por defecto, los elimina los mensajes del servidor tras la descarga. Es ideal para usuarios que acceden al correo desde un √∫nico dispositivo, pero presenta limitaciones para sincronizaci√≥n entre m√∫ltiples dispositivos\nIMAP es un protocolo m√°s moderno que permite acceder a los correos electr√≥nicos manteniendo la sincronizaci√≥n entre el servidor y m√∫ltiples clientes. Los mensajes permanecen en el servidor y permite sincronizaci√≥n en tiempo real entre dispositivos. Soporta carpetas, etiquetas y b√∫squedas en el servidor. Es ideal para usuarios que acceden al correo desde m√∫ltiples dispositivos\n\n\n5.3.4 QUIC\nQUIC representa una evoluci√≥n revolucionaria en los protocolos de transporte de Internet, desarrollado inicialmente por Google en 2012 y estandarizado por la IETF en 2021 como RFC 9000. Este protocolo moderno construido sobre UDP combina las mejores caracter√≠sticas de TCP con la seguridad integrada de TLS 1.3, eliminando muchas de las limitaciones hist√≥ricas de los protocolos tradicionales. Sus principales ventajas incluyen el multiplexado nativo de streams sin el problema de head-of-line blocking que afecta a HTTP/2 sobre TCP, el establecimiento de conexiones con latencia cero (0-RTT) para reconexiones, y la capacidad √∫nica de migraci√≥n de conexi√≥n que permite a los dispositivos cambiar transparentemente entre redes WiFi y m√≥viles sin interrumpir las sesiones activas. Adem√°s, QUIC incorpora algoritmos de control de congesti√≥n m√°s sofisticados y mecanismos de correcci√≥n de errores (Forward Error Correction) que mejoran significativamente el rendimiento en condiciones de red inestables o con alta p√©rdida de paquetes.\nLos casos de uso de QUIC son especialmente relevantes en aplicaciones que requieren baja latencia y alta confiabilidad, siendo adoptado masivamente por servicios de streaming, aplicaciones de videoconferencia, juegos en l√≠nea, y plataformas de contenido como YouTube, donde Google reporta reducciones de hasta 30% en tiempo de carga. Su adopci√≥n en 2025 ha alcanzado cifras impresionantes: el 8.2% de todos los sitios web globalmente utilizan QUIC, mientras que HTTP/3 (que funciona exclusivamente sobre QUIC) es empleado por el 31.1% de los sitios web.",
    "crumbs": [
      "Introducci√≥n a redes",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Capa de aplicaci√≥n</span>"
    ]
  },
  {
    "objectID": "ch/part_networks/application_layer/application_layer.html#servicios",
    "href": "ch/part_networks/application_layer/application_layer.html#servicios",
    "title": "5¬† Capa de aplicaci√≥n",
    "section": "5.4 Servicios",
    "text": "5.4 Servicios\n\n5.4.1 CDNs\nLas CDN funcionan mediante una red distribuida de servidores edge ubicados estrat√©gicamente en diferentes regiones geogr√°ficas, que almacenan copias del contenido desde los servidores origen para reducir la distancia f√≠sica que deben recorrer los datos hasta llegar al usuario final. El sistema utiliza enrutamiento inteligente que autom√°ticamente dirige cada solicitud al servidor m√°s cercano disponible, t√≠picamente reduciendo la latencia de carga de 200-500ms a menos de 50ms. La estrategia de cach√© var√≠a seg√∫n el tipo de contenido: archivos est√°ticos como im√°genes, v√≠deos y assets de aplicaciones se almacenan por per√≠odos prolongados (d√≠as o semanas), mientras que contenido din√°mico como respuestas de APIs se cachea por minutos u horas con validaci√≥n frecuente. Para contenido personalizado, las CDN implementan t√©cnicas de cach√© parcial donde elementos comunes se reutilizan entre usuarios, y para streaming en tiempo real dividen el contenido en peque√±os segmentos que pueden cachearse individualmente.\nM√°s all√° de la simple entrega de contenido, las CDN modernas act√∫an como una capa de protecci√≥n y optimizaci√≥n que incluye compresi√≥n autom√°tica de archivos, conversi√≥n de formatos de imagen seg√∫n el dispositivo del usuario, y balanceado de carga inteligente que redistribuye el tr√°fico cuando alg√∫n servidor se sobrecarga. En aplicaciones como videojuegos, las CDN aceleran la descarga de actualizaciones y assets mediante t√©cnicas de pre-carga predictiva, mientras que para aplicaciones web ejecutan c√≥digo simple directamente en los servidores edge para personalizaci√≥n b√°sica sin necesidad de consultar el servidor origen. La arquitectura distribuida proporciona resistencia natural contra ca√≠das de servicio y ataques DDoS, ya que el tr√°fico malicioso se dispersa autom√°ticamente entre m√∫ltiples ubicaciones, y sistemas de monitoreo en tiempo real pueden redirigir usuarios desde servidores con problemas hacia alternativas saludables, manteniendo la disponibilidad del servicio incluso durante fallas regionales o ataques coordinados",
    "crumbs": [
      "Introducci√≥n a redes",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Capa de aplicaci√≥n</span>"
    ]
  },
  {
    "objectID": "ch/part_networks/application_layer/application_layer.html#footnotes",
    "href": "ch/part_networks/application_layer/application_layer.html#footnotes",
    "title": "5¬† Capa de aplicaci√≥n",
    "section": "",
    "text": "Dos m√°quinas pueden tener diferente endianness (orden de bytes): big-endian almacena el byte m√°s significativo primero, mientras que little-endian lo guarda al final. Los protocolos de red usan network byte order (big-endian) para garantizar que ambas m√°quinas interpreten los datos correctamente, independientemente de su arquitectura interna.‚Ü©Ô∏é\nEn realidad son para sistemas distribuidos. Pero las aplicaciones de red son inherentemente sistemas distribuidos.‚Ü©Ô∏é",
    "crumbs": [
      "Introducci√≥n a redes",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Capa de aplicaci√≥n</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Analytics, IoT. 2020. ‚ÄúInternet of Things (IoT) and Non-IoT Active\nDevice Connections Worldwide from 2010 to 2025 (in Billions).‚Äù\nStatista. https://www.statista.com/statistics/1101442/iot-number-of-connected-devices-worldwide/.\n\n\nBBC Brasil. 2019. ‚Äú[Image from: Article Title].‚Äù https://www.bbc.com/portuguese/geral-50162526.\n\n\nClaypool, Mark, and Kajal Claypool. 2006. ‚ÄúLatency and Player\nActions in Online Games.‚Äù Commun. ACM 49 (11): 40‚Äì45. https://doi.org/10.1145/1167838.1167860.\n\n\nKurose, James F., and Keith W. Ross. 2017. Computer Networks: A\nTop-down Approach. 7th ed. Boston, MA: Pearson.\n\n\nRitchie, Hannah, Edouard Mathieu, Max Roser, and Esteban Ortiz-Ospina.\n2023. ‚ÄúInternet.‚Äù Our World in Data. https://ourworldindata.org/internet.",
    "crumbs": [
      "References"
    ]
  }
]